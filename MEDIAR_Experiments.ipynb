{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biuER5L5P_bp"
      },
      "source": [
        "# MEDIAR Experiments\n",
        "\n",
        "The framework for most of the experiments is conducted by loading the corresponding model from google drive using the ```gdown``` command. Then, a configuration file is either created or modified from previous experiments (```config/``` directory). Our experimental process/reasoning is more clearly explained in the project report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00LjatqCPZf6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "Clone Github repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wC7RDZmIDTR"
      },
      "outputs": [],
      "source": [
        "# Clone MEDIAR github repo\n",
        "!git clone https://github.com/CS-433/ml-project-2-doughminators.git\n",
        "%rm -rf ./sample_data\n",
        "%cd ml-project-2-doughminators/\n",
        "\n",
        "# Install dependencies\n",
        "%pip install -r requirements.txt\n",
        "%pip install segmentation-models-pytorch==0.3.1\n",
        "%pip install wandb\n",
        "\n",
        "\n",
        "!wandb offline\n",
        "\n",
        "# Uncomment and add login key to record experiments\n",
        "# !wandb online\n",
        "# !wandb login [ insert wandb key ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKYRYitHRNR"
      },
      "source": [
        "#### Download MEDIAR Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doVGxk2VHApv",
        "outputId": "b9a95928-0f6c-4e8f-eb02-e6f3787fa078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=168MtudjTMLoq9YGTyoD2Rjl_d3Gy6c_L\n",
            "To: /content/ml-project-2-doughminators/weights/from_phase1.pth\n",
            "100% 486M/486M [00:06<00:00, 70.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JJ2-QKTCk-G7sp5ddkqcifMxgnyOrXjx\n",
            "To: /content/ml-project-2-doughminators/weights/from_phase2.pth\n",
            "100% 486M/486M [00:10<00:00, 46.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download MEDIAR pretrained weights\n",
        "%mkdir weights\n",
        "!gdown https://drive.google.com/uc?id=168MtudjTMLoq9YGTyoD2Rjl_d3Gy6c_L -O weights/from_phase1.pth\n",
        "!gdown https://drive.google.com/uc?id=1JJ2-QKTCk-G7sp5ddkqcifMxgnyOrXjx -O weights/from_phase2.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load packages"
      ],
      "metadata": {
        "id": "EFpX1Z21Yv7T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R2iwnqsUQvLn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import glob\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from train_tools import *\n",
        "from train_tools.models import MEDIARFormer\n",
        "from core.MEDIAR import Predictor, EnsemblePredictor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If one wants to use the A100 NVIDIA GPUs on colab, a new versino of torch needs to be installed. For CUDA compatibility when using A100, run this cell and restart kernel."
      ],
      "metadata": {
        "id": "C7Q2HOdoc0p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0+cu113 --extra-index-url https://download.pytorch.org/whl/cu113"
      ],
      "metadata": {
        "id": "M-Rx8S8Yc-lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrhtOdY5lKu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### 2. Prediction on yeast data without any fine-tuning: MEDIAR's phase 1, phase 1 fine-tuned, Ensemble Model.\n",
        "\n",
        "In this section, we perform prediction and evaluation on the whole YeaZ dataset, in order to establish the performance of MEDIAR on the YeaZ data without having seen it.\n",
        "#### Download (restructured) yeast data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKyibPGqRrwu"
      },
      "outputs": [],
      "source": [
        "!gdown [ insert data link ] --fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9rCM4qM5zGI"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/ml-project-2-doughminators/Datasets.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/ml-project-2-doughminators/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKGvncUnV29Q"
      },
      "source": [
        "Sanity check: should be 2914 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRixTbgaVud3",
        "outputId": "ab3ec732-e544-4d0a-b0d1-3280d192935a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2914"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "len(os.listdir(\"/content/ml-project-2-doughminators/Datasets/images\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kATPJwW__WNX"
      },
      "source": [
        "#### Inference on whole YeaZ dataset\n",
        "- switch device accordingly in the config file\n",
        "\n",
        "Note: this corresponds to the P1FT model in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Zihq3tx_VT-",
        "outputId": "0c592ab0-df70-4f04-e077-7cacea392c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'pred_setups': {'algo_params': {'use_tta': False},\n",
            "                 'device': 'cuda:0',\n",
            "                 'exp_name': 'mediar_p1_base',\n",
            "                 'input_path': 'Datasets/images',\n",
            "                 'make_submission': True,\n",
            "                 'model': {'name': 'mediar-former',\n",
            "                           'params': {'classes': 3,\n",
            "                                      'decoder_channels': [1024, 512, 256, 128,\n",
            "                                                           64],\n",
            "                                      'decoder_pab_channels': 256,\n",
            "                                      'encoder_name': 'mit_b5',\n",
            "                                      'in_channels': 3}},\n",
            "                 'model_path': './weights/from_phase1.pth',\n",
            "                 'name': 'mediar',\n",
            "                 'output_path': './results/mediar_base_prediction'}}\n",
            "========================================================================================================================\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.60s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.25s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 10_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 11_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 12_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.41s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.61s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.68s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.45s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.43s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.42s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 12_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 13_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 14_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 16_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 16_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 170922_ageing-pos37-ch1-60ph-001_crop_1.tiff; img size = torch.Size([1, 3, 2032, 2032]); costing: 14.41s\n",
            "Prediction finished: 170922_ageing-pos37-ch1-60ph-051_crop_1.tiff; img size = torch.Size([1, 3, 2032, 2032]); costing: 15.97s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.41s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 1_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 1_crop_1.tiff; img size = torch.Size([1, 3, 808, 360]); costing: 0.77s\n",
            "Prediction finished: 1out1_crop_1.tiff; img size = torch.Size([1, 3, 808, 360]); costing: 0.73s\n",
            "Prediction finished: 1out2_crop_1.tiff; img size = torch.Size([1, 3, 808, 360]); costing: 0.75s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f10_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.83s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f11_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.86s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f12_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.81s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f13_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.83s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f1_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.71s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f2_crop_1.tiff; img size = torch.Size([1, 3, 400, 611]); costing: 0.40s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f3_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.71s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f4_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.71s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f5_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.72s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f6_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.74s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f7_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.74s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f8_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.73s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f9_crop_1.tiff; img size = torch.Size([1, 3, 609, 611]); costing: 0.73s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f10_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.47s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f11_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.48s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f12_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.48s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f13_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.49s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f1_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.43s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f2_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.42s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f3_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.50s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f4_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.49s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f5_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.51s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f6_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.51s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f7_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.53s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f8_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.50s\n",
            "Prediction finished: 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f9_crop_1.tiff; img size = torch.Size([1, 3, 416, 680]); costing: 0.47s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1.tiff; img size = torch.Size([1, 3, 640, 809]); costing: 1.20s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1.tiff; img size = torch.Size([1, 3, 640, 809]); costing: 1.22s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1.tiff; img size = torch.Size([1, 3, 640, 809]); costing: 1.19s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1.tiff; img size = torch.Size([1, 3, 364, 860]); costing: 0.63s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 364, 860]); costing: 0.63s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1.tiff; img size = torch.Size([1, 3, 364, 860]); costing: 0.62s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1.tiff; img size = torch.Size([1, 3, 538, 732]); costing: 1.05s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1.tiff; img size = torch.Size([1, 3, 538, 732]); costing: 1.05s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1.tiff; img size = torch.Size([1, 3, 538, 732]); costing: 1.04s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1.tiff; img size = torch.Size([1, 3, 621, 682]); costing: 1.02s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1.tiff; img size = torch.Size([1, 3, 621, 682]); costing: 0.99s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1.tiff; img size = torch.Size([1, 3, 621, 682]); costing: 0.98s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1.tiff; img size = torch.Size([1, 3, 459, 559]); costing: 0.46s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 459, 559]); costing: 0.46s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1.tiff; img size = torch.Size([1, 3, 459, 559]); costing: 0.46s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1.tiff; img size = torch.Size([1, 3, 501, 524]); costing: 0.50s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1.tiff; img size = torch.Size([1, 3, 501, 524]); costing: 0.50s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1.tiff; img size = torch.Size([1, 3, 501, 524]); costing: 0.48s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1.tiff; img size = torch.Size([1, 3, 595, 496]); costing: 0.52s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 595, 496]); costing: 0.53s\n",
            "Prediction finished: 200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1.tiff; img size = torch.Size([1, 3, 595, 496]); costing: 0.51s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1.tiff; img size = torch.Size([1, 3, 610, 925]); costing: 1.45s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1.tiff; img size = torch.Size([1, 3, 610, 925]); costing: 1.46s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1.tiff; img size = torch.Size([1, 3, 610, 925]); costing: 1.49s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1.tiff; img size = torch.Size([1, 3, 610, 925]); costing: 1.51s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1.tiff; img size = torch.Size([1, 3, 610, 925]); costing: 1.51s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1.tiff; img size = torch.Size([1, 3, 403, 656]); costing: 0.47s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1.tiff; img size = torch.Size([1, 3, 403, 656]); costing: 0.48s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1.tiff; img size = torch.Size([1, 3, 403, 656]); costing: 0.47s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1.tiff; img size = torch.Size([1, 3, 403, 656]); costing: 0.46s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1.tiff; img size = torch.Size([1, 3, 403, 656]); costing: 0.46s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1.tiff; img size = torch.Size([1, 3, 724, 615]); costing: 1.20s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1.tiff; img size = torch.Size([1, 3, 724, 615]); costing: 1.20s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1.tiff; img size = torch.Size([1, 3, 724, 615]); costing: 1.19s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1.tiff; img size = torch.Size([1, 3, 724, 615]); costing: 1.19s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1.tiff; img size = torch.Size([1, 3, 724, 615]); costing: 1.17s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1.tiff; img size = torch.Size([1, 3, 643, 849]); costing: 1.29s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 643, 849]); costing: 1.41s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1.tiff; img size = torch.Size([1, 3, 643, 849]); costing: 1.38s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1.tiff; img size = torch.Size([1, 3, 643, 849]); costing: 1.25s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1.tiff; img size = torch.Size([1, 3, 634, 523]); costing: 0.87s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1.tiff; img size = torch.Size([1, 3, 634, 523]); costing: 0.88s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1.tiff; img size = torch.Size([1, 3, 634, 523]); costing: 0.87s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1.tiff; img size = torch.Size([1, 3, 634, 523]); costing: 0.85s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1.tiff; img size = torch.Size([1, 3, 634, 523]); costing: 0.84s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1.tiff; img size = torch.Size([1, 3, 601, 596]); costing: 0.75s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1.tiff; img size = torch.Size([1, 3, 601, 596]); costing: 0.76s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 601, 596]); costing: 0.75s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1.tiff; img size = torch.Size([1, 3, 601, 596]); costing: 0.74s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1.tiff; img size = torch.Size([1, 3, 601, 596]); costing: 0.75s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1.tiff; img size = torch.Size([1, 3, 566, 784]); costing: 1.26s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1.tiff; img size = torch.Size([1, 3, 566, 784]); costing: 1.28s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1.tiff; img size = torch.Size([1, 3, 566, 784]); costing: 1.19s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1.tiff; img size = torch.Size([1, 3, 716, 643]); costing: 0.88s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1.tiff; img size = torch.Size([1, 3, 716, 643]); costing: 0.89s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1.tiff; img size = torch.Size([1, 3, 716, 643]); costing: 0.89s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1.tiff; img size = torch.Size([1, 3, 716, 643]); costing: 0.89s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1.tiff; img size = torch.Size([1, 3, 716, 643]); costing: 0.86s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1.tiff; img size = torch.Size([1, 3, 406, 824]); costing: 0.66s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1.tiff; img size = torch.Size([1, 3, 406, 824]); costing: 0.68s\n",
            "Prediction finished: 200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1.tiff; img size = torch.Size([1, 3, 406, 824]); costing: 0.66s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.47s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.31s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.37s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.32s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.30s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.42s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.41s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.32s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(1)_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(3)_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.19s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.55s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(4)_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.72s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.26s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.55s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.26s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.25s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.25s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.20s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.23s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.26s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.25s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.24s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(5)_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 256, 450]); costing: 0.21s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.38s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.37s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.38s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.38s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.38s\n",
            "Prediction finished: 200917_JK_MS133-0003_Position(6)_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 385, 595]); costing: 0.38s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.84s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.81s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.84s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.85s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.82s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.85s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.91s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t100_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.87s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t150_modified_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.84s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t1_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.69s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t200_modified_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.82s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t50_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.64s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.27s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.37s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.57s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.52s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.50s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.54s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.66s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 3.59s\n",
            "Prediction finished: 20201221_LLY3752_Gal+aa_OD2.08_60x_concdZ5XY54C1_crop_1.tiff; img size = torch.Size([1, 3, 2060, 2260]); costing: 18.01s\n",
            "Prediction finished: 20201221_LLY3752_Gal+aa_OD2.08_60x_concdZ5XY55C1_crop_1.tiff; img size = torch.Size([1, 3, 2060, 2260]); costing: 17.79s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 0.33s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 0.36s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 0.24s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 0.25s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 0.25s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 0.22s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 0.25s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 0.23s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 0.25s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 0.37s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_01_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_03_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 0.25s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_04_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 0.25s\n",
            "Prediction finished: 210311_SW646_AsymmetricAfternoon01_3_crop_1.tiff; img size = torch.Size([1, 3, 628, 597]); costing: 0.75s\n",
            "Prediction finished: 210521_Ncdc13_01_01_01_01_crop_1.tiff; img size = torch.Size([1, 3, 948, 810]); costing: 2.26s\n",
            "Prediction finished: 210521_Ncdc13_01_01_01_02_crop_1.tiff; img size = torch.Size([1, 3, 704, 820]); costing: 1.24s\n",
            "Prediction finished: 210521_Ncdc13_01_01_02_02_crop_1.tiff; img size = torch.Size([1, 3, 276, 304]); costing: 0.32s\n",
            "Prediction finished: 210521_Ncdc13_01_01_03_01_crop_1.tiff; img size = torch.Size([1, 3, 308, 636]); costing: 0.47s\n",
            "Prediction finished: 210521_Ncdc13_01_01_07_01_crop_1.tiff; img size = torch.Size([1, 3, 388, 482]); costing: 0.33s\n",
            "Prediction finished: 210521_Ncdc13_01_01_08_01_crop_1.tiff; img size = torch.Size([1, 3, 332, 418]); costing: 0.33s\n",
            "Prediction finished: 210521_Ncdc13_01_01_08_02_crop_1.tiff; img size = torch.Size([1, 3, 312, 464]); costing: 0.33s\n",
            "Prediction finished: 23_fm464_live095_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1434, 1434]); costing: 5.99s\n",
            "Prediction finished: 23_fm464_live098_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1459, 1459]); costing: 6.41s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.63s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.42s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.51s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 2_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 1.31s\n",
            "Prediction finished: 2out1_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 1.31s\n",
            "Prediction finished: 2out2_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.41s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.44s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.50s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.45s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.47s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.45s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.46s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.43s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.41s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.41s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.42s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.42s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.45s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.44s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.43s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.41s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.41s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.39s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.40s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.33s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.28s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.35s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 3_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.69s\n",
            "Prediction finished: 3out1_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.58s\n",
            "Prediction finished: 3out2_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.56s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.48s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.49s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.40s\n",
            "Prediction finished: 4_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.35s\n",
            "Prediction finished: 4out1_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.24s\n",
            "Prediction finished: 4out2_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.22s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.38s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 5_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.77s\n",
            "Prediction finished: 5out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.76s\n",
            "Prediction finished: 5out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.77s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.26s\n",
            "Prediction finished: 6out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.49s\n",
            "Prediction finished: 6out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.26s\n",
            "Prediction finished: 7.5.2018_tp50_pos03_crop_1.tiff; img size = torch.Size([1, 3, 512, 500]); costing: 0.40s\n",
            "Prediction finished: 7.5.2018_tp50_pos06_crop_1.tiff; img size = torch.Size([1, 3, 512, 505]); costing: 0.31s\n",
            "Prediction finished: 7.5.2018_tp50_pos08_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.30s\n",
            "Prediction finished: 7.5.2018_tp50_pos09_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.38s\n",
            "Prediction finished: 7.5.2018_tp50_pos10_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.36s\n",
            "Prediction finished: 7.5.2018_tp50_pos21_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.38s\n",
            "Prediction finished: 7.5.2018_tp50_pos28_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.34s\n",
            "Prediction finished: 7.5.2018_tp50_pos32_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.32s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.80s\n",
            "Prediction finished: 7out1_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.77s\n",
            "Prediction finished: 7out2_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.75s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.39s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.26s\n",
            "Prediction finished: 8out1_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.29s\n",
            "Prediction finished: 8out2_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.40s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: Abf1_Ancestor_5_z24_BF_crop_1.tiff; img size = torch.Size([1, 3, 958, 918]); costing: 2.57s\n",
            "Prediction finished: Abf1_Ancestor_6_z23_BF_crop_1.tiff; img size = torch.Size([1, 3, 730, 958]); costing: 2.74s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_1.tiff; img size = torch.Size([1, 3, 953, 650]); costing: 1.89s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_2.tiff; img size = torch.Size([1, 3, 678, 308]); costing: 0.52s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.74s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.74s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.76s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.77s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.79s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_0.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.03s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_1.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.11s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_2.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.13s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_3.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.14s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_4.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.08s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.58s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.57s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.59s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.71s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.60s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.42s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.42s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.43s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.43s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.44s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.27s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.26s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.28s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.27s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.27s\n",
            "Prediction finished: MS183_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.60s\n",
            "Prediction finished: MS183_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.62s\n",
            "Prediction finished: MS183_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.59s\n",
            "Prediction finished: MS183_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.61s\n",
            "Prediction finished: MS183_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.19s\n",
            "Prediction finished: MS183_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.97s\n",
            "Prediction finished: MS183_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.76s\n",
            "Prediction finished: MS183_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.74s\n",
            "Prediction finished: MS183_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.89s\n",
            "Prediction finished: PN1192_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 17.50s\n",
            "Prediction finished: PN1192_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 15.86s\n",
            "Prediction finished: PN1192_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 17.77s\n",
            "Prediction finished: PN1192_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 16.68s\n",
            "Prediction finished: PN1192_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 18.65s\n",
            "Prediction finished: PN1192_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 17.30s\n",
            "Prediction finished: PN1192_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 12.66s\n",
            "Prediction finished: PN19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 20.02s\n",
            "Prediction finished: PN19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.53s\n",
            "Prediction finished: PN19_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.70s\n",
            "Prediction finished: PN19_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.80s\n",
            "Prediction finished: PN19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.64s\n",
            "Prediction finished: PN19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 20.55s\n",
            "Prediction finished: PN19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 20.69s\n",
            "Prediction finished: PN19_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 21.03s\n",
            "Prediction finished: PN19_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.69s\n",
            "Prediction finished: PN19_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 15.56s\n",
            "Prediction finished: PN19_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.76s\n",
            "Prediction finished: PN19_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.76s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.02s\n",
            "Prediction finished: Schmoller_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.09s\n",
            "Prediction finished: Schmoller_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.10s\n",
            "Prediction finished: Schmoller_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.03s\n",
            "Prediction finished: Schmoller_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: V11032020_p1_crop_1.tiff; img size = torch.Size([1, 3, 410, 360]); costing: 0.26s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.72s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.72s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.72s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.72s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 0.76s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 0.83s\n",
            "Prediction finished: a_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.77s\n",
            "Prediction finished: a_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.77s\n",
            "Prediction finished: a_reexport1_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.83s\n",
            "Prediction finished: a_reexport1_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.84s\n",
            "Prediction finished: a_reexport1_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.77s\n",
            "Prediction finished: a_reexport1_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.79s\n",
            "Prediction finished: a_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.43s\n",
            "Prediction finished: a_reexport2_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.45s\n",
            "Prediction finished: a_reexport2_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.45s\n",
            "Prediction finished: a_reexport2_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.42s\n",
            "Prediction finished: a_reexport2_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.42s\n",
            "Prediction finished: a_reexport2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 1.93s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 1.98s\n",
            "Prediction finished: alk1alk2_001_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 15.02s\n",
            "Prediction finished: alk1alk2_011_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.39s\n",
            "Prediction finished: bendy1_crop_1.tiff; img size = torch.Size([1, 3, 692, 937]); costing: 1.56s\n",
            "Prediction finished: bendy2_crop_1.tiff; img size = torch.Size([1, 3, 541, 812]); costing: 1.10s\n",
            "Prediction finished: cdc20F10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.33s\n",
            "Prediction finished: cdc20F10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.34s\n",
            "Prediction finished: cdc20F10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.33s\n",
            "Prediction finished: cdc20F10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.26s\n",
            "Prediction finished: cdc20F1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.32s\n",
            "Prediction finished: cdc20F1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.34s\n",
            "Prediction finished: cdc20F1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.35s\n",
            "Prediction finished: cdc20F1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.34s\n",
            "Prediction finished: cdc20F1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.34s\n",
            "Prediction finished: cdc20F1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.25s\n",
            "Prediction finished: cdc20F2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.31s\n",
            "Prediction finished: cdc20F2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.24s\n",
            "Prediction finished: cdc20F3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.48s\n",
            "Prediction finished: cdc20F3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.54s\n",
            "Prediction finished: cdc20F3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.53s\n",
            "Prediction finished: cdc20F3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.53s\n",
            "Prediction finished: cdc20F3mCh_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.45s\n",
            "Prediction finished: cdc20F4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 2.15s\n",
            "Prediction finished: cdc20F4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.88s\n",
            "Prediction finished: cdc20F4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.95s\n",
            "Prediction finished: cdc20F4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.81s\n",
            "Prediction finished: cdc20F4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.80s\n",
            "Prediction finished: cdc20F4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.84s\n",
            "Prediction finished: cdc20F4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.80s\n",
            "Prediction finished: cdc20F4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.81s\n",
            "Prediction finished: cdc20F4mCh_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 2.14s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.43s\n",
            "Prediction finished: cdc20F5BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.65s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.35s\n",
            "Prediction finished: cdc20F5BF_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.59s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.25s\n",
            "Prediction finished: cdc20F5BF_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.39s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5BF_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.46s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.41s\n",
            "Prediction finished: cdc20F5BF_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.50s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5BF_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.46s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.25s\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.47s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.25s\n",
            "Prediction finished: cdc20F5PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.66s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.24s\n",
            "Prediction finished: cdc20F5PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.63s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.29s\n",
            "Prediction finished: cdc20F5PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.45s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.45s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.23s\n",
            "Prediction finished: cdc20F5PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.52s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.38s\n",
            "Prediction finished: cdc20F5mCh_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.18s\n",
            "Prediction finished: cdc20F6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.97s\n",
            "Prediction finished: cdc20F6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.83s\n",
            "Prediction finished: cdc20F6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.85s\n",
            "Prediction finished: cdc20F6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.85s\n",
            "Prediction finished: cdc20F6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 2.05s\n",
            "Prediction finished: cdc20F6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 2.14s\n",
            "Prediction finished: cdc20F6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.88s\n",
            "Prediction finished: cdc20F6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.89s\n",
            "Prediction finished: cdc20F6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.87s\n",
            "Prediction finished: cdc20F6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.88s\n",
            "Prediction finished: cdc20F6mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.70s\n",
            "Prediction finished: cdc20F7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.86s\n",
            "Prediction finished: cdc20F7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.87s\n",
            "Prediction finished: cdc20F7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.80s\n",
            "Prediction finished: cdc20F7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.81s\n",
            "Prediction finished: cdc20F7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.80s\n",
            "Prediction finished: cdc20F7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.80s\n",
            "Prediction finished: cdc20F7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.80s\n",
            "Prediction finished: cdc20F7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.82s\n",
            "Prediction finished: cdc20F7mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.69s\n",
            "Prediction finished: cdc20F8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.31s\n",
            "Prediction finished: cdc20F8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.30s\n",
            "Prediction finished: cdc20F8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.20s\n",
            "Prediction finished: cdc20F8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.22s\n",
            "Prediction finished: cdc20F8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.24s\n",
            "Prediction finished: cdc20F8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.22s\n",
            "Prediction finished: cdc20F8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.22s\n",
            "Prediction finished: cdc20F8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.23s\n",
            "Prediction finished: cdc20F8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.35s\n",
            "Prediction finished: cdc20F8mCh_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.09s\n",
            "Prediction finished: cdc20F9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.86s\n",
            "Prediction finished: cdc20F9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.87s\n",
            "Prediction finished: cdc20F9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.87s\n",
            "Prediction finished: cdc20F9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.87s\n",
            "Prediction finished: cdc20F9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.86s\n",
            "Prediction finished: cdc20F9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.86s\n",
            "Prediction finished: cdc20F9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.87s\n",
            "Prediction finished: cdc20F9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.89s\n",
            "Prediction finished: cdc20F9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.88s\n",
            "Prediction finished: cdc20F9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.89s\n",
            "Prediction finished: cdc20F9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.88s\n",
            "Prediction finished: cdc20F9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 1.25s\n",
            "Prediction finished: cdc20F9mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.82s\n",
            "Prediction finished: clnF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.67s\n",
            "Prediction finished: clnF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.35s\n",
            "Prediction finished: clnF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.30s\n",
            "Prediction finished: clnF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.29s\n",
            "Prediction finished: clnF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.30s\n",
            "Prediction finished: clnF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.29s\n",
            "Prediction finished: clnF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.29s\n",
            "Prediction finished: clnF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.31s\n",
            "Prediction finished: clnF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.29s\n",
            "Prediction finished: clnF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.27s\n",
            "Prediction finished: clnF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.93s\n",
            "Prediction finished: clnF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.72s\n",
            "Prediction finished: clnF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.72s\n",
            "Prediction finished: clnF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.73s\n",
            "Prediction finished: clnF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.68s\n",
            "Prediction finished: clnF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.95s\n",
            "Prediction finished: clnF11PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.79s\n",
            "Prediction finished: clnF11PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 6.06s\n",
            "Prediction finished: clnF11PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.81s\n",
            "Prediction finished: clnF11PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 6.12s\n",
            "Prediction finished: clnF11PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.79s\n",
            "Prediction finished: clnF11PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 6.14s\n",
            "Prediction finished: clnF11mCh_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.67s\n",
            "Prediction finished: clnF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.87s\n",
            "Prediction finished: clnF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.87s\n",
            "Prediction finished: clnF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.86s\n",
            "Prediction finished: clnF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.86s\n",
            "Prediction finished: clnF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.88s\n",
            "Prediction finished: clnF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.94s\n",
            "Prediction finished: clnF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.98s\n",
            "Prediction finished: clnF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.95s\n",
            "Prediction finished: clnF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.88s\n",
            "Prediction finished: clnF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.90s\n",
            "Prediction finished: clnF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.89s\n",
            "Prediction finished: clnF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.89s\n",
            "Prediction finished: clnF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.71s\n",
            "Prediction finished: clnF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.27s\n",
            "Prediction finished: clnF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.28s\n",
            "Prediction finished: clnF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.41s\n",
            "Prediction finished: clnF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.28s\n",
            "Prediction finished: clnF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.27s\n",
            "Prediction finished: clnF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.27s\n",
            "Prediction finished: clnF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.30s\n",
            "Prediction finished: clnF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.44s\n",
            "Prediction finished: clnF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.31s\n",
            "Prediction finished: clnF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.32s\n",
            "Prediction finished: clnF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.31s\n",
            "Prediction finished: clnF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.31s\n",
            "Prediction finished: clnF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.15s\n",
            "Prediction finished: clnF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.89s\n",
            "Prediction finished: clnF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.91s\n",
            "Prediction finished: clnF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.91s\n",
            "Prediction finished: clnF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.83s\n",
            "Prediction finished: clnF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.82s\n",
            "Prediction finished: clnF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.81s\n",
            "Prediction finished: clnF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.87s\n",
            "Prediction finished: clnF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.86s\n",
            "Prediction finished: clnF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.84s\n",
            "Prediction finished: clnF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.87s\n",
            "Prediction finished: clnF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.84s\n",
            "Prediction finished: clnF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.88s\n",
            "Prediction finished: clnF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.83s\n",
            "Prediction finished: clnF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.45s\n",
            "Prediction finished: clnF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.46s\n",
            "Prediction finished: clnF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.50s\n",
            "Prediction finished: clnF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.51s\n",
            "Prediction finished: clnF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.50s\n",
            "Prediction finished: clnF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.52s\n",
            "Prediction finished: clnF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.51s\n",
            "Prediction finished: clnF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.52s\n",
            "Prediction finished: clnF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.47s\n",
            "Prediction finished: clnF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.48s\n",
            "Prediction finished: clnF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.47s\n",
            "Prediction finished: clnF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.48s\n",
            "Prediction finished: clnF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.40s\n",
            "Prediction finished: clnF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.01s\n",
            "Prediction finished: clnF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.01s\n",
            "Prediction finished: clnF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.00s\n",
            "Prediction finished: clnF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.18s\n",
            "Prediction finished: clnF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.16s\n",
            "Prediction finished: clnF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.01s\n",
            "Prediction finished: clnF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.04s\n",
            "Prediction finished: clnF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.60s\n",
            "Prediction finished: clnF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.03s\n",
            "Prediction finished: clnF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.24s\n",
            "Prediction finished: clnF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.45s\n",
            "Prediction finished: clnF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.40s\n",
            "Prediction finished: clnF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.66s\n",
            "Prediction finished: clnF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.70s\n",
            "Prediction finished: clnF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.72s\n",
            "Prediction finished: clnF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.82s\n",
            "Prediction finished: clnF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.81s\n",
            "Prediction finished: clnF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.70s\n",
            "Prediction finished: clnF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.72s\n",
            "Prediction finished: clnF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.75s\n",
            "Prediction finished: clnF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.75s\n",
            "Prediction finished: clnF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.76s\n",
            "Prediction finished: clnF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.86s\n",
            "Prediction finished: clnF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 2.02s\n",
            "Prediction finished: clnF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.75s\n",
            "Prediction finished: clnF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 2.07s\n",
            "Prediction finished: clnF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 4.13s\n",
            "Prediction finished: clnF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.90s\n",
            "Prediction finished: clnF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.49s\n",
            "Prediction finished: clnF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.38s\n",
            "Prediction finished: clnF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.35s\n",
            "Prediction finished: clnF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 4.10s\n",
            "Prediction finished: clnF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.77s\n",
            "Prediction finished: clnF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.52s\n",
            "Prediction finished: clnF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.66s\n",
            "Prediction finished: clnF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.42s\n",
            "Prediction finished: clnF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.48s\n",
            "Prediction finished: clnF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.52s\n",
            "Prediction finished: clnF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.22s\n",
            "Prediction finished: clnF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.50s\n",
            "Prediction finished: clnF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.50s\n",
            "Prediction finished: clnF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.49s\n",
            "Prediction finished: clnF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.50s\n",
            "Prediction finished: clnF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.50s\n",
            "Prediction finished: clnF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.50s\n",
            "Prediction finished: clnF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.41s\n",
            "Prediction finished: clnF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.01s\n",
            "Prediction finished: clnF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.01s\n",
            "Prediction finished: clnF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.09s\n",
            "Prediction finished: clnF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.10s\n",
            "Prediction finished: clnF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.10s\n",
            "Prediction finished: clnF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.01s\n",
            "Prediction finished: clnF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.03s\n",
            "Prediction finished: clnF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.05s\n",
            "Prediction finished: clnF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.03s\n",
            "Prediction finished: clnF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.03s\n",
            "Prediction finished: clnF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.02s\n",
            "Prediction finished: clnF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.03s\n",
            "Prediction finished: clnF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.88s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: d_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.31s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.32s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.30s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.29s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "Prediction finished: d_reexport1_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.31s\n",
            "Prediction finished: d_reexport1_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.31s\n",
            "Prediction finished: d_reexport1_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.31s\n",
            "Prediction finished: d_reexport1_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.33s\n",
            "Prediction finished: d_reexport1_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.34s\n",
            "Prediction finished: d_reexport1_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.33s\n",
            "Prediction finished: d_reexport1_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.34s\n",
            "Prediction finished: d_reexport1_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.32s\n",
            "Prediction finished: d_reexport1_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_4.tiff; img size = torch.Size([1, 3, 2000, 1988]); costing: 13.16s\n",
            "Prediction finished: d_reexport2_crop_1.tiff; img size = torch.Size([1, 3, 950, 1000]); costing: 2.65s\n",
            "Prediction finished: d_reexport2_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.29s\n",
            "Prediction finished: d_reexport2_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.27s\n",
            "Prediction finished: d_reexport2_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.27s\n",
            "Prediction finished: d_reexport2_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.29s\n",
            "Prediction finished: d_reexport2_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.27s\n",
            "Prediction finished: d_reexport2_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.26s\n",
            "Prediction finished: d_reexport2_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.75s\n",
            "Prediction finished: d_reexport2_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 1.00s\n",
            "Prediction finished: d_reexport2_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.76s\n",
            "Prediction finished: d_reexport2_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.71s\n",
            "Prediction finished: d_reexport2_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.73s\n",
            "Prediction finished: d_reexport2_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.75s\n",
            "Prediction finished: d_reexport2_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.76s\n",
            "Prediction finished: d_reexport2_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.82s\n",
            "Prediction finished: d_reexport2_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.73s\n",
            "Prediction finished: d_reexport2_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.73s\n",
            "Prediction finished: d_reexport2_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.76s\n",
            "Prediction finished: d_reexport2_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.76s\n",
            "Prediction finished: ddF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.41s\n",
            "Prediction finished: ddF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.28s\n",
            "Prediction finished: ddF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.30s\n",
            "Prediction finished: ddF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.28s\n",
            "Prediction finished: ddF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.29s\n",
            "Prediction finished: ddF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.45s\n",
            "Prediction finished: ddF10PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.33s\n",
            "Prediction finished: ddF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.45s\n",
            "Prediction finished: ddF10PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.32s\n",
            "Prediction finished: ddF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10mCh_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.29s\n",
            "Prediction finished: ddF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.48s\n",
            "Prediction finished: ddF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.41s\n",
            "Prediction finished: ddF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.41s\n",
            "Prediction finished: ddF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.41s\n",
            "Prediction finished: ddF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.41s\n",
            "Prediction finished: ddF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.36s\n",
            "Prediction finished: ddF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.46s\n",
            "Prediction finished: ddF2BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.46s\n",
            "Prediction finished: ddF2BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.51s\n",
            "Prediction finished: ddF2BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.51s\n",
            "Prediction finished: ddF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.52s\n",
            "Prediction finished: ddF2PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.51s\n",
            "Prediction finished: ddF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.52s\n",
            "Prediction finished: ddF2PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.47s\n",
            "Prediction finished: ddF2PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.47s\n",
            "Prediction finished: ddF2PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.46s\n",
            "Prediction finished: ddF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.47s\n",
            "Prediction finished: ddF2PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.48s\n",
            "Prediction finished: ddF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.47s\n",
            "Prediction finished: ddF2PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.46s\n",
            "Prediction finished: ddF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.41s\n",
            "Prediction finished: ddF2mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.39s\n",
            "Prediction finished: ddF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.28s\n",
            "Prediction finished: ddF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.28s\n",
            "Prediction finished: ddF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.24s\n",
            "Prediction finished: ddF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.26s\n",
            "Prediction finished: ddF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.26s\n",
            "Prediction finished: ddF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.31s\n",
            "Prediction finished: ddF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.31s\n",
            "Prediction finished: ddF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.32s\n",
            "Prediction finished: ddF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.33s\n",
            "Prediction finished: ddF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.34s\n",
            "Prediction finished: ddF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.34s\n",
            "Prediction finished: ddF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.34s\n",
            "Prediction finished: ddF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.33s\n",
            "Prediction finished: ddF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.29s\n",
            "Prediction finished: ddF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.25s\n",
            "Prediction finished: ddF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.25s\n",
            "Prediction finished: ddF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.21s\n",
            "Prediction finished: ddF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.75s\n",
            "Prediction finished: ddF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.75s\n",
            "Prediction finished: ddF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.75s\n",
            "Prediction finished: ddF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.44s\n",
            "Prediction finished: ddF6BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.78s\n",
            "Prediction finished: ddF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.51s\n",
            "Prediction finished: ddF6BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.82s\n",
            "Prediction finished: ddF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.50s\n",
            "Prediction finished: ddF6PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.84s\n",
            "Prediction finished: ddF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.45s\n",
            "Prediction finished: ddF6PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.45s\n",
            "Prediction finished: ddF6PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.45s\n",
            "Prediction finished: ddF6PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.46s\n",
            "Prediction finished: ddF6PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.46s\n",
            "Prediction finished: ddF6PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.78s\n",
            "Prediction finished: ddF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.39s\n",
            "Prediction finished: ddF6mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.67s\n",
            "Prediction finished: ddF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.39s\n",
            "Prediction finished: ddF7BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.39s\n",
            "Prediction finished: ddF7BF_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.26s\n",
            "Prediction finished: ddF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.39s\n",
            "Prediction finished: ddF7BF_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.25s\n",
            "Prediction finished: ddF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.46s\n",
            "Prediction finished: ddF7BF_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.29s\n",
            "Prediction finished: ddF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.46s\n",
            "Prediction finished: ddF7BF_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.28s\n",
            "Prediction finished: ddF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.44s\n",
            "Prediction finished: ddF7BF_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.29s\n",
            "Prediction finished: ddF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.45s\n",
            "Prediction finished: ddF7PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.29s\n",
            "Prediction finished: ddF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.39s\n",
            "Prediction finished: ddF7PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.25s\n",
            "Prediction finished: ddF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.42s\n",
            "Prediction finished: ddF7PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.38s\n",
            "Prediction finished: ddF7mCh_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.23s\n",
            "Prediction finished: ddF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.39s\n",
            "Prediction finished: ddF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.39s\n",
            "Prediction finished: ddF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.41s\n",
            "Prediction finished: ddF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.36s\n",
            "Prediction finished: ddF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.25s\n",
            "Prediction finished: ddF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.32s\n",
            "Prediction finished: ddF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: ddF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: ddF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.31s\n",
            "Prediction finished: ddF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.32s\n",
            "Prediction finished: ddF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.33s\n",
            "Prediction finished: ddF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.32s\n",
            "Prediction finished: ddF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.32s\n",
            "Prediction finished: ddF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.33s\n",
            "Prediction finished: ddF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.23s\n",
            "Prediction finished: fab1_002_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.14s\n",
            "Prediction finished: fab1_022_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 13.95s\n",
            "Prediction finished: fig4_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 13.91s\n",
            "Prediction finished: ibidi1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.41s\n",
            "Prediction finished: ibidi1out1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.42s\n",
            "Prediction finished: ibidi1out1b_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.42s\n",
            "Prediction finished: ibidi1out2_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.41s\n",
            "Prediction finished: ibidi2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.30s\n",
            "Prediction finished: ibidi2out1_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.28s\n",
            "Prediction finished: ibidi2out2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.29s\n",
            "Prediction finished: ibidi3_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 0.42s\n",
            "Prediction finished: ibidi3out1_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 0.49s\n",
            "Prediction finished: ibidi4_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 0.33s\n",
            "Prediction finished: ibidi4out1_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 0.31s\n",
            "Prediction finished: ibidi5_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.82s\n",
            "Prediction finished: ibidi5out1_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.81s\n",
            "Prediction finished: ibidi5out2_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.76s\n",
            "Prediction finished: image1_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.73s\n",
            "Prediction finished: image2_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.75s\n",
            "Prediction finished: image3_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.68s\n",
            "Prediction finished: image4_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.89s\n",
            "Prediction finished: image5_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: long1_crop_1.tiff; img size = torch.Size([1, 3, 653, 843]); costing: 1.18s\n",
            "Prediction finished: long2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.98s\n",
            "Prediction finished: long3_crop_1.tiff; img size = torch.Size([1, 3, 675, 838]); costing: 1.17s\n",
            "Prediction finished: long4_crop_1.tiff; img size = torch.Size([1, 3, 728, 890]); costing: 1.68s\n",
            "Prediction finished: m_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.61s\n",
            "Prediction finished: m_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.61s\n",
            "Prediction finished: m_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.56s\n",
            "Prediction finished: m_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.57s\n",
            "Prediction finished: m_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.58s\n",
            "Prediction finished: m_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.59s\n",
            "Prediction finished: m_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.59s\n",
            "Prediction finished: m_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.63s\n",
            "Prediction finished: m_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.73s\n",
            "Prediction finished: m_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.64s\n",
            "Prediction finished: m_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.52s\n",
            "Prediction finished: m_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.53s\n",
            "Prediction finished: m_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.53s\n",
            "Prediction finished: m_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.54s\n",
            "Prediction finished: m_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.55s\n",
            "Prediction finished: m_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.65s\n",
            "Prediction finished: m_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.67s\n",
            "Prediction finished: m_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.61s\n",
            "Prediction finished: merged_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.69s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.68s\n",
            "Prediction finished: merged_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "Prediction finished: merged_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.55s\n",
            "Prediction finished: merged_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "Prediction finished: merged_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.68s\n",
            "Prediction finished: merged_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.55s\n",
            "Prediction finished: merged_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "Prediction finished: merged_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.76s\n",
            "Prediction finished: merged_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.69s\n",
            "Prediction finished: merged_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.89s\n",
            "Prediction finished: merged_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.00s\n",
            "Prediction finished: merged_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.05s\n",
            "Prediction finished: merged_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.30s\n",
            "Prediction finished: merged_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "Prediction finished: merged_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: merged_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.70s\n",
            "Prediction finished: merged_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.79s\n",
            "Prediction finished: merged_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.82s\n",
            "Prediction finished: merged_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.73s\n",
            "Prediction finished: merged_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.75s\n",
            "Prediction finished: merged_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.05s\n",
            "Prediction finished: merged_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.04s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.85s\n",
            "Prediction finished: merged_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.90s\n",
            "Prediction finished: merged_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.77s\n",
            "Prediction finished: merged_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.74s\n",
            "Prediction finished: merged_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.73s\n",
            "Prediction finished: merged_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.75s\n",
            "Prediction finished: merged_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "Prediction finished: merged_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "Prediction finished: merged_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.79s\n",
            "Prediction finished: merged_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.69s\n",
            "Prediction finished: merged_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.77s\n",
            "Prediction finished: merged_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.81s\n",
            "Prediction finished: merged_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.76s\n",
            "Prediction finished: merged_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: merged_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.84s\n",
            "Prediction finished: merged_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.73s\n",
            "Prediction finished: pFB_s10_t25_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.29s\n",
            "Prediction finished: pFB_s1_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.32s\n",
            "Prediction finished: pFB_s4_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.35s\n",
            "Prediction finished: pFB_s5_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.25s\n",
            "Prediction finished: pFB_s6_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.33s\n",
            "Prediction finished: pFB_s8_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.36s\n",
            "Prediction finished: pFB_s9_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.34s\n",
            "Prediction finished: pMP_pos0_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.96s\n",
            "Prediction finished: pMP_pos0_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.87s\n",
            "Prediction finished: pMP_pos1_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.71s\n",
            "Prediction finished: pMP_pos1_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.49s\n",
            "Prediction finished: pMP_pos2_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.66s\n",
            "Prediction finished: pMPpos0_004_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.50s\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.76s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 15.44s\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.06s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 14.98s\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.15s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 15.18s\n",
            "Prediction finished: pSP_102_crop_1.tiff; img size = torch.Size([1, 3, 1899, 440]); costing: 1.62s\n",
            "Prediction finished: pSP_102_crop_2.tiff; img size = torch.Size([1, 3, 571, 869]); costing: 1.11s\n",
            "Prediction finished: pSP_102_crop_3.tiff; img size = torch.Size([1, 3, 401, 589]); costing: 0.48s\n",
            "Prediction finished: pSP_58_crop_1.tiff; img size = torch.Size([1, 3, 1700, 1969]); costing: 10.26s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.60s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.31s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.72s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.79s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.52s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.29s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.94s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.53s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.76s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.36s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.31s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.49s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.85s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.86s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.21s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.07s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.57s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.95s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.83s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 16.47s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 16.55s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.76s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 16.17s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.56s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.96s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.18s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.46s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.85s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.75s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.31s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.67s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.10s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.32s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 15.34s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.27s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.00s\n",
            "Prediction finished: sc472_021220_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.30s\n",
            "Prediction finished: sc472_021220_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.03s\n",
            "Prediction finished: sc472_021220_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.40s\n",
            "Prediction finished: sc472_021220_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.84s\n",
            "Prediction finished: sc472_021220_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.28s\n",
            "Prediction finished: sc472_021220_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.89s\n",
            "Prediction finished: sc472_021220_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.53s\n",
            "Prediction finished: sc472_021220_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.60s\n",
            "Prediction finished: sc472_021220_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.29s\n",
            "Prediction finished: sc472_021220_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.74s\n",
            "Prediction finished: sc472_021220_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 17.98s\n",
            "Prediction finished: sc472_021220_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 17.33s\n",
            "Prediction finished: sc472_021220_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.75s\n",
            "Prediction finished: sc472_021220_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.98s\n",
            "Prediction finished: sc472_021220_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.84s\n",
            "Prediction finished: sc472_021220_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.63s\n",
            "Prediction finished: sc472_021220_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 17.68s\n",
            "Prediction finished: sc472_021220_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.51s\n",
            "Prediction finished: sc472_021220_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.21s\n",
            "Prediction finished: sc472_021220_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.45s\n",
            "Prediction finished: sc472_021220_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.66s\n",
            "Prediction finished: sc472_021220_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.27s\n",
            "Prediction finished: sc472_021220_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.13s\n",
            "Prediction finished: sc472_021220_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.67s\n",
            "Prediction finished: sc472_300920_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.28s\n",
            "Prediction finished: sc472_300920_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.46s\n",
            "Prediction finished: sc472_300920_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.60s\n",
            "Prediction finished: sc472_300920_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.47s\n",
            "Prediction finished: sc472_300920_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.09s\n",
            "Prediction finished: sc472_300920_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.34s\n",
            "Prediction finished: sc472_300920_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.98s\n",
            "Prediction finished: sc472_300920_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.68s\n",
            "Prediction finished: sc472_300920_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.20s\n",
            "Prediction finished: sc472_300920_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.35s\n",
            "Prediction finished: sc472_300920_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.83s\n",
            "Prediction finished: sc472_300920_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.82s\n",
            "Prediction finished: sc472_300920_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.86s\n",
            "Prediction finished: sc472_300920_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.20s\n",
            "Prediction finished: sc472_300920_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.98s\n",
            "Prediction finished: sc472_300920_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.61s\n",
            "Prediction finished: sc472_300920_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.64s\n",
            "Prediction finished: sc472_300920_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.77s\n",
            "Prediction finished: sc472_300920_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.63s\n",
            "Prediction finished: sc472_300920_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.86s\n",
            "Prediction finished: sc472_300920_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.05s\n",
            "Prediction finished: sc472_300920_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.04s\n",
            "Prediction finished: sc472_300920_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.07s\n",
            "Prediction finished: sc472_300920_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.35s\n",
            "Prediction finished: sc472_300920_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.99s\n",
            "Prediction finished: small1_crop_1.tiff; img size = torch.Size([1, 3, 478, 604]); costing: 0.45s\n",
            "Prediction finished: small2_crop_1.tiff; img size = torch.Size([1, 3, 478, 652]); costing: 0.48s\n",
            "Prediction finished: small3_crop_1.tiff; img size = torch.Size([1, 3, 344, 331]); costing: 0.25s\n",
            "Prediction finished: v_cdc20null_crop_1.tiff; img size = torch.Size([1, 3, 820, 1070]); costing: 2.61s\n",
            "Prediction finished: v_clnnull_crop_1.tiff; img size = torch.Size([1, 3, 1050, 1000]); costing: 2.81s\n",
            "Prediction finished: vac14_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.30s\n",
            "Prediction finished: vac14_008_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.33s\n",
            "Prediction finished: video2out_crop_1.tiff; img size = torch.Size([1, 3, 431, 267]); costing: 0.28s\n",
            "Prediction finished: video3out_crop_1.tiff; img size = torch.Size([1, 3, 370, 568]); costing: 0.40s\n",
            "Prediction finished: wt-k699_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.17s\n",
            "Prediction finished: wt-k699_018_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.33s\n",
            "Prediction finished: wt-k699_030_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.52s\n",
            "Prediction finished: wt1_crop_1.tiff; img size = torch.Size([1, 3, 695, 650]); costing: 1.12s\n",
            "Prediction finished: wt2_crop_1.tiff; img size = torch.Size([1, 3, 1007, 800]); costing: 2.80s\n",
            "Prediction finished: wt3_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 2.47s\n",
            "Prediction finished: wt3out1_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 2.49s\n",
            "Prediction finished: wtF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.87s\n",
            "Prediction finished: wtF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.31s\n",
            "Prediction finished: wtF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.83s\n",
            "Prediction finished: wtF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 2.01s\n",
            "Prediction finished: wtF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.36s\n",
            "Prediction finished: wtF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.85s\n",
            "Prediction finished: wtF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.84s\n",
            "Prediction finished: wtF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.84s\n",
            "Prediction finished: wtF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.31s\n",
            "Prediction finished: wtF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.44s\n",
            "Prediction finished: wtF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.45s\n",
            "Prediction finished: wtF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.44s\n",
            "Prediction finished: wtF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.44s\n",
            "Prediction finished: wtF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.46s\n",
            "Prediction finished: wtF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.44s\n",
            "Prediction finished: wtF12BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.84s\n",
            "Prediction finished: wtF12BF_10_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.84s\n",
            "Prediction finished: wtF12BF_1_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.73s\n",
            "Prediction finished: wtF12BF_20_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.73s\n",
            "Prediction finished: wtF12BF_2_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.72s\n",
            "Prediction finished: wtF12BF_5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.73s\n",
            "Prediction finished: wtF13BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.33s\n",
            "Prediction finished: wtF13BF_10_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.31s\n",
            "Prediction finished: wtF13BF_1_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.32s\n",
            "Prediction finished: wtF13BF_20_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.33s\n",
            "Prediction finished: wtF13BF_2_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.32s\n",
            "Prediction finished: wtF13BF_5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.32s\n",
            "Prediction finished: wtF14BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.18s\n",
            "Prediction finished: wtF14BF_10_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.18s\n",
            "Prediction finished: wtF14BF_1_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.17s\n",
            "Prediction finished: wtF14BF_20_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.08s\n",
            "Prediction finished: wtF14BF_2_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.09s\n",
            "Prediction finished: wtF14BF_5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.08s\n",
            "Prediction finished: wtF15BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.32s\n",
            "Prediction finished: wtF15BF_10_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.31s\n",
            "Prediction finished: wtF15BF_1_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.31s\n",
            "Prediction finished: wtF15BF_20_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.32s\n",
            "Prediction finished: wtF15BF_2_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.31s\n",
            "Prediction finished: wtF15BF_5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.31s\n",
            "Prediction finished: wtF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.79s\n",
            "Prediction finished: wtF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.79s\n",
            "Prediction finished: wtF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.80s\n",
            "Prediction finished: wtF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.80s\n",
            "Prediction finished: wtF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.79s\n",
            "Prediction finished: wtF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.86s\n",
            "Prediction finished: wtF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.51s\n",
            "Prediction finished: wtF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.51s\n",
            "Prediction finished: wtF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.51s\n",
            "Prediction finished: wtF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.52s\n",
            "Prediction finished: wtF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.28s\n",
            "Prediction finished: wtF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.28s\n",
            "Prediction finished: wtF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.28s\n",
            "Prediction finished: wtF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.50s\n",
            "Prediction finished: wtF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.52s\n",
            "Prediction finished: wtF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.49s\n",
            "Prediction finished: wtF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.50s\n",
            "Prediction finished: wtF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.56s\n",
            "Prediction finished: wtF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.57s\n",
            "Prediction finished: wtF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.55s\n",
            "Prediction finished: wtF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.56s\n",
            "Prediction finished: wtF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.84s\n",
            "Prediction finished: wtF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.82s\n",
            "Prediction finished: wtF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.82s\n",
            "Prediction finished: wtF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.82s\n",
            "Prediction finished: wtF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.81s\n",
            "Prediction finished: wtF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.81s\n",
            "Prediction finished: wtF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: wtF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: wtF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wt_live003_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1459, 1459]); costing: 6.15s\n",
            "Prediction finished: z2_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 4.19s\n",
            "Prediction finished: z3_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 3.95s\n",
            "\n",
            " Total Time Cost: 3970.87s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_p1_base1218_0014.zip\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --config_path=config/step3_prediction/base_prediction.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J8lmzEH_Vom"
      },
      "source": [
        "Evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xHSpit6ZId",
        "outputId": "4cd69876-5fda-4149-962b-7f300ddfe980"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  8% 226/2869 [00:12<02:30, 17.55it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 27% 774/2869 [00:18<00:33, 61.83it/s]No segmentation results!\n",
            " 27% 781/2869 [00:18<01:13, 28.38it/s]No segmentation results!\n",
            "No segmentation results!\n",
            "No segmentation results!\n",
            " 27% 786/2869 [00:19<02:08, 16.23it/s]No segmentation results!\n",
            " 28% 793/2869 [00:20<03:26, 10.06it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20201221_LLY3752_Gal+aa_OD2_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 52% 1502/2869 [00:54<01:14, 18.37it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 7_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1927/2869 [01:44<01:34, 10.01it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1932/2869 [01:44<01:21, 11.51it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1937/2869 [01:44<01:09, 13.38it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1945/2869 [01:44<00:54, 16.81it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1953/2869 [01:44<00:43, 21.09it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1957/2869 [01:45<00:38, 23.75it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1965/2869 [01:45<00:35, 25.14it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1972/2869 [01:45<00:39, 22.57it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1978/2869 [01:46<00:46, 19.20it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1985/2869 [01:46<01:14, 11.90it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 1994/2869 [01:47<01:06, 13.25it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2005/2869 [01:48<00:58, 14.80it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2016/2869 [01:48<01:06, 12.89it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2022/2869 [01:49<01:19, 10.65it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2028/2869 [01:49<01:13, 11.46it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2035/2869 [01:50<00:48, 17.14it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2042/2869 [01:50<00:44, 18.66it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2048/2869 [01:50<00:45, 18.16it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2054/2869 [01:51<00:45, 18.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2060/2869 [01:51<00:42, 19.25it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2066/2869 [01:51<00:40, 19.98it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2072/2869 [01:51<00:29, 27.46it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2078/2869 [01:52<00:23, 33.52it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2087/2869 [01:54<01:48,  7.19it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2093/2869 [01:55<02:12,  5.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2100/2869 [01:55<01:12, 10.54it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2107/2869 [01:55<01:01, 12.39it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2113/2869 [01:56<01:07, 11.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2119/2869 [01:57<01:14, 10.12it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2126/2869 [01:57<00:53, 13.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2131/2869 [01:57<00:46, 15.82it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2138/2869 [01:57<00:33, 21.75it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2145/2869 [01:58<00:37, 19.38it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2152/2869 [01:59<01:17,  9.23it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2158/2869 [02:00<01:26,  8.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2165/2869 [02:00<00:59, 11.75it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2172/2869 [02:01<01:07, 10.37it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2178/2869 [02:01<01:26,  7.96it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2183/2869 [02:02<01:29,  7.70it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2190/2869 [02:02<00:42, 15.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2197/2869 [02:03<00:31, 21.09it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2203/2869 [02:03<00:34, 19.56it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 82% 2365/2869 [02:08<00:18, 26.79it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2374/2869 [02:08<00:15, 32.63it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2387/2869 [02:08<00:13, 35.56it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2392/2869 [02:08<00:12, 38.02it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2401/2869 [02:09<00:13, 35.21it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2413/2869 [02:09<00:14, 31.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2421/2869 [02:09<00:14, 30.85it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2430/2869 [02:10<00:12, 33.90it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2434/2869 [02:10<00:12, 33.64it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2442/2869 [02:10<00:12, 33.04it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2447/2869 [02:10<00:12, 34.64it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2456/2869 [02:10<00:11, 36.83it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2465/2869 [02:11<00:13, 29.65it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2475/2869 [02:11<00:17, 22.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2487/2869 [02:12<00:17, 21.29it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2499/2869 [02:12<00:14, 26.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2508/2869 [02:12<00:12, 29.26it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2517/2869 [02:13<00:11, 30.03it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2521/2869 [02:13<00:10, 32.11it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2529/2869 [02:13<00:09, 34.67it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 94% 2687/2869 [02:41<02:05,  1.45it/s]No segmentation results!\n",
            " 94% 2689/2869 [02:42<02:03,  1.46it/s]No segmentation results!\n",
            " 94% 2691/2869 [02:43<01:58,  1.51it/s]No segmentation results!\n",
            " 94% 2696/2869 [02:45<01:01,  2.82it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc1_972_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc313_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc370_wee1-50_4h_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2780/2869 [03:47<00:18,  4.93it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2787/2869 [03:47<00:07, 11.02it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2795/2869 [03:47<00:03, 19.00it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF12BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2801/2869 [03:48<00:03, 18.31it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF13BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2806/2869 [03:48<00:02, 24.30it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF14BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2812/2869 [03:48<00:02, 21.12it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF15BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2817/2869 [03:48<00:01, 26.86it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2825/2869 [03:49<00:01, 27.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2829/2869 [03:49<00:01, 29.30it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2838/2869 [03:49<00:00, 33.42it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2843/2869 [03:49<00:00, 36.56it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2847/2869 [03:49<00:00, 34.75it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2855/2869 [03:49<00:00, 31.84it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2859/2869 [03:50<00:00, 30.63it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2869/2869 [03:51<00:00, 12.42it/s]\n",
            "mean F1 Score: 0.7976438693098384 +/- 0.004924061546026901\n",
            "mean AP Score: 0.7267010646108664 +/- 0.005751133675645321\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=results/mediar_base_prediction --gt_path=Datasets/labels --save_path=evaluation_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOoKdnByXovz"
      },
      "source": [
        "Ensemble model\n",
        "\n",
        "Note: this corresponds to Ensemble(P1,P1FT)+TTA model in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0VZrsX_DXb1",
        "outputId": "c15f20a0-6375-4fa9-accb-8adb064a4099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'device': 'cuda:0',\n",
            "                 'exp_name': 'mediar_ensemble_tta',\n",
            "                 'input_path': 'Datasets/images',\n",
            "                 'make_submission': True,\n",
            "                 'model': {'name': 'mediar-former',\n",
            "                           'params': {'classes': 3,\n",
            "                                      'decoder_channels': [1024, 512, 256, 128,\n",
            "                                                           64],\n",
            "                                      'decoder_pab_channels': 256,\n",
            "                                      'encoder_name': 'mit_b5',\n",
            "                                      'in_channels': 3}},\n",
            "                 'model_path1': './weights/from_phase1.pth',\n",
            "                 'model_path2': './weights/from_phase2.pth',\n",
            "                 'name': 'ensemble_mediar',\n",
            "                 'output_path': './results/mediar_ensemble_tta'}}\n",
            "========================================================================================================================\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 10_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 10_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 11_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 11_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 12_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 12_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 13_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 13_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 14_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 14_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 16_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 16_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 170922_ageing-pos37-ch1-60ph-001_crop_1.tiff\n",
            "Prediction already done for 170922_ageing-pos37-ch1-60ph-051_crop_1.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_0.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_1.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_10.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_11.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_12.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_13.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_2.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_3.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_4.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_5.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_6.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_7.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_8.tiff\n",
            "Prediction already done for 1_Ref_Zstack_DIC_crop_1_frame_9.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_0.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_1.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_10.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_11.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_12.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_13.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_2.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_3.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_4.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_5.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_6.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_7.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_8.tiff\n",
            "Prediction already done for 1_Ref_Zstack_TL_crop_1_frame_9.tiff\n",
            "Prediction already done for 1_crop_1.tiff\n",
            "Prediction already done for 1out1_crop_1.tiff\n",
            "Prediction already done for 1out2_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f10_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f11_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f12_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f13_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f1_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f2_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f3_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f4_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f5_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f6_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f7_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f8_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f9_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f10_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f11_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f12_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f13_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f1_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f2_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f3_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f4_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f5_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f6_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f7_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f8_crop_1.tiff\n",
            "Prediction already done for 200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f9_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1.tiff\n",
            "Prediction already done for 200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_0.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_10.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_100.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_101.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_102.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_103.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_104.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_105.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_106.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_107.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_108.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_109.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_11.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_110.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_111.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_112.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_113.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_114.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_115.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_116.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_117.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_118.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_119.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_12.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_120.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_13.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_14.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_15.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_16.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_17.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_18.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_19.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_2.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_20.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_21.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_22.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_23.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_24.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_25.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_26.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_27.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_28.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_29.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_3.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_30.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_31.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_32.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_33.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_34.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_35.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_36.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_37.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_38.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_39.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_4.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_40.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_41.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_42.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_43.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_44.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_45.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_46.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_47.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_48.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_49.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_5.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_50.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_51.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_52.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_53.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_54.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_55.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_56.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_57.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_58.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_59.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_6.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_60.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_61.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_62.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_63.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_64.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_65.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_66.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_67.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_68.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_69.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_7.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_70.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_71.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_72.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_73.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_74.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_75.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_76.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_77.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_78.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_79.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_8.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_80.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_81.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_82.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_83.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_84.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_85.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_86.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_87.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_88.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_89.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_9.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_90.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_91.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_92.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_93.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_94.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_95.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_96.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_97.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_98.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(1)_crop_1_frame_99.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_0.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_10.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_100.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_101.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_102.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_103.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_104.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_105.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_106.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_107.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_108.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_109.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_11.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_110.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_111.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_112.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_113.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_114.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_115.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_116.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_117.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_118.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_119.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_12.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_120.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_13.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_14.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_15.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_16.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_17.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_18.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_19.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_2.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_20.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_21.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_22.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_23.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_24.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_25.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_26.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_27.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_28.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_29.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_3.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_30.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_31.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_32.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_33.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_34.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_35.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_36.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_37.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_38.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_39.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_4.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_40.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_41.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_42.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_43.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_44.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_45.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_46.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_47.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_48.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_49.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_5.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_50.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_51.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_52.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_53.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_54.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_55.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_56.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_57.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_58.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_59.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_6.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_60.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_61.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_62.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_63.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_64.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_65.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_66.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_67.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_68.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_69.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_7.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_70.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_71.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_72.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_73.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_74.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_75.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_76.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_77.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_78.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_79.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_8.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_80.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_81.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_82.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_83.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_84.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_85.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_86.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_87.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_88.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_89.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_9.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_90.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_91.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_92.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_93.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_94.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_95.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_96.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_97.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_98.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(3)_crop_1_frame_99.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_0.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_10.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_100.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_101.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_102.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_103.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_104.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_105.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_106.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_107.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_108.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_109.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_11.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_110.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_111.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_112.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_113.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_114.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_115.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_116.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_117.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_118.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_119.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_12.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_120.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_13.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_14.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_15.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_16.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_17.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_18.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_19.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_2.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_20.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_21.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_22.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_23.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_24.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_25.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_26.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_27.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_28.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_29.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_3.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_30.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_31.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_32.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_33.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_34.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_35.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_36.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_37.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_38.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_39.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_4.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_40.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_41.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_42.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_43.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_44.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_45.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_46.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_47.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_48.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_49.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_5.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_50.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_51.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_52.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_53.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_54.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_55.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_56.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_57.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_58.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_59.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_6.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_60.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_61.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_62.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_63.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_64.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_65.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_66.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_67.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_68.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_69.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_7.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_70.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_71.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_72.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_73.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_74.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_75.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_76.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_77.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_78.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_79.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_8.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_80.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_81.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_82.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_83.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_84.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_85.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_86.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_87.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_88.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_89.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_9.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_90.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_91.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_92.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_93.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_94.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_95.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_96.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_97.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_98.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(4)_crop_1_frame_99.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_0.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_10.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_100.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_101.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_102.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_103.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_104.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_105.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_106.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_107.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_108.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_109.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_11.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_110.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_111.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_112.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_113.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_114.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_115.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_116.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_117.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_118.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_119.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_12.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_120.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_13.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_14.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_15.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_16.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_17.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_18.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_19.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_2.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_20.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_21.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_22.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_23.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_24.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_25.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_26.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_27.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_28.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_29.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_3.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_30.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_31.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_32.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_33.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_34.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_35.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_36.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_37.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_38.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_39.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_4.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_40.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_41.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_42.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_43.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_44.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_45.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_46.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_47.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_48.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_49.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_5.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_50.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_51.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_52.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_53.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_54.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_55.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_56.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_57.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_58.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_59.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_6.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_60.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_61.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_62.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_63.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_64.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_65.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_66.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_67.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_68.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_69.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_7.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_70.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_71.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_72.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_73.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_74.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_75.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_76.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_77.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_78.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_79.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_8.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_80.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_81.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_82.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_83.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_84.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_85.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_86.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_87.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_88.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_89.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_9.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_90.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_91.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_92.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_93.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_94.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_95.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_96.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_97.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_98.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(5)_crop_1_frame_99.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_0.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_1.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_2.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_3.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_4.tiff\n",
            "Prediction already done for 200917_JK_MS133-0003_Position(6)_crop_1_frame_5.tiff\n",
            "Prediction already done for 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_0.tiff\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.98s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 15.31s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.77s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.96s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.33s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.93s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.63s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.33s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 13.65s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t100_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.22s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t150_modified_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.12s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t1_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.16s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t200_modified_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.52s\n",
            "Prediction finished: 2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t50_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.42s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.11s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 14.87s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 14.90s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.05s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.07s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.43s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_MINUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.21s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_PLUS_10S_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.01s\n",
            "Prediction finished: 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D.dv_MID_crop_1.tiff; img size = torch.Size([1, 3, 924, 924]); costing: 15.18s\n",
            "Prediction finished: 20201221_LLY3752_Gal+aa_OD2.08_60x_concdZ5XY54C1_crop_1.tiff; img size = torch.Size([1, 3, 2060, 2260]); costing: 82.96s\n",
            "Prediction finished: 20201221_LLY3752_Gal+aa_OD2.08_60x_concdZ5XY55C1_crop_1.tiff; img size = torch.Size([1, 3, 2060, 2260]); costing: 81.93s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 1.05s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 1.06s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 1.04s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 1.04s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 350, 400]); costing: 1.09s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 1.05s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 1.06s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 1.03s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 1.01s\n",
            "Prediction finished: 2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 256, 300]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_01_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 1.03s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_03_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 1.04s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: 210308_SW646_Asymmetric01_4_04_crop_1.tiff; img size = torch.Size([1, 3, 335, 273]); costing: 1.05s\n",
            "Prediction finished: 210311_SW646_AsymmetricAfternoon01_3_crop_1.tiff; img size = torch.Size([1, 3, 628, 597]); costing: 3.68s\n",
            "Prediction finished: 210521_Ncdc13_01_01_01_01_crop_1.tiff; img size = torch.Size([1, 3, 948, 810]); costing: 10.99s\n",
            "Prediction finished: 210521_Ncdc13_01_01_01_02_crop_1.tiff; img size = torch.Size([1, 3, 704, 820]); costing: 5.67s\n",
            "Prediction finished: 210521_Ncdc13_01_01_02_02_crop_1.tiff; img size = torch.Size([1, 3, 276, 304]); costing: 1.05s\n",
            "Prediction finished: 210521_Ncdc13_01_01_03_01_crop_1.tiff; img size = torch.Size([1, 3, 308, 636]); costing: 1.93s\n",
            "Prediction finished: 210521_Ncdc13_01_01_07_01_crop_1.tiff; img size = torch.Size([1, 3, 388, 482]); costing: 1.09s\n",
            "Prediction finished: 210521_Ncdc13_01_01_08_01_crop_1.tiff; img size = torch.Size([1, 3, 332, 418]); costing: 1.07s\n",
            "Prediction finished: 210521_Ncdc13_01_01_08_02_crop_1.tiff; img size = torch.Size([1, 3, 312, 464]); costing: 1.08s\n",
            "Prediction finished: 23_fm464_live095_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1434, 1434]); costing: 32.09s\n",
            "Prediction finished: 23_fm464_live098_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1459, 1459]); costing: 31.80s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.20s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.19s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.20s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.20s\n",
            "Prediction finished: 2_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 2_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 5.60s\n",
            "Prediction finished: 2out1_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 5.64s\n",
            "Prediction finished: 2out2_crop_1.tiff; img size = torch.Size([1, 3, 592, 760]); costing: 5.58s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_10_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.23s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.29s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.28s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_11_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.26s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.26s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_11_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_12_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_12_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.23s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_13_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_13_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.07s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.07s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.07s\n",
            "Prediction finished: 3306_pad1_14_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_15_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_15_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_16_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_16_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_17_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_17_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.23s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_18_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_19_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_1_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.29s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.25s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_20_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.25s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.25s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_20_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_21_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_22_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_22_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.23s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_23_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_24_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_24_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_25_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.23s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_25_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.25s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_2_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.22s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_2_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_3_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_3_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_4_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.14s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_4_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_5_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.08s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_5_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_6_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_6_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.20s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.19s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.12s\n",
            "Prediction finished: 3306_pad1_7_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.17s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.15s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.13s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.21s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.18s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.10s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.11s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.09s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 1.16s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 3_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 7.47s\n",
            "Prediction finished: 3out1_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 7.35s\n",
            "Prediction finished: 3out2_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 7.35s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.18s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 4_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 5.66s\n",
            "Prediction finished: 4out1_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 5.57s\n",
            "Prediction finished: 4out2_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 5.66s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.19s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.19s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.19s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 5_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.24s\n",
            "Prediction finished: 5out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.26s\n",
            "Prediction finished: 5out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.28s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 6_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.70s\n",
            "Prediction finished: 6out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.74s\n",
            "Prediction finished: 6out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.72s\n",
            "Prediction finished: 7.5.2018_tp50_pos03_crop_1.tiff; img size = torch.Size([1, 3, 512, 500]); costing: 1.16s\n",
            "Prediction finished: 7.5.2018_tp50_pos06_crop_1.tiff; img size = torch.Size([1, 3, 512, 505]); costing: 1.09s\n",
            "Prediction finished: 7.5.2018_tp50_pos08_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.08s\n",
            "Prediction finished: 7.5.2018_tp50_pos09_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.16s\n",
            "Prediction finished: 7.5.2018_tp50_pos10_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.20s\n",
            "Prediction finished: 7.5.2018_tp50_pos21_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.16s\n",
            "Prediction finished: 7.5.2018_tp50_pos28_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.10s\n",
            "Prediction finished: 7.5.2018_tp50_pos32_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 7_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 8.29s\n",
            "Prediction finished: 7out1_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 8.40s\n",
            "Prediction finished: 7out2_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 8.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.16s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.18s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.17s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 8_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 11.05s\n",
            "Prediction finished: 8out1_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 10.94s\n",
            "Prediction finished: 8out2_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 10.90s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.13s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.11s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.12s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.07s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.09s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.08s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.14s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.15s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 1.10s\n",
            "Prediction finished: Abf1_Ancestor_5_z24_BF_crop_1.tiff; img size = torch.Size([1, 3, 958, 918]); costing: 11.16s\n",
            "Prediction finished: Abf1_Ancestor_6_z23_BF_crop_1.tiff; img size = torch.Size([1, 3, 730, 958]); costing: 11.33s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_1.tiff; img size = torch.Size([1, 3, 953, 650]); costing: 7.63s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_2.tiff; img size = torch.Size([1, 3, 678, 308]); costing: 2.00s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 3.75s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 3.71s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 3.70s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 3.72s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 3.74s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_0.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 5.39s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_1.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 5.42s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_2.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 5.44s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_3.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 5.42s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_4.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 5.52s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 14.04s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 14.01s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 14.04s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 14.06s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 14.08s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 1.92s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 1.93s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 1.99s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 1.94s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 1.93s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 1.05s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 1.06s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 1.06s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 1.06s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 1.06s\n",
            "Prediction finished: MS183_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.63s\n",
            "Prediction finished: MS183_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.85s\n",
            "Prediction finished: MS183_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 72.06s\n",
            "Prediction finished: MS183_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 72.46s\n",
            "Prediction finished: MS183_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 72.20s\n",
            "Prediction finished: MS183_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.88s\n",
            "Prediction finished: MS183_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.73s\n",
            "Prediction finished: MS183_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.67s\n",
            "Prediction finished: MS183_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 71.97s\n",
            "Prediction finished: PN1192_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 62.95s\n",
            "Prediction finished: PN1192_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 61.05s\n",
            "Prediction finished: PN1192_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 63.95s\n",
            "Prediction finished: PN1192_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 63.07s\n",
            "Prediction finished: PN1192_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 64.63s\n",
            "Prediction finished: PN1192_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 63.51s\n",
            "Prediction finished: PN1192_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 58.32s\n",
            "Prediction finished: PN19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 77.44s\n",
            "Prediction finished: PN19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 75.18s\n",
            "Prediction finished: PN19_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 74.10s\n",
            "Prediction finished: PN19_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 75.16s\n",
            "Prediction finished: PN19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 75.75s\n",
            "Prediction finished: PN19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 78.67s\n",
            "Prediction finished: PN19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 78.61s\n",
            "Prediction finished: PN19_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 79.43s\n",
            "Prediction finished: PN19_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 74.83s\n",
            "Prediction finished: PN19_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 73.46s\n",
            "Prediction finished: PN19_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 74.82s\n",
            "Prediction finished: PN19_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 74.14s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.45s\n",
            "Prediction finished: Schmoller_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.38s\n",
            "Prediction finished: Schmoller_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.46s\n",
            "Prediction finished: Schmoller_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.39s\n",
            "Prediction finished: Schmoller_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.44s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.41s\n",
            "Prediction finished: Schmoller_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.40s\n",
            "Prediction finished: Schmoller_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.33s\n",
            "Prediction finished: Schmoller_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.40s\n",
            "Prediction finished: Schmoller_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.40s\n",
            "Prediction finished: Schmoller_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.38s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.47s\n",
            "Prediction finished: Schmoller_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.38s\n",
            "Prediction finished: Schmoller_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.39s\n",
            "Prediction finished: Schmoller_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.45s\n",
            "Prediction finished: Schmoller_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "Prediction finished: Schmoller_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.38s\n",
            "Prediction finished: Schmoller_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.33s\n",
            "Prediction finished: Schmoller_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.32s\n",
            "Prediction finished: Schmoller_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.44s\n",
            "Prediction finished: Schmoller_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "Prediction finished: Schmoller_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.39s\n",
            "Prediction finished: Schmoller_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "Prediction finished: Schmoller_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.39s\n",
            "Prediction finished: Schmoller_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "Prediction finished: Schmoller_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.39s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.47s\n",
            "Prediction finished: Schmoller_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.44s\n",
            "Prediction finished: Schmoller_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.44s\n",
            "Prediction finished: Schmoller_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.33s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.42s\n",
            "Prediction finished: Schmoller_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.32s\n",
            "Prediction finished: Schmoller_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.43s\n",
            "Prediction finished: Schmoller_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.44s\n",
            "Prediction finished: Schmoller_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.36s\n",
            "Prediction finished: Schmoller_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.45s\n",
            "Prediction finished: Schmoller_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.35s\n",
            "Prediction finished: Schmoller_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.34s\n",
            "Prediction finished: Schmoller_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.41s\n",
            "Prediction finished: Schmoller_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.37s\n",
            "Prediction finished: Schmoller_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.40s\n",
            "Prediction finished: Schmoller_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 5.33s\n",
            "Prediction finished: V11032020_p1_crop_1.tiff; img size = torch.Size([1, 3, 410, 360]); costing: 1.07s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 3.65s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 3.70s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 3.67s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 3.68s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 3.75s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 3.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.61s\n",
            "Prediction finished: a_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.61s\n",
            "Prediction finished: a_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.60s\n",
            "Prediction finished: a_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.61s\n",
            "Prediction finished: a_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.66s\n",
            "Prediction finished: a_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.61s\n",
            "Prediction finished: a_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.66s\n",
            "Prediction finished: a_reexport1_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.61s\n",
            "Prediction finished: a_reexport1_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.63s\n",
            "Prediction finished: a_reexport1_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.64s\n",
            "Prediction finished: a_reexport1_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.60s\n",
            "Prediction finished: a_reexport1_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.65s\n",
            "Prediction finished: a_reexport1_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.66s\n",
            "Prediction finished: a_reexport1_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.66s\n",
            "Prediction finished: a_reexport1_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.60s\n",
            "Prediction finished: a_reexport1_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 3.62s\n",
            "Prediction finished: a_reexport2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.89s\n",
            "Prediction finished: a_reexport2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.93s\n",
            "Prediction finished: a_reexport2_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.90s\n",
            "Prediction finished: a_reexport2_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.87s\n",
            "Prediction finished: a_reexport2_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.89s\n",
            "Prediction finished: a_reexport2_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.89s\n",
            "Prediction finished: a_reexport2_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.87s\n",
            "Prediction finished: a_reexport2_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.90s\n",
            "Prediction finished: a_reexport2_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.87s\n",
            "Prediction finished: a_reexport2_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.94s\n",
            "Prediction finished: a_reexport2_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.90s\n",
            "Prediction finished: a_reexport2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.87s\n",
            "Prediction finished: a_reexport2_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.90s\n",
            "Prediction finished: a_reexport2_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.95s\n",
            "Prediction finished: a_reexport2_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.97s\n",
            "Prediction finished: a_reexport2_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.97s\n",
            "Prediction finished: a_reexport2_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.97s\n",
            "Prediction finished: a_reexport2_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.89s\n",
            "Prediction finished: a_reexport2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.90s\n",
            "Prediction finished: a_reexport2_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.91s\n",
            "Prediction finished: a_reexport2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.88s\n",
            "Prediction finished: a_reexport2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.86s\n",
            "Prediction finished: a_reexport2_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.87s\n",
            "Prediction finished: a_reexport2_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "Prediction finished: a_reexport2_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 1.92s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 10.52s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 10.38s\n",
            "Prediction finished: alk1alk2_001_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 78.34s\n",
            "Prediction finished: alk1alk2_011_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.97s\n",
            "Prediction finished: bendy1_crop_1.tiff; img size = torch.Size([1, 3, 692, 937]); costing: 7.27s\n",
            "Prediction finished: bendy2_crop_1.tiff; img size = torch.Size([1, 3, 541, 812]); costing: 5.45s\n",
            "Prediction finished: cdc20F10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.13s\n",
            "Prediction finished: cdc20F10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.12s\n",
            "Prediction finished: cdc20F10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.12s\n",
            "Prediction finished: cdc20F10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.13s\n",
            "Prediction finished: cdc20F10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.13s\n",
            "Prediction finished: cdc20F10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.12s\n",
            "Prediction finished: cdc20F10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.13s\n",
            "Prediction finished: cdc20F10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.14s\n",
            "Prediction finished: cdc20F10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.19s\n",
            "Prediction finished: cdc20F10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.19s\n",
            "Prediction finished: cdc20F10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.15s\n",
            "Prediction finished: cdc20F10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.14s\n",
            "Prediction finished: cdc20F10mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 1.05s\n",
            "Prediction finished: cdc20F1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.10s\n",
            "Prediction finished: cdc20F1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.08s\n",
            "Prediction finished: cdc20F1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.08s\n",
            "Prediction finished: cdc20F1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.13s\n",
            "Prediction finished: cdc20F1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.14s\n",
            "Prediction finished: cdc20F1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.11s\n",
            "Prediction finished: cdc20F1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.08s\n",
            "Prediction finished: cdc20F1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.05s\n",
            "Prediction finished: cdc20F2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.08s\n",
            "Prediction finished: cdc20F2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.08s\n",
            "Prediction finished: cdc20F2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.14s\n",
            "Prediction finished: cdc20F2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.15s\n",
            "Prediction finished: cdc20F2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.16s\n",
            "Prediction finished: cdc20F2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.11s\n",
            "Prediction finished: cdc20F2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.10s\n",
            "Prediction finished: cdc20F2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.09s\n",
            "Prediction finished: cdc20F2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.10s\n",
            "Prediction finished: cdc20F2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.10s\n",
            "Prediction finished: cdc20F2mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 1.04s\n",
            "Prediction finished: cdc20F3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.96s\n",
            "Prediction finished: cdc20F3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 2.03s\n",
            "Prediction finished: cdc20F3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 2.02s\n",
            "Prediction finished: cdc20F3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.99s\n",
            "Prediction finished: cdc20F3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.97s\n",
            "Prediction finished: cdc20F3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.97s\n",
            "Prediction finished: cdc20F3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.98s\n",
            "Prediction finished: cdc20F3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.98s\n",
            "Prediction finished: cdc20F3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 2.02s\n",
            "Prediction finished: cdc20F3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 2.00s\n",
            "Prediction finished: cdc20F3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.97s\n",
            "Prediction finished: cdc20F3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.97s\n",
            "Prediction finished: cdc20F3mCh_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 1.88s\n",
            "Prediction finished: cdc20F4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.30s\n",
            "Prediction finished: cdc20F4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.41s\n",
            "Prediction finished: cdc20F4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.28s\n",
            "Prediction finished: cdc20F4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.27s\n",
            "Prediction finished: cdc20F4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.28s\n",
            "Prediction finished: cdc20F4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.29s\n",
            "Prediction finished: cdc20F4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.34s\n",
            "Prediction finished: cdc20F4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.33s\n",
            "Prediction finished: cdc20F4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.31s\n",
            "Prediction finished: cdc20F4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.38s\n",
            "Prediction finished: cdc20F4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.33s\n",
            "Prediction finished: cdc20F4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.37s\n",
            "Prediction finished: cdc20F4mCh_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 8.16s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.04s\n",
            "Prediction finished: cdc20F5BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.23s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.04s\n",
            "Prediction finished: cdc20F5BF_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.27s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.06s\n",
            "Prediction finished: cdc20F5BF_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.17s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.07s\n",
            "Prediction finished: cdc20F5BF_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.10s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.07s\n",
            "Prediction finished: cdc20F5BF_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.01s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.05s\n",
            "Prediction finished: cdc20F5BF_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.03s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.07s\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.09s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.03s\n",
            "Prediction finished: cdc20F5PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.08s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.03s\n",
            "Prediction finished: cdc20F5PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.06s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.03s\n",
            "Prediction finished: cdc20F5PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.14s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.03s\n",
            "Prediction finished: cdc20F5PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.11s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.02s\n",
            "Prediction finished: cdc20F5PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 11.10s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 1.00s\n",
            "Prediction finished: cdc20F5mCh_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 10.63s\n",
            "Prediction finished: cdc20F6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.46s\n",
            "Prediction finished: cdc20F6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.35s\n",
            "Prediction finished: cdc20F6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.29s\n",
            "Prediction finished: cdc20F6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.51s\n",
            "Prediction finished: cdc20F6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.40s\n",
            "Prediction finished: cdc20F6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.35s\n",
            "Prediction finished: cdc20F6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.58s\n",
            "Prediction finished: cdc20F6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.47s\n",
            "Prediction finished: cdc20F6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.43s\n",
            "Prediction finished: cdc20F6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.55s\n",
            "Prediction finished: cdc20F6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.39s\n",
            "Prediction finished: cdc20F6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.38s\n",
            "Prediction finished: cdc20F6mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 8.19s\n",
            "Prediction finished: cdc20F7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.75s\n",
            "Prediction finished: cdc20F7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.72s\n",
            "Prediction finished: cdc20F7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.71s\n",
            "Prediction finished: cdc20F7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.72s\n",
            "Prediction finished: cdc20F7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.71s\n",
            "Prediction finished: cdc20F7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.71s\n",
            "Prediction finished: cdc20F7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.79s\n",
            "Prediction finished: cdc20F7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.74s\n",
            "Prediction finished: cdc20F7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.73s\n",
            "Prediction finished: cdc20F7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.76s\n",
            "Prediction finished: cdc20F7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.74s\n",
            "Prediction finished: cdc20F7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.76s\n",
            "Prediction finished: cdc20F7mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 3.60s\n",
            "Prediction finished: cdc20F8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.57s\n",
            "Prediction finished: cdc20F8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.57s\n",
            "Prediction finished: cdc20F8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.66s\n",
            "Prediction finished: cdc20F8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.60s\n",
            "Prediction finished: cdc20F8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.69s\n",
            "Prediction finished: cdc20F8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.58s\n",
            "Prediction finished: cdc20F8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.61s\n",
            "Prediction finished: cdc20F8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.61s\n",
            "Prediction finished: cdc20F8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.60s\n",
            "Prediction finished: cdc20F8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.61s\n",
            "Prediction finished: cdc20F8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.60s\n",
            "Prediction finished: cdc20F8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.69s\n",
            "Prediction finished: cdc20F8mCh_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 5.38s\n",
            "Prediction finished: cdc20F9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.80s\n",
            "Prediction finished: cdc20F9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.89s\n",
            "Prediction finished: cdc20F9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.82s\n",
            "Prediction finished: cdc20F9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.81s\n",
            "Prediction finished: cdc20F9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.89s\n",
            "Prediction finished: cdc20F9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.82s\n",
            "Prediction finished: cdc20F9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.81s\n",
            "Prediction finished: cdc20F9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.83s\n",
            "Prediction finished: cdc20F9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.83s\n",
            "Prediction finished: cdc20F9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.83s\n",
            "Prediction finished: cdc20F9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.82s\n",
            "Prediction finished: cdc20F9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.91s\n",
            "Prediction finished: cdc20F9mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 3.65s\n",
            "Prediction finished: clnF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.09s\n",
            "Prediction finished: clnF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.08s\n",
            "Prediction finished: clnF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.08s\n",
            "Prediction finished: clnF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.09s\n",
            "Prediction finished: clnF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.10s\n",
            "Prediction finished: clnF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.09s\n",
            "Prediction finished: clnF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.15s\n",
            "Prediction finished: clnF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.15s\n",
            "Prediction finished: clnF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.11s\n",
            "Prediction finished: clnF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.10s\n",
            "Prediction finished: clnF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.09s\n",
            "Prediction finished: clnF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.10s\n",
            "Prediction finished: clnF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 1.08s\n",
            "Prediction finished: clnF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.51s\n",
            "Prediction finished: clnF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.28s\n",
            "Prediction finished: clnF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.33s\n",
            "Prediction finished: clnF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.40s\n",
            "Prediction finished: clnF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.51s\n",
            "Prediction finished: clnF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.34s\n",
            "Prediction finished: clnF11PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.24s\n",
            "Prediction finished: clnF11PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.24s\n",
            "Prediction finished: clnF11PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.34s\n",
            "Prediction finished: clnF11PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.33s\n",
            "Prediction finished: clnF11PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.27s\n",
            "Prediction finished: clnF11PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.44s\n",
            "Prediction finished: clnF11mCh_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 27.53s\n",
            "Prediction finished: clnF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.81s\n",
            "Prediction finished: clnF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.81s\n",
            "Prediction finished: clnF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.88s\n",
            "Prediction finished: clnF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.83s\n",
            "Prediction finished: clnF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.80s\n",
            "Prediction finished: clnF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.88s\n",
            "Prediction finished: clnF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.85s\n",
            "Prediction finished: clnF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.82s\n",
            "Prediction finished: clnF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.83s\n",
            "Prediction finished: clnF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.86s\n",
            "Prediction finished: clnF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.82s\n",
            "Prediction finished: clnF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.83s\n",
            "Prediction finished: clnF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 3.72s\n",
            "Prediction finished: clnF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.95s\n",
            "Prediction finished: clnF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.98s\n",
            "Prediction finished: clnF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.95s\n",
            "Prediction finished: clnF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.93s\n",
            "Prediction finished: clnF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.96s\n",
            "Prediction finished: clnF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 11.08s\n",
            "Prediction finished: clnF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 11.12s\n",
            "Prediction finished: clnF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.98s\n",
            "Prediction finished: clnF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 11.00s\n",
            "Prediction finished: clnF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.96s\n",
            "Prediction finished: clnF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.99s\n",
            "Prediction finished: clnF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.98s\n",
            "Prediction finished: clnF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 10.86s\n",
            "Prediction finished: clnF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.76s\n",
            "Prediction finished: clnF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.76s\n",
            "Prediction finished: clnF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.81s\n",
            "Prediction finished: clnF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.79s\n",
            "Prediction finished: clnF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.77s\n",
            "Prediction finished: clnF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.77s\n",
            "Prediction finished: clnF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.79s\n",
            "Prediction finished: clnF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.81s\n",
            "Prediction finished: clnF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.78s\n",
            "Prediction finished: clnF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.89s\n",
            "Prediction finished: clnF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.78s\n",
            "Prediction finished: clnF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.79s\n",
            "Prediction finished: clnF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 3.83s\n",
            "Prediction finished: clnF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.99s\n",
            "Prediction finished: clnF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.95s\n",
            "Prediction finished: clnF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.96s\n",
            "Prediction finished: clnF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.96s\n",
            "Prediction finished: clnF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.95s\n",
            "Prediction finished: clnF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 2.01s\n",
            "Prediction finished: clnF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 2.02s\n",
            "Prediction finished: clnF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.96s\n",
            "Prediction finished: clnF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.95s\n",
            "Prediction finished: clnF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.96s\n",
            "Prediction finished: clnF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.96s\n",
            "Prediction finished: clnF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.97s\n",
            "Prediction finished: clnF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 1.94s\n",
            "Prediction finished: clnF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.52s\n",
            "Prediction finished: clnF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.50s\n",
            "Prediction finished: clnF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.67s\n",
            "Prediction finished: clnF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.55s\n",
            "Prediction finished: clnF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.51s\n",
            "Prediction finished: clnF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.65s\n",
            "Prediction finished: clnF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.58s\n",
            "Prediction finished: clnF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.61s\n",
            "Prediction finished: clnF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.72s\n",
            "Prediction finished: clnF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.59s\n",
            "Prediction finished: clnF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.58s\n",
            "Prediction finished: clnF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.75s\n",
            "Prediction finished: clnF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 8.21s\n",
            "Prediction finished: clnF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.24s\n",
            "Prediction finished: clnF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.34s\n",
            "Prediction finished: clnF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.25s\n",
            "Prediction finished: clnF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.26s\n",
            "Prediction finished: clnF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.36s\n",
            "Prediction finished: clnF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.24s\n",
            "Prediction finished: clnF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.28s\n",
            "Prediction finished: clnF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.29s\n",
            "Prediction finished: clnF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.27s\n",
            "Prediction finished: clnF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.28s\n",
            "Prediction finished: clnF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.28s\n",
            "Prediction finished: clnF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.29s\n",
            "Prediction finished: clnF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 8.38s\n",
            "Prediction finished: clnF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.91s\n",
            "Prediction finished: clnF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.95s\n",
            "Prediction finished: clnF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.92s\n",
            "Prediction finished: clnF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.92s\n",
            "Prediction finished: clnF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 15.02s\n",
            "Prediction finished: clnF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.92s\n",
            "Prediction finished: clnF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 15.17s\n",
            "Prediction finished: clnF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.97s\n",
            "Prediction finished: clnF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.97s\n",
            "Prediction finished: clnF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 15.00s\n",
            "Prediction finished: clnF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 15.01s\n",
            "Prediction finished: clnF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 15.02s\n",
            "Prediction finished: clnF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 14.87s\n",
            "Prediction finished: clnF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.99s\n",
            "Prediction finished: clnF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.98s\n",
            "Prediction finished: clnF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.97s\n",
            "Prediction finished: clnF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.98s\n",
            "Prediction finished: clnF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.96s\n",
            "Prediction finished: clnF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 2.04s\n",
            "Prediction finished: clnF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 2.01s\n",
            "Prediction finished: clnF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.99s\n",
            "Prediction finished: clnF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.99s\n",
            "Prediction finished: clnF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.99s\n",
            "Prediction finished: clnF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 2.00s\n",
            "Prediction finished: clnF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 2.04s\n",
            "Prediction finished: clnF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 1.92s\n",
            "Prediction finished: clnF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.95s\n",
            "Prediction finished: clnF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.95s\n",
            "Prediction finished: clnF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 4.03s\n",
            "Prediction finished: clnF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.97s\n",
            "Prediction finished: clnF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.92s\n",
            "Prediction finished: clnF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 4.05s\n",
            "Prediction finished: clnF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.96s\n",
            "Prediction finished: clnF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.96s\n",
            "Prediction finished: clnF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 4.06s\n",
            "Prediction finished: clnF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.98s\n",
            "Prediction finished: clnF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.96s\n",
            "Prediction finished: clnF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.98s\n",
            "Prediction finished: clnF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 3.85s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.08s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.06s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.03s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.08s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.09s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.09s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 1.01s\n",
            "Prediction finished: d_reexport1_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.07s\n",
            "Prediction finished: d_reexport1_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.07s\n",
            "Prediction finished: d_reexport1_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.15s\n",
            "Prediction finished: d_reexport1_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.16s\n",
            "Prediction finished: d_reexport1_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.09s\n",
            "Prediction finished: d_reexport1_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.11s\n",
            "Prediction finished: d_reexport1_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.11s\n",
            "Prediction finished: d_reexport1_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.16s\n",
            "Prediction finished: d_reexport1_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.17s\n",
            "Prediction finished: d_reexport1_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.07s\n",
            "Prediction finished: d_reexport1_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.13s\n",
            "Prediction finished: d_reexport1_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.05s\n",
            "Prediction finished: d_reexport1_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.05s\n",
            "Prediction finished: d_reexport1_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.06s\n",
            "Prediction finished: d_reexport1_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.05s\n",
            "Prediction finished: d_reexport1_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.07s\n",
            "Prediction finished: d_reexport1_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.06s\n",
            "Prediction finished: d_reexport1_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.05s\n",
            "Prediction finished: d_reexport1_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.06s\n",
            "Prediction finished: d_reexport1_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.06s\n",
            "Prediction finished: d_reexport1_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.06s\n",
            "Prediction finished: d_reexport1_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.10s\n",
            "Prediction finished: d_reexport1_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.12s\n",
            "Prediction finished: d_reexport1_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.14s\n",
            "Prediction finished: d_reexport1_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.08s\n",
            "Prediction finished: d_reexport1_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.07s\n",
            "Prediction finished: d_reexport1_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.05s\n",
            "Prediction finished: d_reexport1_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 1.04s\n",
            "Prediction finished: d_reexport1_crop_4.tiff; img size = torch.Size([1, 3, 2000, 1988]); costing: 70.84s\n",
            "Prediction finished: d_reexport2_crop_1.tiff; img size = torch.Size([1, 3, 950, 1000]); costing: 13.98s\n",
            "Prediction finished: d_reexport2_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.09s\n",
            "Prediction finished: d_reexport2_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.09s\n",
            "Prediction finished: d_reexport2_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.09s\n",
            "Prediction finished: d_reexport2_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.05s\n",
            "Prediction finished: d_reexport2_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.10s\n",
            "Prediction finished: d_reexport2_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.11s\n",
            "Prediction finished: d_reexport2_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.11s\n",
            "Prediction finished: d_reexport2_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.03s\n",
            "Prediction finished: d_reexport2_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.04s\n",
            "Prediction finished: d_reexport2_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.02s\n",
            "Prediction finished: d_reexport2_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 1.08s\n",
            "Prediction finished: d_reexport2_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.62s\n",
            "Prediction finished: d_reexport2_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.60s\n",
            "Prediction finished: d_reexport2_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.64s\n",
            "Prediction finished: d_reexport2_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.62s\n",
            "Prediction finished: d_reexport2_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.63s\n",
            "Prediction finished: d_reexport2_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.64s\n",
            "Prediction finished: d_reexport2_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.65s\n",
            "Prediction finished: d_reexport2_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.66s\n",
            "Prediction finished: d_reexport2_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.71s\n",
            "Prediction finished: d_reexport2_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.77s\n",
            "Prediction finished: d_reexport2_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.71s\n",
            "Prediction finished: d_reexport2_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.62s\n",
            "Prediction finished: d_reexport2_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.65s\n",
            "Prediction finished: d_reexport2_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.63s\n",
            "Prediction finished: d_reexport2_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: d_reexport2_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.67s\n",
            "Prediction finished: d_reexport2_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 3.61s\n",
            "Prediction finished: ddF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.86s\n",
            "Prediction finished: ddF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.06s\n",
            "Prediction finished: ddF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.86s\n",
            "Prediction finished: ddF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.08s\n",
            "Prediction finished: ddF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.92s\n",
            "Prediction finished: ddF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.13s\n",
            "Prediction finished: ddF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.87s\n",
            "Prediction finished: ddF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.89s\n",
            "Prediction finished: ddF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.89s\n",
            "Prediction finished: ddF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.94s\n",
            "Prediction finished: ddF10PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.14s\n",
            "Prediction finished: ddF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.89s\n",
            "Prediction finished: ddF10PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.89s\n",
            "Prediction finished: ddF10PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.89s\n",
            "Prediction finished: ddF10PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.07s\n",
            "Prediction finished: ddF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.90s\n",
            "Prediction finished: ddF10PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.12s\n",
            "Prediction finished: ddF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.95s\n",
            "Prediction finished: ddF10PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.08s\n",
            "Prediction finished: ddF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 1.86s\n",
            "Prediction finished: ddF10mCh_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 1.04s\n",
            "Prediction finished: ddF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.89s\n",
            "Prediction finished: ddF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.92s\n",
            "Prediction finished: ddF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.90s\n",
            "Prediction finished: ddF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.96s\n",
            "Prediction finished: ddF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.90s\n",
            "Prediction finished: ddF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.90s\n",
            "Prediction finished: ddF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.91s\n",
            "Prediction finished: ddF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.90s\n",
            "Prediction finished: ddF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.90s\n",
            "Prediction finished: ddF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.97s\n",
            "Prediction finished: ddF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.98s\n",
            "Prediction finished: ddF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.92s\n",
            "Prediction finished: ddF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 1.85s\n",
            "Prediction finished: ddF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.95s\n",
            "Prediction finished: ddF2BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.93s\n",
            "Prediction finished: ddF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.95s\n",
            "Prediction finished: ddF2BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.98s\n",
            "Prediction finished: ddF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.95s\n",
            "Prediction finished: ddF2BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.93s\n",
            "Prediction finished: ddF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.94s\n",
            "Prediction finished: ddF2BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.93s\n",
            "Prediction finished: ddF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.97s\n",
            "Prediction finished: ddF2BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.99s\n",
            "Prediction finished: ddF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 2.03s\n",
            "Prediction finished: ddF2BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.94s\n",
            "Prediction finished: ddF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.96s\n",
            "Prediction finished: ddF2PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.94s\n",
            "Prediction finished: ddF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.97s\n",
            "Prediction finished: ddF2PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.94s\n",
            "Prediction finished: ddF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 2.02s\n",
            "Prediction finished: ddF2PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.95s\n",
            "Prediction finished: ddF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.95s\n",
            "Prediction finished: ddF2PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.94s\n",
            "Prediction finished: ddF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.96s\n",
            "Prediction finished: ddF2PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.95s\n",
            "Prediction finished: ddF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 2.01s\n",
            "Prediction finished: ddF2PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 2.04s\n",
            "Prediction finished: ddF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 1.89s\n",
            "Prediction finished: ddF2mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 1.88s\n",
            "Prediction finished: ddF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.08s\n",
            "Prediction finished: ddF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.13s\n",
            "Prediction finished: ddF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.15s\n",
            "Prediction finished: ddF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.08s\n",
            "Prediction finished: ddF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.07s\n",
            "Prediction finished: ddF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 1.03s\n",
            "Prediction finished: ddF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.06s\n",
            "Prediction finished: ddF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.07s\n",
            "Prediction finished: ddF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.06s\n",
            "Prediction finished: ddF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.06s\n",
            "Prediction finished: ddF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.11s\n",
            "Prediction finished: ddF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.12s\n",
            "Prediction finished: ddF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.14s\n",
            "Prediction finished: ddF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.09s\n",
            "Prediction finished: ddF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.06s\n",
            "Prediction finished: ddF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.07s\n",
            "Prediction finished: ddF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.08s\n",
            "Prediction finished: ddF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.08s\n",
            "Prediction finished: ddF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 1.04s\n",
            "Prediction finished: ddF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.06s\n",
            "Prediction finished: ddF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.05s\n",
            "Prediction finished: ddF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.04s\n",
            "Prediction finished: ddF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.10s\n",
            "Prediction finished: ddF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.09s\n",
            "Prediction finished: ddF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.06s\n",
            "Prediction finished: ddF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.05s\n",
            "Prediction finished: ddF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.05s\n",
            "Prediction finished: ddF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.05s\n",
            "Prediction finished: ddF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.04s\n",
            "Prediction finished: ddF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.05s\n",
            "Prediction finished: ddF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.06s\n",
            "Prediction finished: ddF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 1.02s\n",
            "Prediction finished: ddF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.92s\n",
            "Prediction finished: ddF6BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.70s\n",
            "Prediction finished: ddF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.93s\n",
            "Prediction finished: ddF6BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.69s\n",
            "Prediction finished: ddF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.93s\n",
            "Prediction finished: ddF6BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.75s\n",
            "Prediction finished: ddF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.94s\n",
            "Prediction finished: ddF6BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.70s\n",
            "Prediction finished: ddF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.94s\n",
            "Prediction finished: ddF6BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.75s\n",
            "Prediction finished: ddF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 2.00s\n",
            "Prediction finished: ddF6BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.68s\n",
            "Prediction finished: ddF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.94s\n",
            "Prediction finished: ddF6PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.73s\n",
            "Prediction finished: ddF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.99s\n",
            "Prediction finished: ddF6PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.70s\n",
            "Prediction finished: ddF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.93s\n",
            "Prediction finished: ddF6PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.69s\n",
            "Prediction finished: ddF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.94s\n",
            "Prediction finished: ddF6PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.71s\n",
            "Prediction finished: ddF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.94s\n",
            "Prediction finished: ddF6PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.71s\n",
            "Prediction finished: ddF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.93s\n",
            "Prediction finished: ddF6PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.79s\n",
            "Prediction finished: ddF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 1.87s\n",
            "Prediction finished: ddF6mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 3.61s\n",
            "Prediction finished: ddF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.90s\n",
            "Prediction finished: ddF7BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.03s\n",
            "Prediction finished: ddF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.88s\n",
            "Prediction finished: ddF7BF_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.09s\n",
            "Prediction finished: ddF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.96s\n",
            "Prediction finished: ddF7BF_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.05s\n",
            "Prediction finished: ddF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.90s\n",
            "Prediction finished: ddF7BF_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.04s\n",
            "Prediction finished: ddF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.89s\n",
            "Prediction finished: ddF7BF_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.05s\n",
            "Prediction finished: ddF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.89s\n",
            "Prediction finished: ddF7BF_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.06s\n",
            "Prediction finished: ddF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.94s\n",
            "Prediction finished: ddF7PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.12s\n",
            "Prediction finished: ddF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.89s\n",
            "Prediction finished: ddF7PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.04s\n",
            "Prediction finished: ddF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.90s\n",
            "Prediction finished: ddF7PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.04s\n",
            "Prediction finished: ddF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.89s\n",
            "Prediction finished: ddF7PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.05s\n",
            "Prediction finished: ddF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.94s\n",
            "Prediction finished: ddF7PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.10s\n",
            "Prediction finished: ddF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.89s\n",
            "Prediction finished: ddF7PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.05s\n",
            "Prediction finished: ddF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 1.86s\n",
            "Prediction finished: ddF7mCh_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 1.03s\n",
            "Prediction finished: ddF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.89s\n",
            "Prediction finished: ddF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.91s\n",
            "Prediction finished: ddF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.93s\n",
            "Prediction finished: ddF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.95s\n",
            "Prediction finished: ddF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.88s\n",
            "Prediction finished: ddF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.89s\n",
            "Prediction finished: ddF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.89s\n",
            "Prediction finished: ddF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.90s\n",
            "Prediction finished: ddF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.90s\n",
            "Prediction finished: ddF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.93s\n",
            "Prediction finished: ddF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.90s\n",
            "Prediction finished: ddF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.91s\n",
            "Prediction finished: ddF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 1.87s\n",
            "Prediction finished: ddF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.08s\n",
            "Prediction finished: ddF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.05s\n",
            "Prediction finished: ddF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.06s\n",
            "Prediction finished: ddF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.06s\n",
            "Prediction finished: ddF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.10s\n",
            "Prediction finished: ddF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.13s\n",
            "Prediction finished: ddF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.07s\n",
            "Prediction finished: ddF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.03s\n",
            "Prediction finished: fab1_002_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.04s\n",
            "Prediction finished: fab1_022_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.06s\n",
            "Prediction finished: fig4_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.00s\n",
            "Prediction finished: ibidi1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 1.90s\n",
            "Prediction finished: ibidi1out1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 1.92s\n",
            "Prediction finished: ibidi1out1b_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 1.98s\n",
            "Prediction finished: ibidi1out2_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 1.97s\n",
            "Prediction finished: ibidi2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 1.12s\n",
            "Prediction finished: ibidi2out1_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 1.08s\n",
            "Prediction finished: ibidi2out2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 1.08s\n",
            "Prediction finished: ibidi3_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 1.91s\n",
            "Prediction finished: ibidi3out1_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 1.91s\n",
            "Prediction finished: ibidi4_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 1.06s\n",
            "Prediction finished: ibidi4out1_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 1.04s\n",
            "Prediction finished: ibidi5_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 3.78s\n",
            "Prediction finished: ibidi5out1_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 3.73s\n",
            "Prediction finished: ibidi5out2_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 3.72s\n",
            "Prediction finished: image1_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.27s\n",
            "Prediction finished: image2_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.24s\n",
            "Prediction finished: image3_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.37s\n",
            "Prediction finished: image4_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.40s\n",
            "Prediction finished: image5_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.30s\n",
            "Prediction finished: long1_crop_1.tiff; img size = torch.Size([1, 3, 653, 843]); costing: 5.55s\n",
            "Prediction finished: long2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 14.52s\n",
            "Prediction finished: long3_crop_1.tiff; img size = torch.Size([1, 3, 675, 838]); costing: 5.53s\n",
            "Prediction finished: long4_crop_1.tiff; img size = torch.Size([1, 3, 728, 890]); costing: 8.23s\n",
            "Prediction finished: m_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.03s\n",
            "Prediction finished: m_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.05s\n",
            "Prediction finished: m_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.05s\n",
            "Prediction finished: m_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.06s\n",
            "Prediction finished: m_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.17s\n",
            "Prediction finished: m_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.08s\n",
            "Prediction finished: m_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.10s\n",
            "Prediction finished: m_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.22s\n",
            "Prediction finished: m_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.16s\n",
            "Prediction finished: m_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.19s\n",
            "Prediction finished: m_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.08s\n",
            "Prediction finished: m_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.05s\n",
            "Prediction finished: m_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.15s\n",
            "Prediction finished: m_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.08s\n",
            "Prediction finished: m_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.06s\n",
            "Prediction finished: m_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.19s\n",
            "Prediction finished: m_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.10s\n",
            "Prediction finished: m_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 8.10s\n",
            "Prediction finished: merged_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.15s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.01s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.01s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.04s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.20s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.18s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.08s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.04s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.06s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "Prediction finished: merged_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.19s\n",
            "Prediction finished: merged_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.16s\n",
            "Prediction finished: merged_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.04s\n",
            "Prediction finished: merged_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.02s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.02s\n",
            "Prediction finished: merged_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.04s\n",
            "Prediction finished: merged_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.06s\n",
            "Prediction finished: merged_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.23s\n",
            "Prediction finished: merged_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.20s\n",
            "Prediction finished: merged_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.14s\n",
            "Prediction finished: merged_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.10s\n",
            "Prediction finished: merged_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.09s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.10s\n",
            "Prediction finished: merged_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.15s\n",
            "Prediction finished: merged_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.50s\n",
            "Prediction finished: merged_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.44s\n",
            "Prediction finished: merged_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.38s\n",
            "Prediction finished: merged_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.59s\n",
            "Prediction finished: merged_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.14s\n",
            "Prediction finished: merged_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.17s\n",
            "Prediction finished: merged_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.22s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.32s\n",
            "Prediction finished: merged_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.50s\n",
            "Prediction finished: merged_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.08s\n",
            "Prediction finished: merged_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.08s\n",
            "Prediction finished: merged_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.12s\n",
            "Prediction finished: merged_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.23s\n",
            "Prediction finished: merged_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.34s\n",
            "Prediction finished: merged_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.49s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.19s\n",
            "Prediction finished: merged_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.42s\n",
            "Prediction finished: merged_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.39s\n",
            "Prediction finished: merged_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.06s\n",
            "Prediction finished: merged_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.09s\n",
            "Prediction finished: merged_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.19s\n",
            "Prediction finished: merged_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.16s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "Prediction finished: merged_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "Prediction finished: merged_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.06s\n",
            "Prediction finished: merged_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.09s\n",
            "Prediction finished: merged_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.08s\n",
            "Prediction finished: merged_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.09s\n",
            "Prediction finished: merged_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.05s\n",
            "Prediction finished: merged_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.20s\n",
            "Prediction finished: merged_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.15s\n",
            "Prediction finished: merged_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.12s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.09s\n",
            "Prediction finished: merged_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.14s\n",
            "Prediction finished: merged_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.10s\n",
            "Prediction finished: merged_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.07s\n",
            "Prediction finished: merged_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.08s\n",
            "Prediction finished: merged_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.12s\n",
            "Prediction finished: merged_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.26s\n",
            "Prediction finished: merged_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.24s\n",
            "Prediction finished: merged_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.27s\n",
            "Prediction finished: merged_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.21s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: merged_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.03s\n",
            "Prediction finished: merged_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.13s\n",
            "Prediction finished: merged_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.22s\n",
            "Prediction finished: merged_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.23s\n",
            "Prediction finished: merged_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 14.20s\n",
            "Prediction finished: pFB_s10_t25_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.11s\n",
            "Prediction finished: pFB_s1_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.15s\n",
            "Prediction finished: pFB_s4_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.15s\n",
            "Prediction finished: pFB_s5_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.11s\n",
            "Prediction finished: pFB_s6_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.24s\n",
            "Prediction finished: pFB_s8_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.16s\n",
            "Prediction finished: pFB_s9_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 1.13s\n",
            "Prediction finished: pMP_pos0_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.87s\n",
            "Prediction finished: pMP_pos0_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.50s\n",
            "Prediction finished: pMP_pos1_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.75s\n",
            "Prediction finished: pMP_pos1_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.38s\n",
            "Prediction finished: pMP_pos2_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.97s\n",
            "Prediction finished: pMPpos0_004_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.15s\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.13s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 68.72s\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.81s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 68.89s\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 71.81s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 68.73s\n",
            "Prediction finished: pSP_102_crop_1.tiff; img size = torch.Size([1, 3, 1899, 440]); costing: 7.26s\n",
            "Prediction finished: pSP_102_crop_2.tiff; img size = torch.Size([1, 3, 571, 869]); costing: 5.31s\n",
            "Prediction finished: pSP_102_crop_3.tiff; img size = torch.Size([1, 3, 401, 589]); costing: 1.86s\n",
            "Prediction finished: pSP_58_crop_1.tiff; img size = torch.Size([1, 3, 1700, 1969]); costing: 55.34s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 74.99s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 74.64s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 75.33s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 75.77s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 76.01s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 75.38s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 74.94s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 75.15s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 74.98s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.41s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.60s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.87s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.86s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.72s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.88s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 73.39s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 73.61s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 74.14s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 74.37s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 74.73s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 74.41s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 74.66s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 73.83s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 57.49s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 58.80s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 58.76s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 59.43s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 61.05s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 58.92s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 58.21s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 58.01s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 59.14s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 59.88s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 61.21s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 60.14s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 59.76s\n",
            "Prediction finished: sc472_021220_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 75.10s\n",
            "Prediction finished: sc472_021220_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.62s\n",
            "Prediction finished: sc472_021220_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.63s\n",
            "Prediction finished: sc472_021220_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.88s\n",
            "Prediction finished: sc472_021220_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.00s\n",
            "Prediction finished: sc472_021220_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.05s\n",
            "Prediction finished: sc472_021220_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.32s\n",
            "Prediction finished: sc472_021220_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.76s\n",
            "Prediction finished: sc472_021220_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.07s\n",
            "Prediction finished: sc472_021220_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.97s\n",
            "Prediction finished: sc472_021220_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 75.96s\n",
            "Prediction finished: sc472_021220_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 75.65s\n",
            "Prediction finished: sc472_021220_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.74s\n",
            "Prediction finished: sc472_021220_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.49s\n",
            "Prediction finished: sc472_021220_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.14s\n",
            "Prediction finished: sc472_021220_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.53s\n",
            "Prediction finished: sc472_021220_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 75.44s\n",
            "Prediction finished: sc472_021220_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 75.03s\n",
            "Prediction finished: sc472_021220_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.25s\n",
            "Prediction finished: sc472_021220_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.93s\n",
            "Prediction finished: sc472_021220_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.61s\n",
            "Prediction finished: sc472_021220_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.55s\n",
            "Prediction finished: sc472_021220_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.84s\n",
            "Prediction finished: sc472_021220_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.10s\n",
            "Prediction finished: sc472_300920_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.15s\n",
            "Prediction finished: sc472_300920_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.57s\n",
            "Prediction finished: sc472_300920_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.88s\n",
            "Prediction finished: sc472_300920_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.46s\n",
            "Prediction finished: sc472_300920_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.15s\n",
            "Prediction finished: sc472_300920_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.09s\n",
            "Prediction finished: sc472_300920_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.17s\n",
            "Prediction finished: sc472_300920_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.05s\n",
            "Prediction finished: sc472_300920_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.66s\n",
            "Prediction finished: sc472_300920_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.57s\n",
            "Prediction finished: sc472_300920_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.86s\n",
            "Prediction finished: sc472_300920_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.60s\n",
            "Prediction finished: sc472_300920_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.84s\n",
            "Prediction finished: sc472_300920_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.38s\n",
            "Prediction finished: sc472_300920_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.74s\n",
            "Prediction finished: sc472_300920_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.90s\n",
            "Prediction finished: sc472_300920_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.05s\n",
            "Prediction finished: sc472_300920_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 72.83s\n",
            "Prediction finished: sc472_300920_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.02s\n",
            "Prediction finished: sc472_300920_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.46s\n",
            "Prediction finished: sc472_300920_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.27s\n",
            "Prediction finished: sc472_300920_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.75s\n",
            "Prediction finished: sc472_300920_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 73.41s\n",
            "Prediction finished: sc472_300920_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.19s\n",
            "Prediction finished: sc472_300920_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 74.17s\n",
            "Prediction finished: small1_crop_1.tiff; img size = torch.Size([1, 3, 478, 604]); costing: 1.93s\n",
            "Prediction finished: small2_crop_1.tiff; img size = torch.Size([1, 3, 478, 652]); costing: 1.97s\n",
            "Prediction finished: small3_crop_1.tiff; img size = torch.Size([1, 3, 344, 331]); costing: 1.08s\n",
            "Prediction finished: v_cdc20null_crop_1.tiff; img size = torch.Size([1, 3, 820, 1070]); costing: 11.07s\n",
            "Prediction finished: v_clnnull_crop_1.tiff; img size = torch.Size([1, 3, 1050, 1000]); costing: 14.37s\n",
            "Prediction finished: vac14_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.72s\n",
            "Prediction finished: vac14_008_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.41s\n",
            "Prediction finished: video2out_crop_1.tiff; img size = torch.Size([1, 3, 431, 267]); costing: 1.06s\n",
            "Prediction finished: video3out_crop_1.tiff; img size = torch.Size([1, 3, 370, 568]); costing: 1.94s\n",
            "Prediction finished: wt-k699_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 78.00s\n",
            "Prediction finished: wt-k699_018_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.98s\n",
            "Prediction finished: wt-k699_030_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 77.64s\n",
            "Prediction finished: wt1_crop_1.tiff; img size = torch.Size([1, 3, 695, 650]); costing: 4.06s\n",
            "Prediction finished: wt2_crop_1.tiff; img size = torch.Size([1, 3, 1007, 800]); costing: 11.24s\n",
            "Prediction finished: wt3_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 11.12s\n",
            "Prediction finished: wt3out1_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 11.17s\n",
            "Prediction finished: wtF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.38s\n",
            "Prediction finished: wtF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.15s\n",
            "Prediction finished: wtF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.39s\n",
            "Prediction finished: wtF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.10s\n",
            "Prediction finished: wtF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.36s\n",
            "Prediction finished: wtF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.10s\n",
            "Prediction finished: wtF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.50s\n",
            "Prediction finished: wtF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.12s\n",
            "Prediction finished: wtF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.35s\n",
            "Prediction finished: wtF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.15s\n",
            "Prediction finished: wtF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 8.36s\n",
            "Prediction finished: wtF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 1.10s\n",
            "Prediction finished: wtF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 1.93s\n",
            "Prediction finished: wtF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 1.98s\n",
            "Prediction finished: wtF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 2.01s\n",
            "Prediction finished: wtF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 1.93s\n",
            "Prediction finished: wtF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 1.93s\n",
            "Prediction finished: wtF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 1.93s\n",
            "Prediction finished: wtF12BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.23s\n",
            "Prediction finished: wtF12BF_10_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.22s\n",
            "Prediction finished: wtF12BF_1_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.24s\n",
            "Prediction finished: wtF12BF_20_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.34s\n",
            "Prediction finished: wtF12BF_2_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.24s\n",
            "Prediction finished: wtF12BF_5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 8.24s\n",
            "Prediction finished: wtF13BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.12s\n",
            "Prediction finished: wtF13BF_10_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.11s\n",
            "Prediction finished: wtF13BF_1_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.11s\n",
            "Prediction finished: wtF13BF_20_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.12s\n",
            "Prediction finished: wtF13BF_2_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.11s\n",
            "Prediction finished: wtF13BF_5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 1.17s\n",
            "Prediction finished: wtF14BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.43s\n",
            "Prediction finished: wtF14BF_10_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.44s\n",
            "Prediction finished: wtF14BF_1_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.44s\n",
            "Prediction finished: wtF14BF_20_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.43s\n",
            "Prediction finished: wtF14BF_2_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.51s\n",
            "Prediction finished: wtF14BF_5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 5.45s\n",
            "Prediction finished: wtF15BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.11s\n",
            "Prediction finished: wtF15BF_10_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.11s\n",
            "Prediction finished: wtF15BF_1_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.10s\n",
            "Prediction finished: wtF15BF_20_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.11s\n",
            "Prediction finished: wtF15BF_2_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.16s\n",
            "Prediction finished: wtF15BF_5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 1.17s\n",
            "Prediction finished: wtF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.73s\n",
            "Prediction finished: wtF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.73s\n",
            "Prediction finished: wtF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.78s\n",
            "Prediction finished: wtF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.74s\n",
            "Prediction finished: wtF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.72s\n",
            "Prediction finished: wtF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 3.73s\n",
            "Prediction finished: wtF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.99s\n",
            "Prediction finished: wtF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.95s\n",
            "Prediction finished: wtF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.94s\n",
            "Prediction finished: wtF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.95s\n",
            "Prediction finished: wtF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.94s\n",
            "Prediction finished: wtF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 1.94s\n",
            "Prediction finished: wtF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 2.00s\n",
            "Prediction finished: wtF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 2.01s\n",
            "Prediction finished: wtF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 1.95s\n",
            "Prediction finished: wtF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 1.95s\n",
            "Prediction finished: wtF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 1.95s\n",
            "Prediction finished: wtF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 1.95s\n",
            "Prediction finished: wtF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.07s\n",
            "Prediction finished: wtF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.07s\n",
            "Prediction finished: wtF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.13s\n",
            "Prediction finished: wtF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.15s\n",
            "Prediction finished: wtF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.08s\n",
            "Prediction finished: wtF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 1.07s\n",
            "Prediction finished: wtF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 2.01s\n",
            "Prediction finished: wtF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 2.00s\n",
            "Prediction finished: wtF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 1.99s\n",
            "Prediction finished: wtF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 2.00s\n",
            "Prediction finished: wtF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 2.08s\n",
            "Prediction finished: wtF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 2.02s\n",
            "Prediction finished: wtF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 1.98s\n",
            "Prediction finished: wtF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 1.98s\n",
            "Prediction finished: wtF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 1.97s\n",
            "Prediction finished: wtF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 1.97s\n",
            "Prediction finished: wtF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 2.04s\n",
            "Prediction finished: wtF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 2.04s\n",
            "Prediction finished: wtF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.75s\n",
            "Prediction finished: wtF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.73s\n",
            "Prediction finished: wtF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.81s\n",
            "Prediction finished: wtF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.76s\n",
            "Prediction finished: wtF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.74s\n",
            "Prediction finished: wtF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 3.75s\n",
            "Prediction finished: wtF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.15s\n",
            "Prediction finished: wtF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.16s\n",
            "Prediction finished: wtF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.10s\n",
            "Prediction finished: wtF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.09s\n",
            "Prediction finished: wtF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.09s\n",
            "Prediction finished: wtF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 1.09s\n",
            "Prediction finished: wt_live003_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1459, 1459]); costing: 31.58s\n",
            "Prediction finished: z2_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 21.57s\n",
            "Prediction finished: z3_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 21.18s\n",
            "\n",
            " Total Time Cost: 17107.92s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_ensemble_tta1218_0224.zip\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --config_path=config/step3_prediction/ensemble_tta.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2L7V72TXufu",
        "outputId": "bde744c9-e092-452f-b8c2-c3d3df704a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  8% 227/2869 [00:12<01:43, 25.51it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 27% 776/2869 [00:18<00:58, 35.94it/s]No segmentation results!\n",
            " 27% 780/2869 [00:19<01:48, 19.31it/s]No segmentation results!\n",
            " 27% 783/2869 [00:19<02:52, 12.06it/s]No segmentation results!\n",
            "No segmentation results!\n",
            " 27% 786/2869 [00:20<03:48,  9.10it/s]No segmentation results!\n",
            " 28% 793/2869 [00:21<05:10,  6.70it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20201221_LLY3752_Gal+aa_OD2_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 52% 1504/2869 [00:52<00:59, 22.84it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 7_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1919/2869 [01:35<00:11, 81.50it/s]No segmentation results!\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1928/2869 [01:37<01:28, 10.68it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1939/2869 [01:38<01:07, 13.81it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1944/2869 [01:38<00:57, 16.03it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1953/2869 [01:38<00:45, 19.94it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1957/2869 [01:38<00:40, 22.49it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1965/2869 [01:39<00:36, 24.98it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1969/2869 [01:39<00:35, 25.58it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1977/2869 [01:39<00:37, 24.07it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1983/2869 [01:40<00:48, 18.10it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 1994/2869 [01:40<00:57, 15.17it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2005/2869 [01:41<00:55, 15.61it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2016/2869 [01:42<01:04, 13.32it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2022/2869 [01:42<01:12, 11.66it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2028/2869 [01:43<01:10, 12.01it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2035/2869 [01:43<00:46, 17.86it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2042/2869 [01:43<00:41, 19.85it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2048/2869 [01:44<00:42, 19.24it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2054/2869 [01:44<00:42, 18.99it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2060/2869 [01:44<00:39, 20.52it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2066/2869 [01:45<00:38, 20.87it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2072/2869 [01:45<00:28, 28.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2078/2869 [01:45<00:23, 34.04it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2085/2869 [01:46<01:24,  9.33it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2094/2869 [01:48<01:56,  6.68it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2099/2869 [01:48<01:15, 10.24it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2105/2869 [01:48<00:52, 14.57it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2112/2869 [01:49<01:02, 12.17it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2119/2869 [01:50<01:12, 10.36it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2126/2869 [01:50<00:52, 14.20it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2131/2869 [01:50<00:43, 17.03it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2138/2869 [01:50<00:31, 22.89it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2145/2869 [01:51<00:35, 20.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2152/2869 [01:52<01:12,  9.93it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2158/2869 [01:52<01:24,  8.46it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2165/2869 [01:53<00:59, 11.80it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2172/2869 [01:54<01:07, 10.30it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2178/2869 [01:54<01:24,  8.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2183/2869 [01:55<01:27,  7.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2190/2869 [01:55<00:42, 15.81it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2198/2869 [01:55<00:32, 20.81it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2204/2869 [01:56<00:33, 19.76it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 82% 2364/2869 [02:00<00:17, 28.29it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2373/2869 [02:00<00:14, 34.09it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2386/2869 [02:01<00:12, 37.81it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2391/2869 [02:01<00:12, 39.68it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2401/2869 [02:01<00:12, 36.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2413/2869 [02:02<00:13, 32.61it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2421/2869 [02:02<00:13, 32.30it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2430/2869 [02:02<00:12, 35.91it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2435/2869 [02:02<00:11, 38.48it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2441/2869 [02:02<00:10, 42.20it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2447/2869 [02:02<00:09, 45.54it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2453/2869 [02:03<00:08, 47.70it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2463/2869 [02:03<00:10, 39.66it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2476/2869 [02:03<00:15, 25.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2488/2869 [02:04<00:16, 23.58it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2500/2869 [02:04<00:12, 28.59it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2508/2869 [02:05<00:11, 30.63it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2517/2869 [02:05<00:11, 31.44it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2522/2869 [02:05<00:10, 33.40it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2527/2869 [02:05<00:09, 35.19it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 94% 2687/2869 [02:31<01:54,  1.59it/s]No segmentation results!\n",
            " 94% 2689/2869 [02:32<02:06,  1.42it/s]No segmentation results!\n",
            " 94% 2691/2869 [02:33<01:56,  1.53it/s]No segmentation results!\n",
            " 94% 2696/2869 [02:35<00:59,  2.93it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc1_972_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc313_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc370_wee1-50_4h_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2781/2869 [03:34<00:13,  6.61it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2788/2869 [03:34<00:06, 12.19it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2796/2869 [03:34<00:03, 18.80it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF12BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2802/2869 [03:35<00:03, 18.16it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF13BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2806/2869 [03:35<00:02, 21.83it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF14BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2812/2869 [03:35<00:03, 16.78it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF15BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2819/2869 [03:36<00:02, 21.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2825/2869 [03:36<00:02, 20.12it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2832/2869 [03:36<00:01, 23.21it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2836/2869 [03:36<00:01, 26.25it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2844/2869 [03:37<00:00, 26.54it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2850/2869 [03:37<00:00, 23.80it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2854/2869 [03:37<00:00, 25.04it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2860/2869 [03:37<00:00, 20.55it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2869/2869 [03:38<00:00, 13.11it/s]\n",
            "mean F1 Score: 0.804237114537445 +/- 0.004831200673781785\n",
            "mean AP Score: 0.7342758076358297 +/- 0.005682898479946222\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=results/mediar_ensemble_tta --gt_path=Datasets/labels --save_path=evaluation_result/ensemble_tta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1xpoCN9UuDu"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/ml-project-2-doughminators/results/mediar_base_prediction.zip /content/ml-project-2-doughminators/results/mediar_base_prediction\n",
        "!zip -r /content/ml-project-2-doughminators/results/mediar_ensemble_tta.zip /content/ml-project-2-doughminators/results/mediar_ensemble_tta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHzFKKn9bJHt"
      },
      "source": [
        "Inference on the phase 1 model (only pretrained on ImageNet-1k and public datasets).\n",
        "\n",
        "Note: this corresponds to P1 model in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RXdTAgPabPZO",
        "outputId": "8fa37616-5b6c-490f-f0ed-94de4dfe2442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_8_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.37s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.34s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.38s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.36s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.29s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.30s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.32s\n",
            "Prediction finished: 3306_pad1_9_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 500, 500]); costing: 0.31s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 3_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.65s\n",
            "Prediction finished: 3out1_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.61s\n",
            "Prediction finished: 3out2_crop_1.tiff; img size = torch.Size([1, 3, 648, 960]); costing: 1.63s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 4_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 4_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.24s\n",
            "Prediction finished: 4out1_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.22s\n",
            "Prediction finished: 4out2_crop_1.tiff; img size = torch.Size([1, 3, 730, 691]); costing: 1.22s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 5_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 5_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 5_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.80s\n",
            "Prediction finished: 5out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.82s\n",
            "Prediction finished: 5out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 2.95s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 6_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.63s\n",
            "Prediction finished: 6out1_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.35s\n",
            "Prediction finished: 6out2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.34s\n",
            "Prediction finished: 7.5.2018_tp50_pos03_crop_1.tiff; img size = torch.Size([1, 3, 512, 500]); costing: 0.24s\n",
            "Prediction finished: 7.5.2018_tp50_pos06_crop_1.tiff; img size = torch.Size([1, 3, 512, 505]); costing: 0.26s\n",
            "Prediction finished: 7.5.2018_tp50_pos08_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.27s\n",
            "Prediction finished: 7.5.2018_tp50_pos09_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.28s\n",
            "Prediction finished: 7.5.2018_tp50_pos10_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.26s\n",
            "Prediction finished: 7.5.2018_tp50_pos21_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.27s\n",
            "Prediction finished: 7.5.2018_tp50_pos28_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.26s\n",
            "Prediction finished: 7.5.2018_tp50_pos32_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 7_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 7_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.79s\n",
            "Prediction finished: 7out1_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.78s\n",
            "Prediction finished: 7out2_crop_1.tiff; img size = torch.Size([1, 3, 920, 920]); costing: 1.90s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.32s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.31s\n",
            "Prediction finished: 8_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 8_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.47s\n",
            "Prediction finished: 8out1_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.37s\n",
            "Prediction finished: 8out2_crop_1.tiff; img size = torch.Size([1, 3, 759, 959]); costing: 2.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.27s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.28s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.29s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.30s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_DIC_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.34s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.37s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.33s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.36s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: 9_Ref_Zstack_TL_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 452, 452]); costing: 0.35s\n",
            "Prediction finished: Abf1_Ancestor_5_z24_BF_crop_1.tiff; img size = torch.Size([1, 3, 958, 918]); costing: 2.39s\n",
            "Prediction finished: Abf1_Ancestor_6_z23_BF_crop_1.tiff; img size = torch.Size([1, 3, 730, 958]); costing: 2.55s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_1.tiff; img size = torch.Size([1, 3, 953, 650]); costing: 1.84s\n",
            "Prediction finished: Abf1_Ancestor_7_z25_BF_crop_2.tiff; img size = torch.Size([1, 3, 678, 308]); costing: 0.51s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.72s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.73s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.75s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.82s\n",
            "Prediction finished: Ahmad_frame_16_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 700, 650]); costing: 0.82s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.28s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Ahmad_frame_16_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_0.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.02s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_1.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.02s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_2.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.04s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_3.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.04s\n",
            "Prediction finished: Ahmad_frame_16_crop_4_frame_4.tiff; img size = torch.Size([1, 3, 620, 720]); costing: 1.05s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.57s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.67s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.57s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.58s\n",
            "Prediction finished: Ahmad_frame_19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1000, 950]); costing: 2.60s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.41s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.41s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.42s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.41s\n",
            "Prediction finished: Ahmad_frame_19_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 470, 620]); costing: 0.42s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.25s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.25s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.28s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.31s\n",
            "Prediction finished: Ahmad_frame_19_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 340, 480]); costing: 0.31s\n",
            "Prediction finished: MS183_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.04s\n",
            "Prediction finished: MS183_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.92s\n",
            "Prediction finished: MS183_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.17s\n",
            "Prediction finished: MS183_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.33s\n",
            "Prediction finished: MS183_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.09s\n",
            "Prediction finished: MS183_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.90s\n",
            "Prediction finished: MS183_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 13.99s\n",
            "Prediction finished: MS183_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.25s\n",
            "Prediction finished: MS183_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1975, 1980]); costing: 14.04s\n",
            "Prediction finished: PN1192_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 19.06s\n",
            "Prediction finished: PN1192_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 16.61s\n",
            "Prediction finished: PN1192_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 20.04s\n",
            "Prediction finished: PN1192_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 18.18s\n",
            "Prediction finished: PN1192_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 19.91s\n",
            "Prediction finished: PN1192_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 18.78s\n",
            "Prediction finished: PN1192_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1935]); costing: 13.04s\n",
            "Prediction finished: PN19_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 20.83s\n",
            "Prediction finished: PN19_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 18.42s\n",
            "Prediction finished: PN19_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.67s\n",
            "Prediction finished: PN19_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.91s\n",
            "Prediction finished: PN19_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 18.35s\n",
            "Prediction finished: PN19_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 22.06s\n",
            "Prediction finished: PN19_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 22.49s\n",
            "Prediction finished: PN19_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 23.79s\n",
            "Prediction finished: PN19_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.49s\n",
            "Prediction finished: PN19_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 16.18s\n",
            "Prediction finished: PN19_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.57s\n",
            "Prediction finished: PN19_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1980, 1970]); costing: 17.46s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_100.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_101.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_102.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_103.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_104.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_105.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_106.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_107.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_108.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_109.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_110.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_111.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_112.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_113.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_114.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_115.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_116.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_117.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_118.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_119.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_120.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.02s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.02s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.04s\n",
            "Prediction finished: Schmoller_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.98s\n",
            "Prediction finished: Schmoller_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.05s\n",
            "Prediction finished: Schmoller_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "[!Caution] Only 5 Cells Detected!!!\n",
            "\n",
            "Prediction finished: Schmoller_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.01s\n",
            "Prediction finished: Schmoller_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.08s\n",
            "Prediction finished: Schmoller_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.07s\n",
            "Prediction finished: Schmoller_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.06s\n",
            "Prediction finished: Schmoller_crop_1_frame_94.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_95.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 1.00s\n",
            "Prediction finished: Schmoller_crop_1_frame_96.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_97.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_98.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: Schmoller_crop_1_frame_99.tiff; img size = torch.Size([1, 3, 760, 700]); costing: 0.99s\n",
            "Prediction finished: V11032020_p1_crop_1.tiff; img size = torch.Size([1, 3, 410, 360]); costing: 0.25s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.70s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.71s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.73s\n",
            "Prediction finished: V11032020_p2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 550, 550]); costing: 0.73s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 0.81s\n",
            "Prediction finished: V11032020_p3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 550, 650]); costing: 0.80s\n",
            "Prediction finished: a_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.67s\n",
            "Prediction finished: a_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.75s\n",
            "Prediction finished: a_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.70s\n",
            "Prediction finished: a_reexport1_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.71s\n",
            "Prediction finished: a_reexport1_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.72s\n",
            "Prediction finished: a_reexport1_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.74s\n",
            "Prediction finished: a_reexport1_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.81s\n",
            "Prediction finished: a_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.73s\n",
            "Prediction finished: a_reexport1_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.80s\n",
            "Prediction finished: a_reexport1_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.82s\n",
            "Prediction finished: a_reexport1_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.76s\n",
            "Prediction finished: a_reexport1_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.77s\n",
            "Prediction finished: a_reexport1_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.78s\n",
            "Prediction finished: a_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.68s\n",
            "Prediction finished: a_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 600, 600]); costing: 0.69s\n",
            "Prediction finished: a_reexport2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.45s\n",
            "Prediction finished: a_reexport2_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.44s\n",
            "Prediction finished: a_reexport2_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.40s\n",
            "Prediction finished: a_reexport2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.41s\n",
            "Prediction finished: a_reexport2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "Prediction finished: a_reexport2_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.38s\n",
            "Prediction finished: a_reexport2_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 545, 461]); costing: 0.39s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: a_reexport3_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "Prediction finished: a_reexport3_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 1.88s\n",
            "Prediction finished: a_reexport3_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 844, 948]); costing: 1.87s\n",
            "Prediction finished: alk1alk2_001_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.69s\n",
            "Prediction finished: alk1alk2_011_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.18s\n",
            "Prediction finished: bendy1_crop_1.tiff; img size = torch.Size([1, 3, 692, 937]); costing: 1.61s\n",
            "Prediction finished: bendy2_crop_1.tiff; img size = torch.Size([1, 3, 541, 812]); costing: 1.16s\n",
            "Prediction finished: cdc20F10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.31s\n",
            "Prediction finished: cdc20F10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.30s\n",
            "Prediction finished: cdc20F10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.32s\n",
            "Prediction finished: cdc20F10mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 486]); costing: 0.24s\n",
            "Prediction finished: cdc20F1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.27s\n",
            "Prediction finished: cdc20F1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.35s\n",
            "Prediction finished: cdc20F1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.32s\n",
            "Prediction finished: cdc20F1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.32s\n",
            "Prediction finished: cdc20F1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.33s\n",
            "Prediction finished: cdc20F1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.32s\n",
            "Prediction finished: cdc20F1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.32s\n",
            "Prediction finished: cdc20F1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.34s\n",
            "Prediction finished: cdc20F1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.27s\n",
            "Prediction finished: cdc20F1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.23s\n",
            "Prediction finished: cdc20F2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.29s\n",
            "Prediction finished: cdc20F2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.28s\n",
            "Prediction finished: cdc20F2mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 451]); costing: 0.24s\n",
            "Prediction finished: cdc20F3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.45s\n",
            "Prediction finished: cdc20F3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.45s\n",
            "Prediction finished: cdc20F3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.45s\n",
            "Prediction finished: cdc20F3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.47s\n",
            "Prediction finished: cdc20F3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.46s\n",
            "Prediction finished: cdc20F3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.51s\n",
            "Prediction finished: cdc20F3mCh_crop_1.tiff; img size = torch.Size([1, 3, 551, 501]); costing: 0.44s\n",
            "Prediction finished: cdc20F4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.88s\n",
            "Prediction finished: cdc20F4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.78s\n",
            "Prediction finished: cdc20F4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.87s\n",
            "Prediction finished: cdc20F4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.85s\n",
            "Prediction finished: cdc20F4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.77s\n",
            "Prediction finished: cdc20F4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.76s\n",
            "Prediction finished: cdc20F4mCh_crop_1.tiff; img size = torch.Size([1, 3, 801, 801]); costing: 1.51s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.19s\n",
            "Prediction finished: cdc20F5BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.54s\n",
            "Prediction finished: cdc20F5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.25s\n",
            "Prediction finished: cdc20F5BF_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.39s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.19s\n",
            "Prediction finished: cdc20F5BF_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.38s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5BF_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.41s\n",
            "Prediction finished: cdc20F5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.20s\n",
            "Prediction finished: cdc20F5BF_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.41s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.26s\n",
            "Prediction finished: cdc20F5BF_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.51s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.21s\n",
            "Prediction finished: cdc20F5PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.38s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.21s\n",
            "Prediction finished: cdc20F5PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.35s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.40s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.51s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.26s\n",
            "Prediction finished: cdc20F5PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.38s\n",
            "[!Caution] Only 1 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.22s\n",
            "Prediction finished: cdc20F5PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.35s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: cdc20F5mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 301]); costing: 0.19s\n",
            "Prediction finished: cdc20F5mCh_crop_2.tiff; img size = torch.Size([1, 3, 1001, 881]); costing: 2.01s\n",
            "Prediction finished: cdc20F6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.86s\n",
            "Prediction finished: cdc20F6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.98s\n",
            "Prediction finished: cdc20F6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.84s\n",
            "Prediction finished: cdc20F6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.80s\n",
            "Prediction finished: cdc20F6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.79s\n",
            "Prediction finished: cdc20F6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.94s\n",
            "Prediction finished: cdc20F6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.92s\n",
            "Prediction finished: cdc20F6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.81s\n",
            "Prediction finished: cdc20F6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.79s\n",
            "Prediction finished: cdc20F6mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 876]); costing: 1.57s\n",
            "Prediction finished: cdc20F7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.78s\n",
            "Prediction finished: cdc20F7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.81s\n",
            "Prediction finished: cdc20F7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.78s\n",
            "Prediction finished: cdc20F7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.78s\n",
            "Prediction finished: cdc20F7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.86s\n",
            "Prediction finished: cdc20F7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.87s\n",
            "Prediction finished: cdc20F7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.87s\n",
            "Prediction finished: cdc20F7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.78s\n",
            "Prediction finished: cdc20F7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.79s\n",
            "Prediction finished: cdc20F7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.80s\n",
            "Prediction finished: cdc20F7mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 601]); costing: 0.68s\n",
            "Prediction finished: cdc20F8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.20s\n",
            "Prediction finished: cdc20F8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.20s\n",
            "Prediction finished: cdc20F8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.19s\n",
            "Prediction finished: cdc20F8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.30s\n",
            "Prediction finished: cdc20F8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.28s\n",
            "Prediction finished: cdc20F8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.19s\n",
            "Prediction finished: cdc20F8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.21s\n",
            "Prediction finished: cdc20F8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.18s\n",
            "Prediction finished: cdc20F8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.18s\n",
            "Prediction finished: cdc20F8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.19s\n",
            "Prediction finished: cdc20F8mCh_crop_1.tiff; img size = torch.Size([1, 3, 673, 731]); costing: 1.02s\n",
            "Prediction finished: cdc20F9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.85s\n",
            "Prediction finished: cdc20F9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.86s\n",
            "Prediction finished: cdc20F9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.85s\n",
            "Prediction finished: cdc20F9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.93s\n",
            "Prediction finished: cdc20F9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.96s\n",
            "Prediction finished: cdc20F9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.93s\n",
            "Prediction finished: cdc20F9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.98s\n",
            "Prediction finished: cdc20F9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.95s\n",
            "Prediction finished: cdc20F9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.96s\n",
            "Prediction finished: cdc20F9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.93s\n",
            "Prediction finished: cdc20F9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.85s\n",
            "Prediction finished: cdc20F9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.86s\n",
            "Prediction finished: cdc20F9mCh_crop_1.tiff; img size = torch.Size([1, 3, 581, 701]); costing: 0.72s\n",
            "Prediction finished: clnF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.29s\n",
            "Prediction finished: clnF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 402, 441]); costing: 0.28s\n",
            "Prediction finished: clnF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.95s\n",
            "Prediction finished: clnF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.71s\n",
            "Prediction finished: clnF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.99s\n",
            "Prediction finished: clnF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.73s\n",
            "Prediction finished: clnF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.96s\n",
            "Prediction finished: clnF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.71s\n",
            "Prediction finished: clnF11PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.71s\n",
            "Prediction finished: clnF11PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.65s\n",
            "Prediction finished: clnF11PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.66s\n",
            "Prediction finished: clnF11PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.67s\n",
            "Prediction finished: clnF11PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.61s\n",
            "Prediction finished: clnF11PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.62s\n",
            "Prediction finished: clnF11mCh_crop_1.tiff; img size = torch.Size([1, 3, 1311, 1463]); costing: 5.68s\n",
            "Prediction finished: clnF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.87s\n",
            "Prediction finished: clnF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.87s\n",
            "Prediction finished: clnF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.93s\n",
            "Prediction finished: clnF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.93s\n",
            "Prediction finished: clnF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.97s\n",
            "Prediction finished: clnF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.88s\n",
            "Prediction finished: clnF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.85s\n",
            "Prediction finished: clnF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.87s\n",
            "Prediction finished: clnF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.86s\n",
            "Prediction finished: clnF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.85s\n",
            "Prediction finished: clnF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.85s\n",
            "Prediction finished: clnF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.85s\n",
            "Prediction finished: clnF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 651, 641]); costing: 0.79s\n",
            "Prediction finished: clnF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.25s\n",
            "Prediction finished: clnF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.39s\n",
            "Prediction finished: clnF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.26s\n",
            "Prediction finished: clnF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.25s\n",
            "Prediction finished: clnF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.25s\n",
            "Prediction finished: clnF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.28s\n",
            "Prediction finished: clnF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.38s\n",
            "Prediction finished: clnF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.37s\n",
            "Prediction finished: clnF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.26s\n",
            "Prediction finished: clnF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.26s\n",
            "Prediction finished: clnF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.25s\n",
            "Prediction finished: clnF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.25s\n",
            "Prediction finished: clnF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 721, 1051]); costing: 2.41s\n",
            "Prediction finished: clnF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.90s\n",
            "Prediction finished: clnF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.84s\n",
            "Prediction finished: clnF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.82s\n",
            "Prediction finished: clnF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.86s\n",
            "Prediction finished: clnF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.85s\n",
            "Prediction finished: clnF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.85s\n",
            "Prediction finished: clnF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.83s\n",
            "Prediction finished: clnF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.82s\n",
            "Prediction finished: clnF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.85s\n",
            "Prediction finished: clnF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.82s\n",
            "Prediction finished: clnF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.83s\n",
            "Prediction finished: clnF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.84s\n",
            "Prediction finished: clnF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 601, 531]); costing: 0.88s\n",
            "Prediction finished: clnF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.50s\n",
            "Prediction finished: clnF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.49s\n",
            "Prediction finished: clnF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.49s\n",
            "Prediction finished: clnF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.50s\n",
            "Prediction finished: clnF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.45s\n",
            "Prediction finished: clnF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.45s\n",
            "Prediction finished: clnF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.44s\n",
            "Prediction finished: clnF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 555, 368]); costing: 0.46s\n",
            "Prediction finished: clnF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.95s\n",
            "Prediction finished: clnF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.99s\n",
            "Prediction finished: clnF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.05s\n",
            "Prediction finished: clnF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.13s\n",
            "Prediction finished: clnF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.95s\n",
            "Prediction finished: clnF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.96s\n",
            "Prediction finished: clnF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.95s\n",
            "Prediction finished: clnF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.95s\n",
            "Prediction finished: clnF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.98s\n",
            "Prediction finished: clnF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 2.09s\n",
            "Prediction finished: clnF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.94s\n",
            "Prediction finished: clnF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.94s\n",
            "Prediction finished: clnF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 901, 891]); costing: 1.99s\n",
            "Prediction finished: clnF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.70s\n",
            "Prediction finished: clnF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.71s\n",
            "Prediction finished: clnF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.81s\n",
            "Prediction finished: clnF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.81s\n",
            "Prediction finished: clnF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.70s\n",
            "Prediction finished: clnF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.70s\n",
            "Prediction finished: clnF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.72s\n",
            "Prediction finished: clnF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.69s\n",
            "Prediction finished: clnF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.69s\n",
            "Prediction finished: clnF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.79s\n",
            "Prediction finished: clnF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.83s\n",
            "Prediction finished: clnF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.69s\n",
            "Prediction finished: clnF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 750, 739]); costing: 1.74s\n",
            "Prediction finished: clnF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.31s\n",
            "Prediction finished: clnF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.40s\n",
            "Prediction finished: clnF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.35s\n",
            "Prediction finished: clnF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.35s\n",
            "Prediction finished: clnF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.33s\n",
            "Prediction finished: clnF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.51s\n",
            "Prediction finished: clnF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.30s\n",
            "Prediction finished: clnF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.29s\n",
            "Prediction finished: clnF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.30s\n",
            "Prediction finished: clnF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.49s\n",
            "Prediction finished: clnF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.31s\n",
            "Prediction finished: clnF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.29s\n",
            "Prediction finished: clnF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 1026, 1094]); costing: 3.46s\n",
            "Prediction finished: clnF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.53s\n",
            "Prediction finished: clnF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.53s\n",
            "Prediction finished: clnF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.54s\n",
            "Prediction finished: clnF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.53s\n",
            "Prediction finished: clnF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.47s\n",
            "Prediction finished: clnF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.47s\n",
            "Prediction finished: clnF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.47s\n",
            "Prediction finished: clnF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.48s\n",
            "Prediction finished: clnF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 565, 459]); costing: 0.45s\n",
            "Prediction finished: clnF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.98s\n",
            "Prediction finished: clnF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.00s\n",
            "Prediction finished: clnF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.98s\n",
            "Prediction finished: clnF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.99s\n",
            "Prediction finished: clnF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.00s\n",
            "Prediction finished: clnF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.07s\n",
            "Prediction finished: clnF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.06s\n",
            "Prediction finished: clnF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.04s\n",
            "Prediction finished: clnF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.97s\n",
            "Prediction finished: clnF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.99s\n",
            "Prediction finished: clnF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.97s\n",
            "Prediction finished: clnF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 0.97s\n",
            "Prediction finished: clnF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 698, 686]); costing: 1.00s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.21s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.23s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.22s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 4 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.27s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.24s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.25s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 2 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "[!Caution] Only 3 Cells Detected!!!\n",
            "\n",
            "Prediction finished: d_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 256, 256]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.33s\n",
            "Prediction finished: d_reexport1_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.28s\n",
            "Prediction finished: d_reexport1_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.31s\n",
            "Prediction finished: d_reexport1_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.31s\n",
            "Prediction finished: d_reexport1_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 502, 500]); costing: 0.27s\n",
            "Prediction finished: d_reexport1_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.23s\n",
            "Prediction finished: d_reexport1_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.30s\n",
            "Prediction finished: d_reexport1_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.29s\n",
            "Prediction finished: d_reexport1_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.25s\n",
            "Prediction finished: d_reexport1_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.23s\n",
            "Prediction finished: d_reexport1_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.23s\n",
            "Prediction finished: d_reexport1_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.23s\n",
            "Prediction finished: d_reexport1_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.24s\n",
            "Prediction finished: d_reexport1_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 420, 350]); costing: 0.26s\n",
            "Prediction finished: d_reexport1_crop_4.tiff; img size = torch.Size([1, 3, 2000, 1988]); costing: 12.55s\n",
            "Prediction finished: d_reexport2_crop_1.tiff; img size = torch.Size([1, 3, 950, 1000]); costing: 2.54s\n",
            "Prediction finished: d_reexport2_crop_2_frame_0.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_1.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_10.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_11.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_12.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_13.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_14.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_15.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_16.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_17.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_18.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_19.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_2.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.27s\n",
            "Prediction finished: d_reexport2_crop_2_frame_20.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.29s\n",
            "Prediction finished: d_reexport2_crop_2_frame_21.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.29s\n",
            "Prediction finished: d_reexport2_crop_2_frame_22.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_23.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.28s\n",
            "Prediction finished: d_reexport2_crop_2_frame_24.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.29s\n",
            "Prediction finished: d_reexport2_crop_2_frame_25.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.30s\n",
            "Prediction finished: d_reexport2_crop_2_frame_26.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.25s\n",
            "Prediction finished: d_reexport2_crop_2_frame_27.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_28.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.24s\n",
            "Prediction finished: d_reexport2_crop_2_frame_29.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_3.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_4.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_5.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_6.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_2_frame_7.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_8.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.22s\n",
            "Prediction finished: d_reexport2_crop_2_frame_9.tiff; img size = torch.Size([1, 3, 330, 300]); costing: 0.23s\n",
            "Prediction finished: d_reexport2_crop_3_frame_0.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_1.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.73s\n",
            "Prediction finished: d_reexport2_crop_3_frame_10.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_11.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.73s\n",
            "Prediction finished: d_reexport2_crop_3_frame_12.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_13.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_14.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_15.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_16.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.69s\n",
            "Prediction finished: d_reexport2_crop_3_frame_17.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_18.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.76s\n",
            "Prediction finished: d_reexport2_crop_3_frame_19.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.75s\n",
            "Prediction finished: d_reexport2_crop_3_frame_2.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.75s\n",
            "Prediction finished: d_reexport2_crop_3_frame_20.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_21.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_22.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_23.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_24.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_25.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.71s\n",
            "Prediction finished: d_reexport2_crop_3_frame_26.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_27.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_28.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_29.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.75s\n",
            "Prediction finished: d_reexport2_crop_3_frame_3.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_4.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.70s\n",
            "Prediction finished: d_reexport2_crop_3_frame_5.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.68s\n",
            "Prediction finished: d_reexport2_crop_3_frame_6.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.77s\n",
            "Prediction finished: d_reexport2_crop_3_frame_7.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: d_reexport2_crop_3_frame_8.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.72s\n",
            "Prediction finished: d_reexport2_crop_3_frame_9.tiff; img size = torch.Size([1, 3, 570, 520]); costing: 0.74s\n",
            "Prediction finished: ddF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.44s\n",
            "Prediction finished: ddF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.29s\n",
            "Prediction finished: ddF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.28s\n",
            "Prediction finished: ddF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.29s\n",
            "Prediction finished: ddF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.28s\n",
            "Prediction finished: ddF10PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.39s\n",
            "Prediction finished: ddF10PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.27s\n",
            "Prediction finished: ddF10PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.38s\n",
            "Prediction finished: ddF10PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.31s\n",
            "Prediction finished: ddF10PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.29s\n",
            "Prediction finished: ddF10PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.40s\n",
            "Prediction finished: ddF10PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.28s\n",
            "Prediction finished: ddF10mCh_crop_1.tiff; img size = torch.Size([1, 3, 331, 661]); costing: 0.36s\n",
            "Prediction finished: ddF10mCh_crop_2.tiff; img size = torch.Size([1, 3, 479, 401]); costing: 0.23s\n",
            "Prediction finished: ddF1BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.47s\n",
            "Prediction finished: ddF1BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.48s\n",
            "Prediction finished: ddF1BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.45s\n",
            "Prediction finished: ddF1BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.48s\n",
            "Prediction finished: ddF1PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.47s\n",
            "Prediction finished: ddF1PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.47s\n",
            "Prediction finished: ddF1PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.48s\n",
            "Prediction finished: ddF1PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.41s\n",
            "Prediction finished: ddF1PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.40s\n",
            "Prediction finished: ddF1mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 527]); costing: 0.36s\n",
            "Prediction finished: ddF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.46s\n",
            "Prediction finished: ddF2BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.46s\n",
            "Prediction finished: ddF2BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.46s\n",
            "Prediction finished: ddF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.44s\n",
            "Prediction finished: ddF2BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.43s\n",
            "Prediction finished: ddF2PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.44s\n",
            "Prediction finished: ddF2PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.45s\n",
            "Prediction finished: ddF2PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.44s\n",
            "Prediction finished: ddF2PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.43s\n",
            "Prediction finished: ddF2PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.45s\n",
            "Prediction finished: ddF2PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.53s\n",
            "Prediction finished: ddF2PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.51s\n",
            "Prediction finished: ddF2PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.51s\n",
            "Prediction finished: ddF2PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.50s\n",
            "Prediction finished: ddF2PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.49s\n",
            "Prediction finished: ddF2PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.49s\n",
            "Prediction finished: ddF2PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.44s\n",
            "Prediction finished: ddF2mCh_crop_1.tiff; img size = torch.Size([1, 3, 478, 596]); costing: 0.39s\n",
            "Prediction finished: ddF2mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 451]); costing: 0.40s\n",
            "Prediction finished: ddF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.27s\n",
            "Prediction finished: ddF3PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.26s\n",
            "Prediction finished: ddF3PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.28s\n",
            "Prediction finished: ddF3mCh_crop_1.tiff; img size = torch.Size([1, 3, 451, 461]); costing: 0.23s\n",
            "Prediction finished: ddF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.28s\n",
            "Prediction finished: ddF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.31s\n",
            "Prediction finished: ddF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.26s\n",
            "Prediction finished: ddF4PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.25s\n",
            "Prediction finished: ddF4PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.26s\n",
            "Prediction finished: ddF4PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.28s\n",
            "Prediction finished: ddF4PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.27s\n",
            "Prediction finished: ddF4mCh_crop_1.tiff; img size = torch.Size([1, 3, 396, 421]); costing: 0.23s\n",
            "Prediction finished: ddF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.24s\n",
            "Prediction finished: ddF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.29s\n",
            "Prediction finished: ddF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.29s\n",
            "Prediction finished: ddF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.29s\n",
            "Prediction finished: ddF5PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.28s\n",
            "Prediction finished: ddF5PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.29s\n",
            "Prediction finished: ddF5PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.29s\n",
            "Prediction finished: ddF5PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.30s\n",
            "Prediction finished: ddF5PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.30s\n",
            "Prediction finished: ddF5PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.30s\n",
            "Prediction finished: ddF5mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 351]); costing: 0.26s\n",
            "Prediction finished: ddF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.45s\n",
            "Prediction finished: ddF6BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.44s\n",
            "Prediction finished: ddF6BF_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.44s\n",
            "Prediction finished: ddF6BF_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.45s\n",
            "Prediction finished: ddF6BF_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.77s\n",
            "Prediction finished: ddF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6BF_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.75s\n",
            "Prediction finished: ddF6PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.82s\n",
            "Prediction finished: ddF6PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.51s\n",
            "Prediction finished: ddF6PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.82s\n",
            "Prediction finished: ddF6PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.48s\n",
            "Prediction finished: ddF6PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.82s\n",
            "Prediction finished: ddF6PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.43s\n",
            "Prediction finished: ddF6PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.44s\n",
            "Prediction finished: ddF6PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.76s\n",
            "Prediction finished: ddF6mCh_crop_1.tiff; img size = torch.Size([1, 3, 432, 551]); costing: 0.38s\n",
            "Prediction finished: ddF6mCh_crop_2.tiff; img size = torch.Size([1, 3, 551, 551]); costing: 0.67s\n",
            "Prediction finished: ddF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.44s\n",
            "Prediction finished: ddF7BF_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.26s\n",
            "Prediction finished: ddF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7BF_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.25s\n",
            "Prediction finished: ddF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7BF_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.41s\n",
            "Prediction finished: ddF7BF_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7BF_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.24s\n",
            "Prediction finished: ddF7PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.40s\n",
            "Prediction finished: ddF7PhC_1.5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.25s\n",
            "Prediction finished: ddF7PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.43s\n",
            "Prediction finished: ddF7PhC_10_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.25s\n",
            "Prediction finished: ddF7PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.39s\n",
            "Prediction finished: ddF7PhC_1_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.32s\n",
            "Prediction finished: ddF7PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.49s\n",
            "Prediction finished: ddF7PhC_20_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.30s\n",
            "Prediction finished: ddF7PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.45s\n",
            "Prediction finished: ddF7PhC_2_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.28s\n",
            "Prediction finished: ddF7PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.49s\n",
            "Prediction finished: ddF7PhC_5_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.29s\n",
            "Prediction finished: ddF7mCh_crop_1.tiff; img size = torch.Size([1, 3, 351, 701]); costing: 0.42s\n",
            "Prediction finished: ddF7mCh_crop_2.tiff; img size = torch.Size([1, 3, 371, 301]); costing: 0.22s\n",
            "Prediction finished: ddF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.39s\n",
            "Prediction finished: ddF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.39s\n",
            "Prediction finished: ddF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.39s\n",
            "Prediction finished: ddF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.41s\n",
            "Prediction finished: ddF8PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.41s\n",
            "Prediction finished: ddF8PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.41s\n",
            "Prediction finished: ddF8PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.41s\n",
            "Prediction finished: ddF8PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.40s\n",
            "Prediction finished: ddF8mCh_crop_1.tiff; img size = torch.Size([1, 3, 301, 601]); costing: 0.36s\n",
            "Prediction finished: ddF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.25s\n",
            "Prediction finished: ddF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.26s\n",
            "Prediction finished: ddF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.26s\n",
            "Prediction finished: ddF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.26s\n",
            "Prediction finished: ddF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.25s\n",
            "Prediction finished: ddF9PhC_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.25s\n",
            "Prediction finished: ddF9PhC_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.25s\n",
            "Prediction finished: ddF9PhC_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9PhC_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9PhC_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9PhC_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.27s\n",
            "Prediction finished: ddF9mCh_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.23s\n",
            "Prediction finished: fab1_002_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.25s\n",
            "Prediction finished: fab1_022_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.08s\n",
            "Prediction finished: fig4_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 13.68s\n",
            "Prediction finished: ibidi1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.42s\n",
            "Prediction finished: ibidi1out1_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.41s\n",
            "Prediction finished: ibidi1out1b_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.41s\n",
            "Prediction finished: ibidi1out2_crop_1.tiff; img size = torch.Size([1, 3, 622, 355]); costing: 0.42s\n",
            "Prediction finished: ibidi2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.30s\n",
            "Prediction finished: ibidi2out1_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.29s\n",
            "Prediction finished: ibidi2out2_crop_1.tiff; img size = torch.Size([1, 3, 393, 505]); costing: 0.28s\n",
            "Prediction finished: ibidi3_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 0.44s\n",
            "Prediction finished: ibidi3out1_crop_1.tiff; img size = torch.Size([1, 3, 584, 412]); costing: 0.42s\n",
            "Prediction finished: ibidi4_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 0.26s\n",
            "Prediction finished: ibidi4out1_crop_1.tiff; img size = torch.Size([1, 3, 318, 428]); costing: 0.26s\n",
            "Prediction finished: ibidi5_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.80s\n",
            "Prediction finished: ibidi5out1_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.77s\n",
            "Prediction finished: ibidi5out2_crop_1.tiff; img size = torch.Size([1, 3, 539, 681]); costing: 0.77s\n",
            "Prediction finished: image1_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.04s\n",
            "Prediction finished: image2_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.79s\n",
            "Prediction finished: image3_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: image4_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.74s\n",
            "Prediction finished: image5_crop_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.76s\n",
            "Prediction finished: long1_crop_1.tiff; img size = torch.Size([1, 3, 653, 843]); costing: 1.28s\n",
            "Prediction finished: long2_crop_1.tiff; img size = torch.Size([1, 3, 960, 960]); costing: 3.10s\n",
            "Prediction finished: long3_crop_1.tiff; img size = torch.Size([1, 3, 675, 838]); costing: 1.24s\n",
            "Prediction finished: long4_crop_1.tiff; img size = torch.Size([1, 3, 728, 890]); costing: 1.74s\n",
            "Prediction finished: m_reexport1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.52s\n",
            "Prediction finished: m_reexport1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.51s\n",
            "Prediction finished: m_reexport1_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.55s\n",
            "Prediction finished: m_reexport1_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.66s\n",
            "Prediction finished: m_reexport1_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.66s\n",
            "Prediction finished: m_reexport1_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.59s\n",
            "Prediction finished: m_reexport1_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.59s\n",
            "Prediction finished: m_reexport1_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.59s\n",
            "Prediction finished: m_reexport1_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.61s\n",
            "Prediction finished: m_reexport1_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.64s\n",
            "Prediction finished: m_reexport1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.55s\n",
            "Prediction finished: m_reexport1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.65s\n",
            "Prediction finished: m_reexport1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.55s\n",
            "Prediction finished: m_reexport1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.54s\n",
            "Prediction finished: m_reexport1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.54s\n",
            "Prediction finished: m_reexport1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.53s\n",
            "Prediction finished: m_reexport1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.54s\n",
            "Prediction finished: m_reexport1_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 800, 800]); costing: 1.57s\n",
            "Prediction finished: merged_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.73s\n",
            "Prediction finished: merged_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.70s\n",
            "Prediction finished: merged_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "Prediction finished: merged_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: merged_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_25.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_26.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.68s\n",
            "Prediction finished: merged_crop_1_frame_27.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_28.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_29.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_30.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.68s\n",
            "Prediction finished: merged_crop_1_frame_31.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_32.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_33.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_34.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: merged_crop_1_frame_35.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "Prediction finished: merged_crop_1_frame_36.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_37.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_38.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_39.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: merged_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_40.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_41.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_42.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_43.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.03s\n",
            "Prediction finished: merged_crop_1_frame_44.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.93s\n",
            "Prediction finished: merged_crop_1_frame_45.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.02s\n",
            "Prediction finished: merged_crop_1_frame_46.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.11s\n",
            "Prediction finished: merged_crop_1_frame_47.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.82s\n",
            "Prediction finished: merged_crop_1_frame_48.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.80s\n",
            "Prediction finished: merged_crop_1_frame_49.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.83s\n",
            "Prediction finished: merged_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_50.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.76s\n",
            "Prediction finished: merged_crop_1_frame_51.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.85s\n",
            "Prediction finished: merged_crop_1_frame_52.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: merged_crop_1_frame_53.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_54.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "Prediction finished: merged_crop_1_frame_55.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.63s\n",
            "Prediction finished: merged_crop_1_frame_56.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_57.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.89s\n",
            "Prediction finished: merged_crop_1_frame_58.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.88s\n",
            "Prediction finished: merged_crop_1_frame_59.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.00s\n",
            "Prediction finished: merged_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_60.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 3.02s\n",
            "Prediction finished: merged_crop_1_frame_61.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.90s\n",
            "Prediction finished: merged_crop_1_frame_62.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_63.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_64.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_65.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.77s\n",
            "Prediction finished: merged_crop_1_frame_66.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.56s\n",
            "Prediction finished: merged_crop_1_frame_67.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_68.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_69.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: merged_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_70.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_71.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_72.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.58s\n",
            "Prediction finished: merged_crop_1_frame_73.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: merged_crop_1_frame_74.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_75.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.59s\n",
            "Prediction finished: merged_crop_1_frame_76.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.60s\n",
            "Prediction finished: merged_crop_1_frame_77.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_78.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.72s\n",
            "Prediction finished: merged_crop_1_frame_79.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.57s\n",
            "Prediction finished: merged_crop_1_frame_80.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.61s\n",
            "Prediction finished: merged_crop_1_frame_81.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.67s\n",
            "Prediction finished: merged_crop_1_frame_82.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.71s\n",
            "Prediction finished: merged_crop_1_frame_83.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "Prediction finished: merged_crop_1_frame_84.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_85.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "Prediction finished: merged_crop_1_frame_86.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.77s\n",
            "Prediction finished: merged_crop_1_frame_87.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "Prediction finished: merged_crop_1_frame_88.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.65s\n",
            "Prediction finished: merged_crop_1_frame_89.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.64s\n",
            "Prediction finished: merged_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.62s\n",
            "Prediction finished: merged_crop_1_frame_90.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.77s\n",
            "Prediction finished: merged_crop_1_frame_91.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.66s\n",
            "Prediction finished: merged_crop_1_frame_92.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.70s\n",
            "Prediction finished: merged_crop_1_frame_93.tiff; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.76s\n",
            "Prediction finished: pFB_s10_t25_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.30s\n",
            "Prediction finished: pFB_s1_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.38s\n",
            "Prediction finished: pFB_s4_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.37s\n",
            "Prediction finished: pFB_s5_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.24s\n",
            "Prediction finished: pFB_s6_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.34s\n",
            "Prediction finished: pFB_s8_t60_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.41s\n",
            "Prediction finished: pFB_s9_t74_crop_1.tiff; img size = torch.Size([1, 3, 512, 512]); costing: 0.41s\n",
            "Prediction finished: pMP_pos0_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 14.13s\n",
            "Prediction finished: pMP_pos0_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.52s\n",
            "Prediction finished: pMP_pos1_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.39s\n",
            "Prediction finished: pMP_pos1_8_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.39s\n",
            "Prediction finished: pMP_pos2_0_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.32s\n",
            "Prediction finished: pMPpos0_004_crop_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.01s\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.11s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_025_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 11.49s\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.20s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_050_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 11.53s\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 13.26s\n",
            "[!Caution] Only 0 Cells Detected!!!\n",
            "\n",
            "Prediction finished: pMPpos0_083_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 2048, 2048]); costing: 11.49s\n",
            "Prediction finished: pSP_102_crop_1.tiff; img size = torch.Size([1, 3, 1899, 440]); costing: 1.46s\n",
            "Prediction finished: pSP_102_crop_2.tiff; img size = torch.Size([1, 3, 571, 869]); costing: 0.99s\n",
            "Prediction finished: pSP_102_crop_3.tiff; img size = torch.Size([1, 3, 401, 589]); costing: 0.38s\n",
            "Prediction finished: pSP_58_crop_1.tiff; img size = torch.Size([1, 3, 1700, 1969]); costing: 10.00s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.07s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 15.90s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.76s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.24s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.95s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.48s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.56s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 16.76s\n",
            "Prediction finished: sc1_972_1_MMStack_Pos0.ome_1_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1968, 1968]); costing: 17.00s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.22s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.19s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.75s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.91s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.47s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 15.07s\n",
            "Prediction finished: sc313_1_MMStack_Pos0.ome_2_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1978, 1968]); costing: 14.93s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.11s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 14.90s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.57s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 16.57s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 16.40s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.44s\n",
            "Prediction finished: sc370_wee1-50_4h_1_MMStack_Pos0.ome_1_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1968, 1988]); costing: 15.34s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.27s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.54s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.93s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.08s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.52s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.36s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.94s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 11.28s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 12.58s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.77s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.57s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 14.99s\n",
            "Prediction finished: sc370_wee1-50_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1940, 1940]); costing: 13.61s\n",
            "Prediction finished: sc472_021220_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.05s\n",
            "Prediction finished: sc472_021220_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.14s\n",
            "Prediction finished: sc472_021220_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.47s\n",
            "Prediction finished: sc472_021220_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.60s\n",
            "Prediction finished: sc472_021220_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.20s\n",
            "Prediction finished: sc472_021220_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.62s\n",
            "Prediction finished: sc472_021220_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.23s\n",
            "Prediction finished: sc472_021220_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.49s\n",
            "Prediction finished: sc472_021220_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.16s\n",
            "Prediction finished: sc472_021220_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.45s\n",
            "Prediction finished: sc472_021220_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 17.77s\n",
            "Prediction finished: sc472_021220_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 17.49s\n",
            "Prediction finished: sc472_021220_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.33s\n",
            "Prediction finished: sc472_021220_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.69s\n",
            "Prediction finished: sc472_021220_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.02s\n",
            "Prediction finished: sc472_021220_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.30s\n",
            "Prediction finished: sc472_021220_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.90s\n",
            "Prediction finished: sc472_021220_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 16.86s\n",
            "Prediction finished: sc472_021220_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.45s\n",
            "Prediction finished: sc472_021220_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.98s\n",
            "Prediction finished: sc472_021220_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.20s\n",
            "Prediction finished: sc472_021220_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.48s\n",
            "Prediction finished: sc472_021220_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.00s\n",
            "Prediction finished: sc472_021220_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.34s\n",
            "Prediction finished: sc472_300920_crop_1_frame_0.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.11s\n",
            "Prediction finished: sc472_300920_crop_1_frame_1.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.94s\n",
            "Prediction finished: sc472_300920_crop_1_frame_10.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.79s\n",
            "Prediction finished: sc472_300920_crop_1_frame_11.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.43s\n",
            "Prediction finished: sc472_300920_crop_1_frame_12.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.71s\n",
            "Prediction finished: sc472_300920_crop_1_frame_13.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.63s\n",
            "Prediction finished: sc472_300920_crop_1_frame_14.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.93s\n",
            "Prediction finished: sc472_300920_crop_1_frame_15.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.70s\n",
            "Prediction finished: sc472_300920_crop_1_frame_16.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.79s\n",
            "Prediction finished: sc472_300920_crop_1_frame_17.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.08s\n",
            "Prediction finished: sc472_300920_crop_1_frame_18.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.65s\n",
            "Prediction finished: sc472_300920_crop_1_frame_19.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.87s\n",
            "Prediction finished: sc472_300920_crop_1_frame_2.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.89s\n",
            "Prediction finished: sc472_300920_crop_1_frame_20.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.75s\n",
            "Prediction finished: sc472_300920_crop_1_frame_21.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.38s\n",
            "Prediction finished: sc472_300920_crop_1_frame_22.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.35s\n",
            "Prediction finished: sc472_300920_crop_1_frame_23.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.81s\n",
            "Prediction finished: sc472_300920_crop_1_frame_24.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.65s\n",
            "Prediction finished: sc472_300920_crop_1_frame_3.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.21s\n",
            "Prediction finished: sc472_300920_crop_1_frame_4.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.07s\n",
            "Prediction finished: sc472_300920_crop_1_frame_5.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.65s\n",
            "Prediction finished: sc472_300920_crop_1_frame_6.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.87s\n",
            "Prediction finished: sc472_300920_crop_1_frame_7.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 14.94s\n",
            "Prediction finished: sc472_300920_crop_1_frame_8.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.78s\n",
            "Prediction finished: sc472_300920_crop_1_frame_9.tiff; img size = torch.Size([1, 3, 1960, 1960]); costing: 15.80s\n",
            "Prediction finished: small1_crop_1.tiff; img size = torch.Size([1, 3, 478, 604]); costing: 0.50s\n",
            "Prediction finished: small2_crop_1.tiff; img size = torch.Size([1, 3, 478, 652]); costing: 0.61s\n",
            "Prediction finished: small3_crop_1.tiff; img size = torch.Size([1, 3, 344, 331]); costing: 0.28s\n",
            "Prediction finished: v_cdc20null_crop_1.tiff; img size = torch.Size([1, 3, 820, 1070]); costing: 2.36s\n",
            "Prediction finished: v_clnnull_crop_1.tiff; img size = torch.Size([1, 3, 1050, 1000]); costing: 2.76s\n",
            "Prediction finished: vac14_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 13.99s\n",
            "Prediction finished: vac14_008_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.06s\n",
            "Prediction finished: video2out_crop_1.tiff; img size = torch.Size([1, 3, 431, 267]); costing: 0.27s\n",
            "Prediction finished: video3out_crop_1.tiff; img size = torch.Size([1, 3, 370, 568]); costing: 0.41s\n",
            "Prediction finished: wt-k699_006_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 13.89s\n",
            "Prediction finished: wt-k699_018_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.11s\n",
            "Prediction finished: wt-k699_030_original_crop_1.tiff; img size = torch.Size([1, 3, 1870, 2520]); costing: 14.41s\n",
            "Prediction finished: wt1_crop_1.tiff; img size = torch.Size([1, 3, 695, 650]); costing: 1.36s\n",
            "Prediction finished: wt2_crop_1.tiff; img size = torch.Size([1, 3, 1007, 800]); costing: 2.71s\n",
            "Prediction finished: wt3_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 2.61s\n",
            "Prediction finished: wt3out1_crop_1.tiff; img size = torch.Size([1, 3, 743, 930]); costing: 2.56s\n",
            "Prediction finished: wtF10BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.86s\n",
            "Prediction finished: wtF10BF_1.5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.31s\n",
            "Prediction finished: wtF10BF_10_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 2.00s\n",
            "Prediction finished: wtF10BF_10_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.37s\n",
            "Prediction finished: wtF10BF_1_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.85s\n",
            "Prediction finished: wtF10BF_1_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_20_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.85s\n",
            "Prediction finished: wtF10BF_20_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_2_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.86s\n",
            "Prediction finished: wtF10BF_2_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.30s\n",
            "Prediction finished: wtF10BF_5_crop_1.tiff; img size = torch.Size([1, 3, 773, 844]); costing: 1.85s\n",
            "Prediction finished: wtF10BF_5_crop_2.tiff; img size = torch.Size([1, 3, 411, 425]); costing: 0.31s\n",
            "Prediction finished: wtF11BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.43s\n",
            "Prediction finished: wtF11BF_10_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.43s\n",
            "Prediction finished: wtF11BF_1_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.43s\n",
            "Prediction finished: wtF11BF_20_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.49s\n",
            "Prediction finished: wtF11BF_2_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.48s\n",
            "Prediction finished: wtF11BF_5_crop_1.tiff; img size = torch.Size([1, 3, 431, 533]); costing: 0.48s\n",
            "Prediction finished: wtF12BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.76s\n",
            "Prediction finished: wtF12BF_10_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.76s\n",
            "Prediction finished: wtF12BF_1_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.75s\n",
            "Prediction finished: wtF12BF_20_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.75s\n",
            "Prediction finished: wtF12BF_2_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.74s\n",
            "Prediction finished: wtF12BF_5_crop_1.tiff; img size = torch.Size([1, 3, 748, 717]); costing: 1.74s\n",
            "Prediction finished: wtF13BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.31s\n",
            "Prediction finished: wtF13BF_10_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.39s\n",
            "Prediction finished: wtF13BF_1_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.36s\n",
            "Prediction finished: wtF13BF_20_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.36s\n",
            "Prediction finished: wtF13BF_2_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.36s\n",
            "Prediction finished: wtF13BF_5_crop_1.tiff; img size = torch.Size([1, 3, 425, 459]); costing: 0.35s\n",
            "Prediction finished: wtF14BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.17s\n",
            "Prediction finished: wtF14BF_10_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.08s\n",
            "Prediction finished: wtF14BF_1_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.07s\n",
            "Prediction finished: wtF14BF_20_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.07s\n",
            "Prediction finished: wtF14BF_2_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.07s\n",
            "Prediction finished: wtF14BF_5_crop_1.tiff; img size = torch.Size([1, 3, 547, 864]); costing: 1.07s\n",
            "Prediction finished: wtF15BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF15BF_10_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF15BF_1_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF15BF_20_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF15BF_2_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF15BF_5_crop_1.tiff; img size = torch.Size([1, 3, 421, 451]); costing: 0.30s\n",
            "Prediction finished: wtF2BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.79s\n",
            "Prediction finished: wtF2BF_10_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.79s\n",
            "Prediction finished: wtF2BF_1_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.87s\n",
            "Prediction finished: wtF2BF_20_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.87s\n",
            "Prediction finished: wtF2BF_2_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.87s\n",
            "Prediction finished: wtF2BF_5_crop_1.tiff; img size = torch.Size([1, 3, 531, 634]); costing: 0.84s\n",
            "Prediction finished: wtF3BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF3BF_10_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.44s\n",
            "Prediction finished: wtF3BF_1_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF3BF_20_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF3BF_2_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF3BF_5_crop_1.tiff; img size = torch.Size([1, 3, 441, 531]); costing: 0.45s\n",
            "Prediction finished: wtF4BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.47s\n",
            "Prediction finished: wtF4BF_10_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.45s\n",
            "Prediction finished: wtF4BF_1_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.46s\n",
            "Prediction finished: wtF4BF_20_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.45s\n",
            "Prediction finished: wtF4BF_2_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.45s\n",
            "Prediction finished: wtF4BF_5_crop_1.tiff; img size = torch.Size([1, 3, 373, 535]); costing: 0.45s\n",
            "Prediction finished: wtF5BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_10_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.28s\n",
            "Prediction finished: wtF5BF_1_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_20_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_2_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF5BF_5_crop_1.tiff; img size = torch.Size([1, 3, 399, 446]); costing: 0.27s\n",
            "Prediction finished: wtF6BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_10_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_1_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_20_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.51s\n",
            "Prediction finished: wtF6BF_2_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.58s\n",
            "Prediction finished: wtF6BF_5_crop_1.tiff; img size = torch.Size([1, 3, 491, 637]); costing: 0.57s\n",
            "Prediction finished: wtF7BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.57s\n",
            "Prediction finished: wtF7BF_10_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.56s\n",
            "Prediction finished: wtF7BF_1_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.54s\n",
            "Prediction finished: wtF7BF_20_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.49s\n",
            "Prediction finished: wtF7BF_2_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.51s\n",
            "Prediction finished: wtF7BF_5_crop_1.tiff; img size = torch.Size([1, 3, 479, 531]); costing: 0.50s\n",
            "Prediction finished: wtF8BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.82s\n",
            "Prediction finished: wtF8BF_10_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.83s\n",
            "Prediction finished: wtF8BF_1_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.83s\n",
            "Prediction finished: wtF8BF_20_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.83s\n",
            "Prediction finished: wtF8BF_2_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.82s\n",
            "Prediction finished: wtF8BF_5_crop_1.tiff; img size = torch.Size([1, 3, 621, 565]); costing: 0.81s\n",
            "Prediction finished: wtF9BF_1.5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: wtF9BF_10_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_1_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_20_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wtF9BF_2_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.30s\n",
            "Prediction finished: wtF9BF_5_crop_1.tiff; img size = torch.Size([1, 3, 401, 401]); costing: 0.29s\n",
            "Prediction finished: wt_live003_cropped_crop_1.tiff; img size = torch.Size([1, 3, 1459, 1459]); costing: 5.82s\n",
            "Prediction finished: z2_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 4.13s\n",
            "Prediction finished: z3_crop_1.tiff; img size = torch.Size([1, 3, 1040, 1392]); costing: 4.09s\n",
            "\n",
            " Total Time Cost: 3937.50s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_p11218_0843.zip\n",
            "\n",
            "  8% 225/2869 [00:12<02:07, 20.78it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "  8% 228/2869 [00:12<01:57, 22.49it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 23% 655/2869 [00:18<00:25, 85.76it/s]No segmentation results!\n",
            " 23% 672/2869 [00:18<00:32, 67.47it/s]No segmentation results!\n",
            "No segmentation results!\n",
            "No segmentation results!\n",
            " 24% 680/2869 [00:18<00:34, 63.71it/s]No segmentation results!\n",
            "No segmentation results!\n",
            " 24% 694/2869 [00:18<00:34, 62.63it/s]No segmentation results!\n",
            " 25% 715/2869 [00:19<00:35, 61.50it/s]No segmentation results!\n",
            " 25% 722/2869 [00:19<00:36, 58.75it/s]No segmentation results!\n",
            " 26% 735/2869 [00:19<00:36, 58.98it/s]No segmentation results!\n",
            " 26% 755/2869 [00:19<00:35, 59.04it/s]No segmentation results!\n",
            " 27% 768/2869 [00:19<00:35, 59.96it/s]No segmentation results!\n",
            " 27% 774/2869 [00:20<00:39, 53.45it/s]No segmentation results!\n",
            " 27% 780/2869 [00:20<01:11, 29.42it/s]No segmentation results!\n",
            "No segmentation results!\n",
            " 27% 785/2869 [00:21<02:07, 16.34it/s]No segmentation results!\n",
            "No segmentation results!\n",
            " 28% 792/2869 [00:22<03:31,  9.84it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 28% 794/2869 [00:22<03:24, 10.17it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 20201221_LLY3752_Gal+aa_OD2_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 52% 1502/2869 [00:56<01:01, 22.15it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file 7_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1927/2869 [01:43<01:17, 12.18it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 67% 1933/2869 [01:44<01:04, 14.50it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1939/2869 [01:44<00:53, 17.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1945/2869 [01:44<00:45, 20.38it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1951/2869 [01:44<00:37, 24.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1956/2869 [01:44<00:33, 27.16it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 68% 1962/2869 [01:44<00:28, 31.41it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1972/2869 [01:45<00:28, 30.97it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1976/2869 [01:45<00:27, 32.31it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 69% 1984/2869 [01:45<00:44, 19.83it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 1994/2869 [01:46<01:06, 13.06it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2005/2869 [01:47<01:18, 10.96it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2016/2869 [01:48<01:34,  9.01it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 70% 2022/2869 [01:49<01:53,  7.46it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2027/2869 [01:49<01:34,  8.93it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2033/2869 [01:50<00:53, 15.57it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2040/2869 [01:50<00:41, 19.99it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 71% 2048/2869 [01:50<00:46, 17.83it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2055/2869 [01:51<00:45, 18.08it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2061/2869 [01:51<00:42, 19.03it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file cdc20F9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2067/2869 [01:51<00:36, 22.22it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2072/2869 [01:51<00:27, 28.53it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 72% 2078/2869 [01:52<00:22, 35.21it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2085/2869 [01:53<01:28,  8.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF11PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2094/2869 [01:55<01:58,  6.52it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2099/2869 [01:55<01:17,  9.91it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 73% 2106/2869 [01:55<00:58, 12.99it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2113/2869 [01:56<01:09, 10.87it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2118/2869 [01:56<01:06, 11.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2125/2869 [01:57<00:42, 17.37it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2131/2869 [01:57<00:34, 21.09it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 74% 2136/2869 [01:57<00:27, 26.40it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2145/2869 [01:57<00:26, 26.91it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2151/2869 [01:58<00:44, 16.05it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2158/2869 [01:59<00:56, 12.66it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 75% 2165/2869 [01:59<00:51, 13.77it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2172/2869 [02:00<01:18,  8.88it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2178/2869 [02:01<02:00,  5.72it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2185/2869 [02:02<01:38,  6.96it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 76% 2189/2869 [02:02<00:58, 11.69it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2198/2869 [02:03<00:47, 14.17it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 77% 2203/2869 [02:03<00:40, 16.53it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file clnF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 82% 2362/2869 [02:08<00:19, 26.47it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2375/2869 [02:08<00:14, 33.29it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF10PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2384/2869 [02:08<00:13, 35.47it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 83% 2389/2869 [02:08<00:12, 38.90it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF1PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2402/2869 [02:09<00:13, 33.82it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2410/2869 [02:09<00:14, 32.47it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF2PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 84% 2422/2869 [02:09<00:15, 29.14it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2427/2869 [02:10<00:13, 32.37it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF3PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2436/2869 [02:10<00:11, 36.65it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2441/2869 [02:10<00:10, 39.39it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF4PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 85% 2447/2869 [02:10<00:09, 43.34it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2454/2869 [02:10<00:08, 48.47it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF5PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2460/2869 [02:10<00:08, 49.87it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 86% 2476/2869 [02:11<00:11, 33.78it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF6PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2488/2869 [02:11<00:12, 30.90it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2499/2869 [02:11<00:09, 37.59it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF7PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 87% 2509/2869 [02:12<00:08, 41.90it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2515/2869 [02:12<00:08, 43.89it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF8PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2520/2869 [02:12<00:07, 44.00it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 88% 2526/2869 [02:12<00:07, 46.31it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file ddF9PhC_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 94% 2687/2869 [02:40<01:42,  1.78it/s]No segmentation results!\n",
            " 94% 2689/2869 [02:41<02:10,  1.38it/s]No segmentation results!\n",
            " 94% 2691/2869 [02:43<02:15,  1.31it/s]No segmentation results!\n",
            " 94% 2696/2869 [02:44<01:03,  2.72it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc1_972_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc313_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file sc370_wee1-50_4h_1_MMStack_Pos0_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2781/2869 [03:47<00:12,  7.16it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF10BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2787/2869 [03:47<00:06, 12.11it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF11BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 97% 2795/2869 [03:48<00:03, 19.76it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF12BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2801/2869 [03:48<00:03, 19.05it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF13BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2806/2869 [03:48<00:02, 25.67it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF14BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2812/2869 [03:48<00:02, 21.61it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF15BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2817/2869 [03:48<00:01, 27.55it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF2BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 98% 2825/2869 [03:49<00:01, 24.77it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF3BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2832/2869 [03:49<00:01, 26.38it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF4BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2838/2869 [03:49<00:01, 27.10it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF5BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2843/2869 [03:49<00:00, 28.87it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF6BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            " 99% 2849/2869 [03:50<00:00, 23.21it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF7BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2855/2869 [03:50<00:00, 21.27it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF8BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2861/2869 [03:50<00:00, 19.89it/s]/content/ml-project-2-doughminators/./evaluate.py:48: UserWarning: Warning: file wtF9BF_1_label.tiff missing\n",
            "  warnings.warn(f\"Warning: file {name} missing\")\n",
            "100% 2869/2869 [03:52<00:00, 12.35it/s]\n",
            "mean F1 Score: 0.7818098017621145 +/- 0.004757400355406547\n",
            "mean AP Score: 0.6989576358296623 +/- 0.005463532680623696\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ (stored 0%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_91_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_6_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_116_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t1_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_23_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_106_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi5out2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_8_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210308_SW646_Asymmetric01_4_03_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_08_Z_54_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_116_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_0_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_42_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_29_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_27_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_25_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_112_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_37_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_50_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_18_Z_43_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_27_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_115_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8out1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_5_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_91_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_0_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_14_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_10_crop_1_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_76_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_20_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_16_Z_43_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_11_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_89_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_10_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_31_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_43_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_66_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_10_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_4_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_1_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_43_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_53_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_27_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_5_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_27_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10mCh_crop_2_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_5_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_49_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_119_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_4_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_28_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_2_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_40_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_0_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi2out1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_42_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_08_Z_61_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_91_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_1_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_28_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_10_Z_64_100_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_8_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9mCh_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_5_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_93_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_73_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_2_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_6_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_55_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_75_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_19_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_5_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_7_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_20_crop_1_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_91_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7mCh_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_8_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_3_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_28_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_18_label.tiff (deflated 77%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/z2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_10_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_115_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_05_Z_50_100_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_10_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_68_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_39_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_4_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_38_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_45_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_23_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_2_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_0_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_44_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_89_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_0_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_5_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_0_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_6_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_33_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_025_crop_1_frame_0_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_75_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_48_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_6_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_45_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_02_02_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_13_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_1_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_21_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_53_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_10_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_10_Z_41_100_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_25_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_89_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_107_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_72_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_25_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_35_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_20_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_102_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_1_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_33_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_93_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_52_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_16_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s5_t74_crop_1_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_7_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_5_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8mCh_crop_1_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_79_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_7_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_61_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_80_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_37_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_25_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_32_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_19_label.tiff (deflated 77%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_2_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_5_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_108_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_104_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_0_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_10_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/20200305_30C_Late_SW183pp_SW184_mad3CO_09_R3D_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_93_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_73_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_95_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_92_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_20_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_108_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_52_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_33_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_5_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_96_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi1out1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_29_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_1_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_35_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi3out1_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_20_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_76_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_2_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_61_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_26_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_110_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_1_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_22_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_59_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_3_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7mCh_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_72_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_8_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_5_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_26_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_14_Z_39_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_5_crop_1_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_57_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_25_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_66_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_1_label.tiff (deflated 91%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5mCh_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_37_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_65_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_1_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_111_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_2_crop_1_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_63_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_19_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_20_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_108_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_8_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_46_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_0_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_12_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_2_crop_1_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_7_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_44_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_106_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_3_frame_3_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_7_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_22_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_44_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_95_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_10_Z_48_100_crop_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_30_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_75_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_23_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_101_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_26_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_12_Z_52_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_62_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_84_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_2_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_41_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_96_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_10_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7out1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_3_frame_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_67_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_51_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_15_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_73_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_2_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_2_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_06_Z_59_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_58_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_18_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_67_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_35_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_4_label.tiff (deflated 60%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_120_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_2_frame_3_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_6_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_07_Z_60_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_0_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_31_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_2_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_73_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_39_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_16_label.tiff (deflated 60%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_18_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_11_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_16_Z_57_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_82_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_0_label.tiff (deflated 64%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_37_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_1_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_51_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_83_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_2_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_47_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_10_Z_41_100_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pSP_102_crop_1_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_34_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_0_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_34_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_62_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_74_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_59_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_5_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_1_label.tiff (deflated 91%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_31_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_19_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_58_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_4_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_2_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f3_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_64_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_1_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_48_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_29_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_9_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_34_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_68_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_23_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_15_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_10_Z_72_100_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_48_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f7_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_4_frame_3_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_42_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_57_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_96_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_12_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_37_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_110_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_102_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_98_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_01_02_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_19_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_1_frame_2_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_107_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_39_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_110_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_66_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_94_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_4_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_5_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_24_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6mCh_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6mCh_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_71_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_5_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_29_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_6_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f4_crop_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_11_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_20_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_3_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_10_crop_1_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_10_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_19_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_17_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_4_frame_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_23_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_10_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t50_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_6_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_80_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_99_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_24_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_67_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_26_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_4_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_16_label.tiff (deflated 62%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_2_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_84_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_10_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_72_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_11_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_20_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_15_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_54_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_46_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_20_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_71_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_50_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_3_frame_3_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_5_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_103_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_88_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s1_t74_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_106_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_7_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_20_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_89_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_24_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_36_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_15_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_75_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_1_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_53_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_65_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 3%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_8_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_44_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_14_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_2_frame_0_label.tiff (deflated 83%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_107_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_5_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_19_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_22_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_30_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi3_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_66_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_86_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_35_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_119_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_15_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_54_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_6_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_67_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f2_crop_1_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2mCh_crop_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_16_Z_51_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_29_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_28_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_24_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_7_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_9_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_5_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f13_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_17_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f3_crop_1_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_11_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_11_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_119_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_025_crop_1_frame_1_label.tiff (deflated 96%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_17_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_2_frame_0_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_2_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_61_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_05_Z_67_100_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_55_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_9_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_54_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_39_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_64_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_86_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6mCh_crop_1_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_36_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_050_crop_1_frame_1_label.tiff (deflated 96%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_38_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_17_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_111_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_114_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/23_fm464_live098_cropped_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_1_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_1_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/long2_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_16_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_59_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_19_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_59_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_47_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_71_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_24_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f11_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_3_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Abf1_Ancestor_7_z25_BF_crop_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_7_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_49_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/z3_crop_1_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_97_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_23_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_2_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_12_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_7_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_0_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s8_t60_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_34_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_36_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p3_crop_1_frame_0_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_13_Z_54_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t200_modified_2_crop_1_frame_0_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/fab1_022_original_crop_1_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_1_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_17_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_60_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_07_Z_53_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_86_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_24_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f1_crop_1_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_56_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_22_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_18_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_10_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_18_Z_68_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_28_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_30_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_19_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_31_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_97_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_08_02_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_10_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5out1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1mCh_crop_1_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_14_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_28_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_17_label.tiff (deflated 59%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_49_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_95_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_61_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_7_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_94_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_10_Z_61_100_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_7_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_3_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_77_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pSP_102_crop_2_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_20_label.tiff (deflated 58%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_88_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_10_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_105_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_41_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_98_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_11_Z_40_100_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f4_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt-k699_006_original_crop_1_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_40_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_41_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_1_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_0_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_16_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_44_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3mCh_crop_1_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/long3_crop_1_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_116_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_0_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_70_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_3_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_11_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_28_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_4_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_6_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_6_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_7_label.tiff (deflated 62%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_87_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_3_frame_4_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_62_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_109_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_10_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p2_crop_1_frame_0_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_24_label.tiff (deflated 58%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_55_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_16_Z_47_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_2_frame_3_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f12_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_10_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_39_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_72_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_114_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_56_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_17_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_100_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_7_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_81_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_5_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_3_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_33_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_10_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_35_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_112_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_9_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_92_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_69_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_31_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_70_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_25_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_0_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_10_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8mCh_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_104_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_110_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_33_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_20_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_76_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_95_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_54_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_2_frame_2_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_37_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_34_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/v_clnnull_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_5_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_4_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_10_crop_1_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_6_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_15_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_19_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_8_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_61_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_83_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_9_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_2_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_92_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_51_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_1_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_116_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt_live003_cropped_crop_1_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_49_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_13_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_52_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_72_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_106_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_7_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_93_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_40_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_89_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_113_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_20_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/video3out_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_118_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_47_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_2_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_6_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_10_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_60_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_13_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_49_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_94_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_0_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_15_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_2_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_14_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_74_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1out2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7mCh_crop_2_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_118_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_30_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_3_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f7_crop_1_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_10_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_5_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_10_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_4_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_57_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5mCh_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_74_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t100_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_8_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_50_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_108_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_23_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_12_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_7_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_2_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_31_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pSP_102_crop_3_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_25_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_14_Z_54_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_10_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_109_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_3_label.tiff (deflated 69%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_1_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_2_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_23_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_80_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_98_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_61_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_90_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_10_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_5_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_85_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_99_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_16_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_118_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_11_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi5out1_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3mCh_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_9_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_11_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_20_crop_1_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_32_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_82_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_22_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_20_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_12_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_114_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1mCh_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_18_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_39_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_86_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_6_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_45_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_48_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_47_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_15_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_20_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_3_label.tiff (deflated 63%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_21_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_76_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_1_frame_2_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_1_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_56_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_1_crop_2_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_6_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_59_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f6_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_12_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_9_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_43_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1mCh_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_18_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_63_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_18_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/small3_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Abf1_Ancestor_5_z24_BF_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_58_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_71_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_7_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_77_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_1_frame_3_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_41_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_28_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_97_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_19_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_70_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_112_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_32_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6out1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_9_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_21_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_14_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_67_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_16_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_35_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_27_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_4_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_20_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_5_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_109_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_20_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi1out1b_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/bendy1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_2_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2out1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_13_Z_45_100_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_11_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_2_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_26_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_105_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_05_Z_44_100_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1out1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_108_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_70_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_101_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_77_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210308_SW646_Asymmetric01_4_01_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_40_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_28_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_26_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_5_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_118_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_07_01_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_0_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_53_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_101_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_37_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_58_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_83_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f5_crop_1_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_5_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_42_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_115_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_35_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_80_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_77_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_5_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_17_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2mCh_crop_2_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_13_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_2_frame_1_label.tiff (deflated 82%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_38_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_20_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_1_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_1_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_10_Z_51_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_11_Z_46_100_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_8_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_12_Z_65_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_1_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p2_crop_1_frame_3_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_104_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_21_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_90_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_24_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF11BF_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/170922_ageing-pos37-ch1-60ph-051_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_76_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_18_label.tiff (deflated 59%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_53_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_57_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_69_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_1_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_27_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_1_frame_1_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_29_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_10_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_0_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_9_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f10_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_50_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_18_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_4_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t200_modified_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_3_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_8_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_78_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9mCh_crop_1_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_8_label.tiff (deflated 62%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_8_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_0_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_20_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_51_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f9_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_19_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_6_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_10_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_64_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_64_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/20200305_30C_Late_SW183pp_SW184_mad3CO_14_R3D_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_23_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_31_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_25_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210308_SW646_Asymmetric01_4_04_crop_1_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_67_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_4_frame_4_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_1_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_17_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6out2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_78_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_41_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_22_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_1_frame_0_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_56_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_3_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_83_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_36_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_21_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_50_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_5_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_64_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_32_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_11_Z_69_100_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_07_Z_67_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_85_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_36_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_15_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s4_t74_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_12_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5mCh_crop_1_label.tiff (deflated 58%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_10_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_12_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_51_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_0_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_4_frame_0_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_2_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_115_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_4_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_27_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_10_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_90_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_2_frame_2_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_2_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_14_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_99_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_17_label.tiff (deflated 63%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_5_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_81_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_5_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p3_crop_1_frame_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_2_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_10_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_27_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_25_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/alk1alk2_011_original_crop_1_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_3_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_95_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_10_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_29_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_88_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_26_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_06_Z_53_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_23_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_117_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5out2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_4_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_12_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt-k699_030_original_crop_1_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f12_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_43_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_52_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_6_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_20_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_26_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t1_modified_crop_1_frame_1_label.tiff (deflated 91%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_49_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_7_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_78_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_14_Z_68_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_14_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_20_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_90_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_87_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_9_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_79_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_80_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_85_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_111_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_10_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_05_Z_57_100_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_20_label.tiff (deflated 63%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_12_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_57_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_54_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_9_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_1_label.tiff (deflated 91%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_93_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_74_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_26_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_14_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_87_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_21_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_60_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_25_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_4_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_11_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_19_label.tiff (deflated 60%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_54_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_13_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_26_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_20_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_100_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_68_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_20_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_22_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi1out2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_53_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_6_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_52_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_102_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_75_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_14_Z_63_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_26_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_74_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_08_Z_47_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_13_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_102_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_4_frame_2_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10mCh_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_14_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_36_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t50_modified_crop_1_frame_0_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_119_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_45_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_20_crop_2_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_23_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_65_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_4_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_48_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_14_label.tiff (deflated 65%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_06_Z_53_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_57_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_1_frame_3_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_100_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_5_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_08_Z_54_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_5_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_120_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_46_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_3_frame_2_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_60_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_15_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_06_Z_44_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_26_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_13_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_68_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_70_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_2_crop_1_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_29_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_07_Z_45_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_70_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_23_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_63_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc313_1_MMStack_Pos0_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/fig4_006_original_crop_1_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_5_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/20200305_30C_Late_SW183pp_SW184_mad3CO_16_R3D_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4out1_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_99_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_23_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/image2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/small2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_2_frame_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_68_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_5_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_28_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/image1_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_13_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_4_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_59_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_06_Z_65_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_004_crop_1_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_5_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_20_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_96_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_22_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4mCh_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_21_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_8_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_39_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_5_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_91_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_25_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_4_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_41_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_14_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_46_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_20_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_51_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_20_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_50_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_0_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_40_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_11_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_20_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_10_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/fab1_002_original_crop_1_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_22_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_39_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_74_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_29_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi4_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_46_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_33_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_4h_1_MMStack_Pos0_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_47_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_11_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_7_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_5_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_14_Z_46_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11mCh_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_28_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_20_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_31_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_24_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_86_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_08_Z_70_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_2_frame_1_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_12_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_103_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_117_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_29_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_0_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_93_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_84_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_106_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_79_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_13_Z_64_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f11_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_40_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_31_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_84_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/23_fm464_live095_cropped_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4out2_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_87_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_101_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210311_SW646_AsymmetricAfternoon01_3_crop_1_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_32_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_21_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_17_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_30_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_56_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_01_01_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_112_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_1_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_15_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_47_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_06_Z_65_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_4_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_38_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_74_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_29_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_18_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_50_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_77_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_19_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_21_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_27_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_0_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_42_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_65_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_1_label.tiff (deflated 65%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_109_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_116_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_27_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_85_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi5_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_5_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_4_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_4_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f6_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_3_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_63_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_13_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_08_Z_45_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/long1_crop_1_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_4_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_1_frame_0_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3out1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(6)_crop_1_frame_5_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_3_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_10_crop_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_4_label.tiff (deflated 63%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_58_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_29_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_22_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_22_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_47_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_92_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_36_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_9_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_38_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_3_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_113_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1PhC_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_18_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_16_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_16_Z_62_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_110_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_33_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_16_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_84_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_36_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_40_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_16_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_13_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_7_label.tiff (deflated 71%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_40_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_20_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_21_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_16_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_13_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_43_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_82_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_17_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_94_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_85_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_44_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMP_pos2_0_crop_1_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_22_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_15_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_24_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_20_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_2_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_4_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_76_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_69_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Abf1_Ancestor_7_z25_BF_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_56_label.tiff (deflated 39%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9mCh_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_65_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/image4_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2out2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_120_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_5_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_9_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_6_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_3_frame_1_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Abf1_Ancestor_6_z23_BF_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_73_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_82_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_18_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_3_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_54_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_62_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_24_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_16_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_19_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt-k699_018_original_crop_1_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_45_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_9_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_10_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_3_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_20_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_60_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_1_crop_1_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_22_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_21_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_06_Z_45_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_77_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_11_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_8_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_3_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_61_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_20_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_32_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_11_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_1_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/MS183_crop_1_frame_0_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_72_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_86_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_73_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF3BF_2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8out2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_1_label.tiff (deflated 52%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_97_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_71_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_23_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_38_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_5_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_48_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_16_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_83_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_10_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s10_t25_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_20_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_83_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_25_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_75_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_2_frame_4_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_65_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_11_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_79_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_1_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/image3_crop_1_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_8_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_34_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_32_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_14_Z_55_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_55_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_21_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF6BF_20_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_17_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_53_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_4_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi4out1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_98_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_66_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_1_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_8_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_22_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_57_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_109_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_84_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6BF_2_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_21_label.tiff (deflated 58%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10BF_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_41_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_2_frame_4_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_10_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_9_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p2_crop_1_frame_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_18_Z_54_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_3_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_100_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5PhC_10_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_12_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_81_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_103_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_6_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F6PhC_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_18_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_81_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_69_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_111_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_56_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_21_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_32_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMP_pos0_8_crop_1_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_1_label.tiff (deflated 63%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_92_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_62_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_11_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_16_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc370_wee1-50_crop_1_frame_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10BF_20_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_63_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_52_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_58_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_18_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_27_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_105_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/video2out_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_52_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_3_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_3_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_112_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_14_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_10_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_17_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_14_Z_70_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/vac14_006_original_crop_1_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_69_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_3_frame_0_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMP_pos0_0_crop_1_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f1_crop_1_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_49_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_20_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_55_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_083_crop_1_frame_0_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_9_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_30_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s9_t74_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_1_crop_2_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_5_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_14_Z_44_100_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_15_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_12_label.tiff (deflated 49%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_107_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_6_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_55_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_87_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_9_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5PhC_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_3_frame_0_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_11_Z_54_100_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_TL_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_96_label.tiff (deflated 38%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_5_crop_1_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_22_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_73_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pSP_58_crop_1_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_2_frame_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_1_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_12_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_38_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_14_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_7_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos10_t150_modified_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_104_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_103_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_16_Z_68_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_2_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_0_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_88_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_11_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_8_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_19_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_107_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_69_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_20_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_27_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF5BF_20_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_30_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_0_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_94_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_20_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_33_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_71_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_1_crop_1_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f2_crop_1_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7PhC_10_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_5_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_2_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_38_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_05_Z_37_100_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_11_Z_62_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_3_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_80_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF10BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_70_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2mCh_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN19_crop_1_frame_0_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_050_crop_1_frame_0_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3PhC_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/1_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_13_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_2_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_24_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7PhC_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_78_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_42_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_18_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_1_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF2BF_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_117_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_12_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11BF_20_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_5_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_9_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_38_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/170922_ageing-pos37-ch1-60ph-001_crop_1_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_20_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_114_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_28_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_2_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_59_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_15_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_10_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_102_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF9BF_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_10_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_88_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_2_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_91_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_14_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_60_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_45_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f9_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_119_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_66_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_43_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_12_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_08_01_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_20_crop_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_15_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_72_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_10_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_114_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_33_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_5_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF12BF_20_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_29_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_100_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_23_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_62_label.tiff (deflated 47%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF15BF_10_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_16_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_28_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_35_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_67_label.tiff (deflated 45%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_1_crop_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_21_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_1_frame_4_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_2_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_23_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_97_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_24_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt3_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_92_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_20_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_87_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_3_frame_4_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_44_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_6_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_2_label.tiff (deflated 77%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_78_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6BF_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_46_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_22_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_98_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_10_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-2_every5th_f8_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_12_Z_42_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_113_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF14BF_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_17_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_4_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2BF_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_34_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_22_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1PhC_5_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_89_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_113_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/small1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_79_label.tiff (deflated 31%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_64_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p2_crop_1_frame_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3out2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_3_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pFB_s6_t60_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_2_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f13_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_69_label.tiff (deflated 44%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_14_label.tiff (deflated 54%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_10_Z_57_100_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_55_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_06_Z_36_100_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_60_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/V11032020_p1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW651_SL762_mad3_tetR_07_Z_40_100_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_27_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_51_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc1_972_1_MMStack_Pos0_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_3_frame_2_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_14_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_13_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_68_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_20_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_9_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMP_pos1_0_crop_1_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_82_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10mCh_crop_1_label.tiff (deflated 36%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2BF_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_4_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_68_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_17_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_115_label.tiff (deflated 32%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_81_label.tiff (deflated 42%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_41_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_5_crop_1_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_10_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMP_pos1_8_crop_1_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_120_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_0_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_1_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_9_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7mCh_crop_1_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_1_crop_1_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/v_cdc20null_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_65_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_48_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_5_label.tiff (deflated 62%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_10_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF3BF_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_30_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_0_label.tiff (deflated 65%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF8BF_2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_11_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_64_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_20_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_10_label.tiff (deflated 58%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4PhC_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_3_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5PhC_1_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_40_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_3_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_39_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4BF_20_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_2_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_3_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4mCh_crop_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_37_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_26_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_104_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_1_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F10mCh_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_11_label.tiff (deflated 61%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_5_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/long4_crop_1_label.tiff (deflated 22%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_101_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF13BF_5_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_19_crop_1_frame_4_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_17_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_4_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_10_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_105_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_13_label.tiff (deflated 66%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_58_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_TL_crop_1_frame_3_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_111_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_43_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_1_frame_1_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF4BF_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_1_frame_28_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F1BF_10_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_1_crop_1_label.tiff (deflated 67%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_1_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_8_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_63_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_0_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_19_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2mCh_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_32_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/vac14_008_original_crop_1_label.tiff (deflated 27%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F4mCh_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_DIC_crop_1_frame_9_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF8BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF7BF_2_crop_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/5_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_99_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_62_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_46_label.tiff (deflated 26%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/image5_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/6_Ref_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_66_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_18_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_021220_crop_1_frame_18_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_15_label.tiff (deflated 37%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Ahmad_frame_16_crop_2_frame_0_label.tiff (deflated 34%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_2_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_TL_crop_1_frame_5_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF5BF_1_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_25_label.tiff (deflated 56%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_27_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF6mCh_crop_2_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_13_Zstack_TL_crop_1_frame_2_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_120_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF2PhC_10_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9PhC_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_10_Zstack_TL_crop_1_frame_9_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_8_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_17_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_5_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF1BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_24_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_1_label.tiff (deflated 21%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_8_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_4_label.tiff (deflated 40%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_15_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_TL_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/11_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020_3_24_AS20_1_AS18_Pos11_crop_1_frame_3_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ibidi2out2_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_13_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_6_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/12_Ref_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_2_frame_24_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_21_Zstack_TL_crop_1_frame_6_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_DIC_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_2_label.tiff (deflated 53%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/20201221_LLY3752_Gal+aa_OD2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wt3out1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_2_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_63_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_82_label.tiff (deflated 17%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF6PhC_1_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_117_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_15_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport2_crop_3_frame_12_label.tiff (deflated 25%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_TL_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3mCh_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/pMPpos0_083_crop_1_frame_1_label.tiff (deflated 96%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_81_label.tiff (deflated 19%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_12_Zstack_TL_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/14_Ref_Zstack_DIC_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_25_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_6_label.tiff (deflated 50%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_DIC_crop_1_frame_4_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_36_label.tiff (deflated 35%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2PhC_20_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/bendy2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_3_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF2BF_10_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_5_Zstack_TL_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/10_Ref_Zstack_TL_crop_1_frame_12_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF5mCh_crop_1_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF10PhC_2_crop_2_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F2PhC_1_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_2_frame_16_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_16_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF3BF_1_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_9_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_2_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/7out2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F3PhC_2_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/4_Ref_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_105_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_34_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_DIC_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_42_label.tiff (deflated 55%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF11PhC_2_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_16_label.tiff (deflated 28%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F7PhC_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_11_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/m_reexport1_crop_1_frame_14_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/13_Ref_Zstack_TL_crop_1_frame_13_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_TL_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9PhC_5_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF4BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_13_label.tiff (deflated 14%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_90_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_71_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_113_label.tiff (deflated 16%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_8_Zstack_DIC_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_103_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/Schmoller_crop_1_frame_85_label.tiff (deflated 41%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_2_label.tiff (deflated 48%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/alk1alk2_001_original_crop_1_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_DIC_crop_1_frame_7_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF8BF_20_crop_1_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/16_Ref_Zstack_TL_crop_1_frame_10_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(1)_crop_1_frame_90_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_24_Zstack_TL_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_78_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF1BF_5_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8mCh_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F9BF_20_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302age_SW643_cdc13_tetR_08_Z_66_100_crop_1_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_13_label.tiff (deflated 43%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_12_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_20_Zstack_TL_crop_1_frame_4_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_35_label.tiff (deflated 30%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_79_label.tiff (deflated 20%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_26_label.tiff (deflated 57%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/9_Ref_Zstack_DIC_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF10BF_10_crop_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/wtF4BF_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_2_Zstack_TL_crop_1_frame_6_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF7BF_1_crop_1_label.tiff (deflated 11%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(4)_crop_1_frame_88_label.tiff (deflated 18%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_30_label.tiff (deflated 29%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_14_Zstack_TL_crop_1_frame_4_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200302_video_cdc13_mad3_tetR_01_01_R3D_REF-1_every5th_f8_crop_1_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_23_Zstack_TL_crop_1_frame_2_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_6_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F5BF_5_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport1_crop_1_frame_21_label.tiff (deflated 33%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport3_crop_1_frame_34_label.tiff (deflated 23%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t150_modified_2_crop_1_frame_0_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3_Ref_Zstack_DIC_crop_1_frame_5_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/merged_crop_1_frame_29_label.tiff (deflated 51%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/sc472_300920_crop_1_frame_7_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/PN1192_crop_1_frame_5_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/d_reexport1_crop_3_frame_12_label.tiff (deflated 15%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/cdc20F8BF_2_crop_1_label.tiff (deflated 10%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/2020-05-21_ageing_5520_4901_1_MMStack_Pos0_t100_modified_2_crop_1_frame_1_label.tiff (deflated 91%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_7_Zstack_DIC_crop_1_frame_1_label.tiff (deflated 6%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_9_Zstack_TL_crop_1_frame_8_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/210521_Ncdc13_01_01_03_01_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(5)_crop_1_frame_45_label.tiff (deflated 46%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/8_Ref_Zstack_TL_crop_1_frame_7_label.tiff (deflated 4%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_25_Zstack_TL_crop_1_frame_8_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/a_reexport2_crop_1_frame_37_label.tiff (deflated 13%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF9BF_5_crop_1_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/ddF7BF_5_crop_2_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/3306_pad1_4_Zstack_DIC_crop_1_frame_0_label.tiff (deflated 5%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_117_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/clnF9PhC_10_crop_1_label.tiff (deflated 9%)\n",
            "  adding: content/ml-project-2-doughminators/results/phase_1_prediction/200917_JK_MS133-0003_Position(3)_crop_1_frame_118_label.tiff (deflated 8%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_2ca3942f-be6b-4c7d-bd22-e5e7aeb1c9ff\", \"phase_1_prediction.zip\", 35021584)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_1caa3625-5a13-4c0c-82eb-e54c65cedf28\", \"seg_metric.csv\", 183894)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!python predict.py --config_path=config/step3_prediction/phase_1_prediction.json\n",
        "!python ./evaluate.py --pred_path=results/phase_1_prediction --gt_path=Datasets/labels --save_path=evaluation_result/phase_1_prediction\n",
        "!zip -r /content/ml-project-2-doughminators/results/phase_1_prediction.zip /content/ml-project-2-doughminators/results/phase_1_prediction\n",
        "from google.colab import files\n",
        "files.download(\"/content/ml-project-2-doughminators/results/phase_1_prediction.zip\")\n",
        "files.download(\"/content/ml-project-2-doughminators/evaluation_result/phase_1_prediction/seg_metric.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPwRqqJyYf0V"
      },
      "source": [
        "### 3. Fine-tuning on YeaZ dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXZ6D4kmGqsB"
      },
      "source": [
        "Download the ```path1.pth``` checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXv_8J8QFsSJ",
        "outputId": "50846e76-f623-483d-cb1f-425fe0ad2413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v5tYYJDqiwTn_mV0KyX5UEonlViSNx4i\n",
            "To: /content/ml-project-2-doughminators/weights/phase1.pth\n",
            "100% 486M/486M [00:10<00:00, 47.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/file/d/1v5tYYJDqiwTn_mV0KyX5UEonlViSNx4i/view?usp=share_link --fuzzy -O weights/phase1.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLgupfh5dDcJ",
        "outputId": "395a6a37-6858-47f6-aa26-0c96099e4f18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------- Path Mapping for Labeled Data is Started... -----------\n",
            "\n",
            "0  mismatches\n",
            "\n",
            "----------- Path Mapping for Tuning Data is Started... -----------\n",
            "\n",
            ">>> \"official\" already exists in path map keys...\n",
            "\n",
            "----------- Path Mapping for Public Data is Started... -----------\n",
            "\n",
            ">>> \"public\" already exists in path map keys...\n",
            "\n",
            "-------------- Path Mapping is Ended !!! ---------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python ./generate_mapping.py --root=./Datasets/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RqqDUWYrE8R"
      },
      "source": [
        "Check that the mapping was successful, i.e., there are 2914 image/label pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJULYzQ_qa1q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "mapping = pd.read_json(\"train_tools/data_utils/mapping_labeled.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QJhOK60qsKw",
        "outputId": "6a4000fd-603d-4da5-b26e-7610fc563d67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2914"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(mapping[\"official\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tuning the phase 1 model (most general, but without having seen any challenge data)."
      ],
      "metadata": {
        "id": "rc3St39udH1k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BdkLqT0ZZaB",
        "outputId": "3f795466-2063-418d-df18-20317afb52bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'data_setups': {'labeled': {'amplified': True,\n",
            "                             'batch_size': 8,\n",
            "                             'mapping_file': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'mapping_file_tuning': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'root': './',\n",
            "                             'valid_portion': 0.2},\n",
            "                 'public': {'enabled': False,\n",
            "                            'params': {'batch_size': 1,\n",
            "                                       'mapping_file': './train_tools/data_utils/mapping_public.json',\n",
            "                                       'root': './'}},\n",
            "                 'unlabeled': {'enabled': False}},\n",
            " 'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'exp_name': 'mediar_from_phase1_on_YeaZ',\n",
            "                 'input_path': './Datasets/test/images',\n",
            "                 'make_submission': True,\n",
            "                 'output_path': './results/'},\n",
            " 'train_setups': {'model': {'name': 'mediar-former',\n",
            "                            'params': {},\n",
            "                            'pretrained': {'enabled': True,\n",
            "                                           'strict': False,\n",
            "                                           'weights': './weights/phase1.pth'}},\n",
            "                  'optimizer': {'name': 'adamw', 'params': {'lr': 2e-05}},\n",
            "                  'scheduler': {'enabled': True,\n",
            "                                'name': 'cosine',\n",
            "                                'params': {'T_max': 100, 'eta_min': 1e-07}},\n",
            "                  'seed': 19940817,\n",
            "                  'trainer': {'name': 'mediar',\n",
            "                              'params': {'algo_params': {'with_public': False},\n",
            "                                         'amp': True,\n",
            "                                         'device': 'cuda:0',\n",
            "                                         'num_epochs': 20,\n",
            "                                         'valid_frequency': 1}}},\n",
            " 'wandb_setups': {'group': 'Fine-tuning',\n",
            "                  'name': 'mediar_from_phase1_on_YeaZ',\n",
            "                  'project': 'CellSeg'}}\n",
            "========================================================================================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandre-misrahi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ml-project-2-doughminators/wandb/run-20231218_194104-bg5mwf42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmediar_from_phase1_on_YeaZ\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/bg5mwf42\u001b[0m\n",
            "\n",
            "Loading pretrained model....\n",
            "\n",
            "(DataLoaded) Training data size: 1689, Validation data size: 422\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\n",
            "==================================================\n",
            "Train start on device: NVIDIA A100-SXM4-40GB\n",
            "==================================================\n",
            "[Round 1/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:15<00:00,  3.47s/it]\n",
            "{'Train_Dice_Loss': 0.202}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:11<03:00,  2.19it/s]No segmentation results!\n",
            "  9% 40/422 [00:26<10:11,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:32,  3.46it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:53,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.72it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.06it/s]\n",
            "{'Valid_Dice_Loss': 0.193, 'Valid_F1_Score': 0.9341}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9341\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 2/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:20<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1507}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<02:59,  2.20it/s]No segmentation results!\n",
            "  9% 40/422 [00:26<11:24,  1.79s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:33,  3.43it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:52,  2.16it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1691, 'Valid_F1_Score': 0.9386}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9386\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 3/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:16<00:00,  3.48s/it]\n",
            "{'Train_Dice_Loss': 0.1397}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:00,  2.19it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:11,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.45it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1641, 'Valid_F1_Score': 0.9395}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9395\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 4/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:17<00:00,  3.48s/it]\n",
            "{'Train_Dice_Loss': 0.1321}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:00,  2.19it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:08,  1.59s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.40it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:53,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.70it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1542, 'Valid_F1_Score': 0.9435}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9435\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 5/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1285}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:17,  1.62s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.43it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:52,  2.16it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1527, 'Valid_F1_Score': 0.9435}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9435\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 6/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:19<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1284}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.17it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:15,  1.61s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.44it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:53,  2.13it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:33,  2.93it/s]No segmentation results!\n",
            " 99% 417/422 [03:22<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:23<00:01,  2.10it/s]No segmentation results!\n",
            "100% 422/422 [03:25<00:00,  2.05it/s]\n",
            "{'Valid_Dice_Loss': 0.152, 'Valid_F1_Score': 0.9437}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9437\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 7/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:18<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1216}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.17it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:16,  1.61s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.42it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:34,  2.91it/s]No segmentation results!\n",
            " 99% 417/422 [03:23<00:01,  2.64it/s]No segmentation results!\n",
            " 99% 418/422 [03:23<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:26<00:00,  2.05it/s]\n",
            "{'Valid_Dice_Loss': 0.1482, 'Valid_F1_Score': 0.9445}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9445\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 8/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:19<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1209}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:18,  1.62s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.41it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:53,  2.14it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.95it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.10it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1447, 'Valid_F1_Score': 0.9452}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9452\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 9/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:20<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1165}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:03,  2.15it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:11,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:34,  3.38it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:34,  2.86it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.65it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.10it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.06it/s]\n",
            "{'Valid_Dice_Loss': 0.138, 'Valid_F1_Score': 0.9482}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9482\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 10/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1123}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<03:04,  2.14it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:24,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:34,  3.38it/s]No segmentation results!\n",
            " 73% 308/422 [02:35<00:53,  2.13it/s]No segmentation results!\n",
            " 77% 323/422 [02:41<00:34,  2.86it/s]No segmentation results!\n",
            " 99% 417/422 [03:25<00:01,  2.64it/s]No segmentation results!\n",
            " 99% 418/422 [03:25<00:01,  2.07it/s]No segmentation results!\n",
            "100% 422/422 [03:28<00:00,  2.03it/s]\n",
            "{'Valid_Dice_Loss': 0.1372, 'Valid_F1_Score': 0.9485}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9485\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 11/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:20<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1137}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:04,  2.14it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:27,  1.64s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:34,  3.38it/s]No segmentation results!\n",
            " 73% 308/422 [02:34<00:53,  2.13it/s]No segmentation results!\n",
            " 77% 323/422 [02:41<00:34,  2.84it/s]No segmentation results!\n",
            " 99% 417/422 [03:26<00:01,  2.65it/s]No segmentation results!\n",
            " 99% 418/422 [03:27<00:01,  2.08it/s]No segmentation results!\n",
            "100% 422/422 [03:29<00:00,  2.02it/s]\n",
            "{'Valid_Dice_Loss': 0.1341, 'Valid_F1_Score': 0.9478}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9478\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 12/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1134}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:05,  2.13it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:21,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.46it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:53,  2.12it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:34,  2.87it/s]No segmentation results!\n",
            " 99% 417/422 [03:23<00:01,  2.66it/s]No segmentation results!\n",
            " 99% 418/422 [03:23<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:26<00:00,  2.05it/s]\n",
            "{'Valid_Dice_Loss': 0.1377, 'Valid_F1_Score': 0.9464}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9464\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 13/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:19<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1113}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:11<03:06,  2.12it/s]No segmentation results!\n",
            "  9% 40/422 [00:26<10:23,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:54<01:34,  3.37it/s]No segmentation results!\n",
            " 73% 308/422 [02:34<00:53,  2.13it/s]No segmentation results!\n",
            " 77% 323/422 [02:41<00:34,  2.90it/s]No segmentation results!\n",
            " 99% 417/422 [03:25<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:25<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:27<00:00,  2.03it/s]\n",
            "{'Valid_Dice_Loss': 0.1317, 'Valid_F1_Score': 0.9497}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9497\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 14/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.11}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:22,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.40it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:53,  2.14it/s]No segmentation results!\n",
            " 77% 323/422 [02:40<00:33,  2.91it/s]No segmentation results!\n",
            " 99% 417/422 [03:23<00:01,  2.66it/s]No segmentation results!\n",
            " 99% 418/422 [03:24<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:26<00:00,  2.04it/s]\n",
            "{'Valid_Dice_Loss': 0.1281, 'Valid_F1_Score': 0.9486}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9486\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 15/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1087}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<03:04,  2.14it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:17,  1.62s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:35,  3.34it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:54,  2.10it/s]No segmentation results!\n",
            " 77% 323/422 [02:40<00:33,  2.92it/s]No segmentation results!\n",
            " 99% 417/422 [03:24<00:01,  2.63it/s]No segmentation results!\n",
            " 99% 418/422 [03:24<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:27<00:00,  2.04it/s]\n",
            "{'Valid_Dice_Loss': 0.1311, 'Valid_F1_Score': 0.9469}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9469\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 16/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:23<00:00,  3.51s/it]\n",
            "{'Train_Dice_Loss': 0.1057}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<03:07,  2.11it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:21,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:35,  3.35it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:53,  2.12it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:34,  2.90it/s]No segmentation results!\n",
            " 99% 417/422 [03:23<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:24<00:01,  2.10it/s]No segmentation results!\n",
            "100% 422/422 [03:26<00:00,  2.04it/s]\n",
            "{'Valid_Dice_Loss': 0.1284, 'Valid_F1_Score': 0.9508}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9508\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 17/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1043}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<03:05,  2.13it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:21,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:54<01:36,  3.31it/s]No segmentation results!\n",
            " 73% 308/422 [02:35<00:53,  2.12it/s]No segmentation results!\n",
            " 77% 323/422 [02:42<00:34,  2.91it/s]No segmentation results!\n",
            " 99% 417/422 [03:25<00:01,  2.65it/s]No segmentation results!\n",
            " 99% 418/422 [03:26<00:01,  2.09it/s]No segmentation results!\n",
            "100% 422/422 [03:28<00:00,  2.02it/s]\n",
            "{'Valid_Dice_Loss': 0.1234, 'Valid_F1_Score': 0.9507}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9507\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 18/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:21<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1014}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.17it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:25,  1.48s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:33,  3.43it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.16it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:19<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:20<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:22<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1258, 'Valid_F1_Score': 0.9486}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9486\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 19/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:22<00:00,  3.50s/it]\n",
            "{'Train_Dice_Loss': 0.1052}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<03:05,  2.13it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:21,  1.63s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:35,  3.34it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:53,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:34,  2.84it/s]No segmentation results!\n",
            " 99% 417/422 [03:23<00:01,  2.65it/s]No segmentation results!\n",
            " 99% 418/422 [03:24<00:01,  2.08it/s]No segmentation results!\n",
            "100% 422/422 [03:26<00:00,  2.04it/s]\n",
            "{'Valid_Dice_Loss': 0.1271, 'Valid_F1_Score': 0.9508}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9508\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 20/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:20<00:00,  3.49s/it]\n",
            "{'Train_Dice_Loss': 0.1017}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:27,  1.49s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:34,  3.39it/s]No segmentation results!\n",
            " 73% 308/422 [02:29<00:53,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:35<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:18<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:18<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:20<00:00,  2.10it/s]\n",
            "{'Valid_Dice_Loss': 0.1208, 'Valid_F1_Score': 0.951}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.951\n",
            "\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "Prediction finished: IBC180_004_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.56s\n",
            "Prediction finished: OD301_01_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.49s\n",
            "Prediction finished: YSM3919_pak2Dcdc42mChSW_24h_04_R3D_image.tif; img size = torch.Size([1, 3, 1024, 1024]); costing: 1.75s\n",
            "Prediction finished: pSP_99_crop_1_im.tif; img size = torch.Size([1, 3, 921, 1580]); costing: 2.68s\n",
            "Prediction finished: pSP_99_crop_2_im.tif; img size = torch.Size([1, 3, 580, 1080]); costing: 0.92s\n",
            "\n",
            " Total Time Cost: 6.40s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_from_phase1_on_YeaZ1219_0956.zip\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Train_Dice_Loss █▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Valid_Dice_Loss █▆▅▄▄▄▄▃▃▃▂▃▂▂▂▂▁▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Valid_F1_Score ▁▃▃▅▅▅▅▆▇▇▇▆▇▇▆██▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      total_time ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Train_Dice_Loss 0.1017\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Valid_Dice_Loss 0.1208\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Valid_F1_Score 0.951\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      total_time 0.92146\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmediar_from_phase1_on_YeaZ\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/bg5mwf42\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNDE4NjMzNQ==/version_details/v14\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231218_194104-bg5mwf42/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python ./main.py --config_path=config/step2_finetuning/finetuning_yeast.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbGmccWLKykd",
        "outputId": "86151476-e809-4691-81c6-7a3b384dc839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "100% 5/5 [00:01<00:00,  2.90it/s]\n",
            "mean F1 Score: 0.92548 +/- 0.014089487712475566\n",
            "mean AP Score: 0.86908 +/- 0.023814252539183338\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=results/ --gt_path=Datasets/test/labels --save_path=evaluation_result/mediar_FT_YeaZ_test_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmF03veOjO7S"
      },
      "source": [
        "Now we finetune the best model, i.e., \"phase 2 fine-tuned\". It performs the best on the challenge data, and it also has seen more data than phase 1 alone! (we just change the initial weights in the config file)\n",
        "\n",
        "However, it may be a bit too specific to challenge data. Let's see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNY1GG8KcPW_",
        "outputId": "9e296a74-4e13-46b9-c1c5-ca1ae71ff680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'data_setups': {'labeled': {'amplified': True,\n",
            "                             'batch_size': 8,\n",
            "                             'mapping_file': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'mapping_file_tuning': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'root': './',\n",
            "                             'valid_portion': 0.2},\n",
            "                 'public': {'enabled': False,\n",
            "                            'params': {'batch_size': 1,\n",
            "                                       'mapping_file': './train_tools/data_utils/mapping_public.json',\n",
            "                                       'root': './'}},\n",
            "                 'unlabeled': {'enabled': False}},\n",
            " 'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'exp_name': 'mediar_ft_challenge_from_phase2_on_YeaZ',\n",
            "                 'input_path': './Datasets/test/images',\n",
            "                 'make_submission': True,\n",
            "                 'output_path': './results/'},\n",
            " 'train_setups': {'model': {'name': 'mediar-former',\n",
            "                            'params': {},\n",
            "                            'pretrained': {'enabled': True,\n",
            "                                           'strict': False,\n",
            "                                           'weights': './weights/from_phase2.pth'}},\n",
            "                  'optimizer': {'name': 'adamw', 'params': {'lr': 2e-05}},\n",
            "                  'scheduler': {'enabled': True,\n",
            "                                'name': 'cosine',\n",
            "                                'params': {'T_max': 100, 'eta_min': 1e-07}},\n",
            "                  'seed': 19940817,\n",
            "                  'trainer': {'name': 'mediar',\n",
            "                              'params': {'algo_params': {'with_public': False},\n",
            "                                         'amp': True,\n",
            "                                         'device': 'cuda:0',\n",
            "                                         'num_epochs': 20,\n",
            "                                         'valid_frequency': 1}}},\n",
            " 'wandb_setups': {'group': 'Fine-tuning',\n",
            "                  'name': 'mediar_ft_challenge_from_phase2_on_YeaZ',\n",
            "                  'project': 'CellSeg'}}\n",
            "========================================================================================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandre-misrahi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ml-project-2-doughminators/wandb/run-20231219_011714-ixr2afxy\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmediar_ft_challenge_from_phase2_on_YeaZ\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/ixr2afxy\u001b[0m\n",
            "\n",
            "Loading pretrained model....\n",
            "\n",
            "(DataLoaded) Training data size: 1689, Validation data size: 422\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\n",
            "==================================================\n",
            "Train start on device: NVIDIA A100-SXM4-40GB\n",
            "==================================================\n",
            "[Round 1/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:28<00:00,  3.53s/it]\n",
            "{'Train_Dice_Loss': 0.1897}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:10<02:59,  2.21it/s]No segmentation results!\n",
            "  9% 40/422 [00:25<10:03,  1.58s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:31,  3.49it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.19it/s]No segmentation results!\n",
            " 77% 323/422 [02:36<00:33,  2.96it/s]No segmentation results!\n",
            " 99% 417/422 [03:19<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:19<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:21<00:00,  2.09it/s]\n",
            "{'Valid_Dice_Loss': 0.1737, 'Valid_F1_Score': 0.9374}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9374\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 2/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:30<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1441}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:26<11:29,  1.80s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:33,  3.41it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:53,  2.14it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.98it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.70it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.164, 'Valid_F1_Score': 0.9401}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9401\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 3/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1357}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:38,  1.51s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:32,  3.45it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.93it/s]No segmentation results!\n",
            " 99% 417/422 [03:19<00:01,  2.70it/s]No segmentation results!\n",
            " 99% 418/422 [03:20<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:22<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1552, 'Valid_F1_Score': 0.9446}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9446\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 4/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.128}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:58,  1.57s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:32,  3.45it/s]No segmentation results!\n",
            " 73% 308/422 [02:29<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:35<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:18<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:19<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:21<00:00,  2.10it/s]\n",
            "{'Valid_Dice_Loss': 0.1508, 'Valid_F1_Score': 0.946}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.946\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 5/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:33<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1214}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:00,  2.20it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:55,  1.56s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:32,  3.46it/s]No segmentation results!\n",
            " 73% 308/422 [02:29<00:52,  2.19it/s]No segmentation results!\n",
            " 77% 323/422 [02:35<00:33,  2.94it/s]No segmentation results!\n",
            " 99% 417/422 [03:17<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:18<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:20<00:00,  2.10it/s]\n",
            "{'Valid_Dice_Loss': 0.1419, 'Valid_F1_Score': 0.948}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.948\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 6/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1205}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:03,  2.16it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:12,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:34,  3.37it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:22<00:01,  2.72it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.15it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.06it/s]\n",
            "{'Valid_Dice_Loss': 0.1402, 'Valid_F1_Score': 0.9472}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9472\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 7/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:29<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1143}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.19it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:12,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.45it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.93it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1349, 'Valid_F1_Score': 0.9493}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9493\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 8/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1143}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<02:59,  2.21it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:59,  1.57s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:31,  3.50it/s]No segmentation results!\n",
            " 73% 308/422 [02:29<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:35<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:18<00:01,  2.72it/s]No segmentation results!\n",
            " 99% 418/422 [03:18<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:20<00:00,  2.10it/s]\n",
            "{'Valid_Dice_Loss': 0.1348, 'Valid_F1_Score': 0.9498}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9498\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 9/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1121}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.17it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:10,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.42it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:53,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.95it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.11it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1297, 'Valid_F1_Score': 0.9488}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9488\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 10/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1094}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:13,  1.61s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.44it/s]No segmentation results!\n",
            " 73% 308/422 [02:33<00:52,  2.16it/s]No segmentation results!\n",
            " 77% 323/422 [02:39<00:33,  2.93it/s]No segmentation results!\n",
            " 99% 417/422 [03:22<00:01,  2.70it/s]No segmentation results!\n",
            " 99% 418/422 [03:23<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:25<00:00,  2.05it/s]\n",
            "{'Valid_Dice_Loss': 0.1298, 'Valid_F1_Score': 0.9505}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9505\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 11/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1083}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<02:59,  2.21it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:02,  1.58s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:33,  3.41it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:36<00:33,  2.95it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.68it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1277, 'Valid_F1_Score': 0.9498}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9498\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 12/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1077}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:02,  2.17it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:05,  1.59s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.41it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:36<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:19<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:19<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:22<00:00,  2.09it/s]\n",
            "{'Valid_Dice_Loss': 0.1271, 'Valid_F1_Score': 0.9497}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9497\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 13/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1078}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:11<03:04,  2.15it/s]No segmentation results!\n",
            "  9% 40/422 [00:26<10:16,  1.61s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:32,  3.43it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.07it/s]\n",
            "{'Valid_Dice_Loss': 0.1217, 'Valid_F1_Score': 0.9504}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9504\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 14/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:31<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1041}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:00,  2.20it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:11,  1.60s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:33,  3.43it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.70it/s]No segmentation results!\n",
            " 99% 418/422 [03:20<00:01,  2.12it/s]No segmentation results!\n",
            "100% 422/422 [03:22<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1195, 'Valid_F1_Score': 0.9499}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9499\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 15/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:33<00:00,  3.56s/it]\n",
            "{'Train_Dice_Loss': 0.1029}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:00,  2.19it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:08,  1.59s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:32,  3.46it/s]No segmentation results!\n",
            " 73% 308/422 [02:30<00:52,  2.17it/s]No segmentation results!\n",
            " 77% 323/422 [02:36<00:33,  2.97it/s]No segmentation results!\n",
            " 99% 417/422 [03:19<00:01,  2.72it/s]No segmentation results!\n",
            " 99% 418/422 [03:20<00:01,  2.14it/s]No segmentation results!\n",
            "100% 422/422 [03:22<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1171, 'Valid_F1_Score': 0.9507}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9507\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 16/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1014}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<02:59,  2.20it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:07,  1.59s/it]No segmentation results!\n",
            " 24% 103/422 [00:51<01:32,  3.46it/s]No segmentation results!\n",
            " 73% 308/422 [02:29<00:51,  2.20it/s]No segmentation results!\n",
            " 77% 323/422 [02:36<00:33,  2.96it/s]No segmentation results!\n",
            " 99% 417/422 [03:18<00:01,  2.71it/s]No segmentation results!\n",
            " 99% 418/422 [03:19<00:01,  2.13it/s]No segmentation results!\n",
            "100% 422/422 [03:21<00:00,  2.09it/s]\n",
            "{'Valid_Dice_Loss': 0.1233, 'Valid_F1_Score': 0.9503}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9503\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 17/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:32<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.1001}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<09:44,  1.53s/it]No segmentation results!\n",
            " 24% 103/422 [00:53<01:34,  3.39it/s]No segmentation results!\n",
            " 73% 308/422 [02:31<00:52,  2.18it/s]No segmentation results!\n",
            " 77% 323/422 [02:37<00:33,  2.93it/s]No segmentation results!\n",
            " 99% 417/422 [03:20<00:01,  2.67it/s]No segmentation results!\n",
            " 99% 418/422 [03:21<00:01,  2.11it/s]No segmentation results!\n",
            "100% 422/422 [03:23<00:00,  2.08it/s]\n",
            "{'Valid_Dice_Loss': 0.1158, 'Valid_F1_Score': 0.9507}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9507\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 18/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:30<00:00,  3.54s/it]\n",
            "{'Train_Dice_Loss': 0.1002}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:01,  2.18it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:17,  1.62s/it]No segmentation results!\n",
            " 24% 103/422 [00:52<01:33,  3.42it/s]No segmentation results!\n",
            " 73% 308/422 [02:32<00:52,  2.15it/s]No segmentation results!\n",
            " 77% 323/422 [02:38<00:33,  2.95it/s]No segmentation results!\n",
            " 99% 417/422 [03:21<00:01,  2.69it/s]No segmentation results!\n",
            " 99% 418/422 [03:22<00:01,  2.10it/s]No segmentation results!\n",
            "100% 422/422 [03:24<00:00,  2.06it/s]\n",
            "{'Valid_Dice_Loss': 0.116, 'Valid_F1_Score': 0.9511}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9511\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 19/20]\n",
            ">>> Train Epoch\n",
            "100% 212/212 [12:33<00:00,  3.55s/it]\n",
            "{'Train_Dice_Loss': 0.0987}\n",
            "\n",
            ">>> Valid Epoch\n",
            "  6% 26/422 [00:09<03:04,  2.14it/s]No segmentation results!\n",
            "  9% 40/422 [00:24<10:10,  1.60s/it]No segmentation results!\n",
            " 16% 67/422 [00:37<01:57,  3.01it/s]"
          ]
        }
      ],
      "source": [
        "!python ./main.py --config_path=config/step2_finetuning/finetuning_yeast.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuObUn8-rSRW"
      },
      "source": [
        "Extract zip of the submission (test data inference results) and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTcR1Ss_4zL0"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/ml-project-2-doughminators/submissions/mediar_ft_challenge_from_phase2_on_YeaZ1219_1535.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/ml-project-2-doughminators/submissions/mediar_ft_challenge_from_phase2_on_YeaZ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjwjMN1MoPtt",
        "outputId": "db37c289-9cb7-4d82-fd03-01733d88059a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "  0% 0/6 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ml-project-2-doughminators/./evaluate.py\", line 84, in <module>\n",
            "    main()\n",
            "  File \"/content/ml-project-2-doughminators/./evaluate.py\", line 41, in main\n",
            "    assert name.endswith(\n",
            "AssertionError: The suffix of label name .ipynb_checkpoints should be _label.tiff\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=submissions/mediar_ft_challenge_from_phase2_on_YeaZ --gt_path=Datasets/test/labels --save_path=evaluation_result/mediar_ft_challenge_from_phase2_on_YeaZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4FAPJBvoP4-"
      },
      "source": [
        "We find out that this \"phase 2 fine-tuned\" model, when further fine-tuned on our YeaZ data, continues to learn after 20 epochs. It also outperforms the phase 1 model after fine-tuning on YeaZ. So, let's train the \"phase 2 fine-tuned\" model further with 20 more epochs. First we download the weights checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GSscL_WoT4A",
        "outputId": "c29ec3dc-781e-45a5-f08b-48bc1ed1e520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1p5Ih0_R3u52pX0oOOvuA46FGVgGVVh4i\n",
            "To: /content/ml-project-2-doughminators/weights/ft_from_phase2_on_YeaZ_20_epochs.pth.zip\n",
            "100% 450M/450M [00:19<00:00, 22.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/file/d/1p5Ih0_R3u52pX0oOOvuA46FGVgGVVh4i/view?usp=sharing --fuzzy -O weights/ft_from_phase2_on_YeaZ_20_epochs.pth.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne6Jeq8-smHW"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/ml-project-2-doughminators/weights/ft_from_phase2_on_YeaZ_20_epochs.pth.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/ml-project-2-doughminators/weights/ft_from_phase2_on_YeaZ_20_epochs.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LkoQFe-tv5J"
      },
      "source": [
        "Modify the config file with 40 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAsYjYGItAf4",
        "outputId": "8f854907-b296-4fcc-b7de-d05b3dc53b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'data_setups': {'labeled': {'amplified': False,\n",
            "                             'batch_size': 8,\n",
            "                             'mapping_file': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'mapping_file_tuning': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'root': './',\n",
            "                             'valid_portion': 0.2},\n",
            "                 'public': {'enabled': False,\n",
            "                            'params': {'batch_size': 1,\n",
            "                                       'mapping_file': './train_tools/data_utils/mapping_public.json',\n",
            "                                       'root': './'}},\n",
            "                 'unlabeled': {'enabled': False}},\n",
            " 'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'exp_name': 'mediar_ft_challenge_from_phase2_on_YeaZ_60_epochs',\n",
            "                 'input_path': './Datasets/test',\n",
            "                 'make_submission': True,\n",
            "                 'output_path': './results/'},\n",
            " 'train_setups': {'model': {'name': 'mediar-former',\n",
            "                            'params': {},\n",
            "                            'pretrained': {'enabled': True,\n",
            "                                           'strict': False,\n",
            "                                           'weights': './weights/from_phase2.pth'}},\n",
            "                  'optimizer': {'name': 'adamw', 'params': {'lr': 2e-05}},\n",
            "                  'scheduler': {'enabled': True,\n",
            "                                'name': 'cosine',\n",
            "                                'params': {'T_max': 100, 'eta_min': 1e-07}},\n",
            "                  'seed': 19940817,\n",
            "                  'trainer': {'name': 'mediar',\n",
            "                              'params': {'algo_params': {'with_public': False},\n",
            "                                         'amp': True,\n",
            "                                         'device': 'cuda:0',\n",
            "                                         'num_epochs': 40,\n",
            "                                         'valid_frequency': 1}}},\n",
            " 'wandb_setups': {'group': 'Fine-tuning',\n",
            "                  'name': 'mediar_ft_challenge_from_phase2_on_YeaZ_60_epochs',\n",
            "                  'project': 'CellSeg'}}\n",
            "========================================================================================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandre-misrahi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ml-project-2-doughminators/wandb/run-20231219_173510-o54nhp5n\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmediar_ft_challenge_from_phase2_on_YeaZ_60_epochs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/o54nhp5n\u001b[0m\n",
            "\n",
            "Loading pretrained model....\n",
            "\n",
            "(DataLoaded) Training data size: 2332, Validation data size: 582\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\n",
            "==================================================\n",
            "Train start on device: NVIDIA A100-SXM4-40GB\n",
            "==================================================\n",
            "[Round 1/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:39<00:00,  3.63s/it]\n",
            "{'Train_Dice_Loss': 0.2046}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:38<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:57<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1954, 'Valid_F1_Score': 0.9443}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9443\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 2/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:42<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1618}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:38<00:50,  1.79it/s]No segmentation results!\n",
            "100% 582/582 [07:56<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1814, 'Valid_F1_Score': 0.9491}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9491\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 3/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1539}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:50,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1766, 'Valid_F1_Score': 0.9522}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9522\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 4/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1483}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:35<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1697, 'Valid_F1_Score': 0.9544}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9544\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 5/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:41<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1442}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:49,  1.84it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1622, 'Valid_F1_Score': 0.954}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.954\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 6/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1421}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.158, 'Valid_F1_Score': 0.9561}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9561\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 7/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1393}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1562, 'Valid_F1_Score': 0.9582}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9582\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 8/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1363}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:24,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:37<00:50,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:55<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1571, 'Valid_F1_Score': 0.955}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.955\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 9/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1343}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:22,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:35<00:50,  1.79it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1557, 'Valid_F1_Score': 0.9562}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9562\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 10/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:46<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1324}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:15<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:37<00:49,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:57<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1534, 'Valid_F1_Score': 0.9569}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9569\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 11/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:46<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1308}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:39<00:50,  1.79it/s]No segmentation results!\n",
            "100% 582/582 [07:57<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1519, 'Valid_F1_Score': 0.9581}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9581\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 12/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1296}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:15<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:38<00:49,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:56<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1448, 'Valid_F1_Score': 0.9589}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9589\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 13/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1273}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.145, 'Valid_F1_Score': 0.9597}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9597\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 14/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1258}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:15<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:39<00:49,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:57<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1429, 'Valid_F1_Score': 0.9601}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9601\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 15/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:47<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1257}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:15<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:37<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:56<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1486, 'Valid_F1_Score': 0.9601}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9601\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 16/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:42<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1256}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1411, 'Valid_F1_Score': 0.9604}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9604\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 17/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1236}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:35<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1392, 'Valid_F1_Score': 0.9623}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9623\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 18/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:47<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1222}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1393, 'Valid_F1_Score': 0.9602}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9602\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 19/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:42<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1213}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:33<00:49,  1.84it/s]No segmentation results!\n",
            "100% 582/582 [07:50<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.14, 'Valid_F1_Score': 0.9618}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9618\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 20/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1183}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:24,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:33<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.139, 'Valid_F1_Score': 0.9624}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9624\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 21/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1195}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:32<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:49<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1375, 'Valid_F1_Score': 0.9612}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9612\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 22/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:42<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1183}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:32<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:49<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1356, 'Valid_F1_Score': 0.9613}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9613\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 23/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.119}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:22,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:32<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:50<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1402, 'Valid_F1_Score': 0.9621}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9621\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 24/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1189}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:35<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1378, 'Valid_F1_Score': 0.9619}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9619\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 25/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1168}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1356, 'Valid_F1_Score': 0.962}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.962\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 26/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:43<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1167}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:22,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:32<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:49<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1342, 'Valid_F1_Score': 0.9615}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9615\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 27/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:47<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1155}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:38<00:50,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:56<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1322, 'Valid_F1_Score': 0.9611}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9611\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 28/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:49<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1134}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:25,  1.65it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1332, 'Valid_F1_Score': 0.9624}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9624\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 29/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1142}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:26,  1.64it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1354, 'Valid_F1_Score': 0.9621}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9621\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 30/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.112}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:55<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1282, 'Valid_F1_Score': 0.9616}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9616\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 31/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:45<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1126}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:24,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:35<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.131, 'Valid_F1_Score': 0.9611}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9611\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 32/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1119}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:22,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:31<00:48,  1.85it/s]No segmentation results!\n",
            "100% 582/582 [07:47<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1313, 'Valid_F1_Score': 0.9625}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9625\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 33/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1121}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:09<03:20,  1.69it/s]No segmentation results!\n",
            " 85% 492/582 [06:27<00:48,  1.84it/s]No segmentation results!\n",
            "100% 582/582 [07:43<00:00,  1.26it/s]\n",
            "{'Valid_Dice_Loss': 0.1299, 'Valid_F1_Score': 0.9637}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9637\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 34/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:41<00:00,  3.63s/it]\n",
            "{'Train_Dice_Loss': 0.1111}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:08<03:20,  1.69it/s]No segmentation results!\n",
            " 85% 492/582 [06:27<00:48,  1.86it/s]No segmentation results!\n",
            "100% 582/582 [07:44<00:00,  1.25it/s]\n",
            "{'Valid_Dice_Loss': 0.1271, 'Valid_F1_Score': 0.9628}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9628\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 35/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:46<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1112}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:31<00:48,  1.84it/s]No segmentation results!\n",
            "100% 582/582 [07:49<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1288, 'Valid_F1_Score': 0.9624}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9624\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 36/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:42<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1119}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:26,  1.64it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:52<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1271, 'Valid_F1_Score': 0.9613}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9613\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 37/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:48<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1072}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:14<03:23,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:37<00:50,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:55<00:00,  1.22it/s]\n",
            "{'Valid_Dice_Loss': 0.1304, 'Valid_F1_Score': 0.9626}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9626\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 38/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:49<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1075}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.66it/s]No segmentation results!\n",
            " 85% 492/582 [06:36<00:49,  1.80it/s]No segmentation results!\n",
            "100% 582/582 [07:54<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.125, 'Valid_F1_Score': 0.9626}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9626\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 39/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.64s/it]\n",
            "{'Train_Dice_Loss': 0.1091}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:33<00:49,  1.82it/s]No segmentation results!\n",
            "100% 582/582 [07:51<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.125, 'Valid_F1_Score': 0.9642}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9642\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 40/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:44<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1071}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:13<03:22,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:34<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:53<00:00,  1.23it/s]\n",
            "{'Valid_Dice_Loss': 0.1245, 'Valid_F1_Score': 0.9636}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9636\n",
            "\n",
            "--------------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 89, in apply_transform\n",
            "    return _apply_transform(transform, data, unpack_items)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 53, in _apply_transform\n",
            "    return transform(parameters)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/io/array.py\", line 232, in __call__\n",
            "    raise RuntimeError(\n",
            "RuntimeError: CustomLoadImage cannot find a suitable reader for file: Datasets/test/.ipynb_checkpoints.\n",
            "    Please install the reader libraries, see also the installation instructions:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies.\n",
            "   The current registered: [<monai.data.image_reader.PILReader object at 0x7a029554c610>, <monai.data.image_reader.NibabelReader object at 0x7a02998acbb0>, <train_tools.data_utils.custom.LoadImage.UnifiedITKReader object at 0x7a029554dbd0>].\n",
            "\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ml-project-2-doughminators/./main.py\", line 129, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/ml-project-2-doughminators/./main.py\", line 106, in main\n",
            "    total_time = predictor.conduct_prediction()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/ml-project-2-doughminators/core/BasePredictor.py\", line 47, in conduct_prediction\n",
            "    img_data = self._get_img_data(img_name)\n",
            "  File \"/content/ml-project-2-doughminators/core/BasePredictor.py\", line 112, in _get_img_data\n",
            "    img_data = self.pred_transforms(img_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/compose.py\", line 173, in __call__\n",
            "    input_ = apply_transform(_transform, input_, self.map_items, self.unpack_items, self.log_stats)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 113, in apply_transform\n",
            "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
            "RuntimeError: applying transform <train_tools.data_utils.custom.LoadImage.CustomLoadImage object at 0x7a029558f370>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 89, in apply_transform\n",
            "    return _apply_transform(transform, data, unpack_items)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 53, in _apply_transform\n",
            "    return transform(parameters)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/io/array.py\", line 232, in __call__\n",
            "    raise RuntimeError(\n",
            "RuntimeError: CustomLoadImage cannot find a suitable reader for file: Datasets/test/.ipynb_checkpoints.\n",
            "    Please install the reader libraries, see also the installation instructions:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies.\n",
            "   The current registered: [<monai.data.image_reader.PILReader object at 0x7a029554c610>, <monai.data.image_reader.NibabelReader object at 0x7a02998acbb0>, <train_tools.data_utils.custom.LoadImage.UnifiedITKReader object at 0x7a029554dbd0>].\n",
            "\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ml-project-2-doughminators/./main.py\", line 129, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/ml-project-2-doughminators/./main.py\", line 106, in main\n",
            "    total_time = predictor.conduct_prediction()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/ml-project-2-doughminators/core/BasePredictor.py\", line 47, in conduct_prediction\n",
            "    img_data = self._get_img_data(img_name)\n",
            "  File \"/content/ml-project-2-doughminators/core/BasePredictor.py\", line 112, in _get_img_data\n",
            "    img_data = self.pred_transforms(img_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/compose.py\", line 173, in __call__\n",
            "    input_ = apply_transform(_transform, input_, self.map_items, self.unpack_items, self.log_stats)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/monai/transforms/transform.py\", line 113, in apply_transform\n",
            "    raise RuntimeError(f\"applying transform {transform}\") from e\n",
            "RuntimeError: applying transform <train_tools.data_utils.custom.LoadImage.CustomLoadImage object at 0x7a029558f370>\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Train_Dice_Loss █▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Valid_Dice_Loss █▇▆▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▃▂▂▂▃▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Valid_F1_Score ▁▃▄▅▄▅▆▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Train_Dice_Loss 0.1071\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Valid_Dice_Loss 0.1245\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  Valid_F1_Score 0.9636\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmediar_ft_challenge_from_phase2_on_YeaZ_60_epochs\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/o54nhp5n\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ️⚡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNDE4NjMzNQ==/version_details/v20\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20231219_173510-o54nhp5n/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python ./main.py --config_path=config/step2_finetuning/finetuning_yeast.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1gC_460gOY"
      },
      "source": [
        "[Error at prediction on test set so we do it manually below]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrM3m421s285",
        "outputId": "2fcb36cb-1b5a-4220-fb5e-11a57c3a0f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yrLncA-wf594qKAE43o3BDP-Za7S1YV0\n",
            "To: /content/ml-project-2-doughminators/weights/ft_from_phase2_on_YeaZ_40_epochs.pth.zip\n",
            "100% 450M/450M [00:13<00:00, 32.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/file/d/1yrLncA-wf594qKAE43o3BDP-Za7S1YV0/view?usp=sharing --fuzzy -O weights/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gJFc9tF-WuO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/ml-project-2-doughminators/weights/ft_from_phase2_on_YeaZ_40_epochs.pth.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/ml-project-2-doughminators/weights/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0mIyHJf_PoW",
        "outputId": "9c1c44b7-e52f-42c2-9de3-e86bb09e180d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'pred_setups': {'algo_params': {'use_tta': False},\n",
            "                 'device': 'cuda:0',\n",
            "                 'exp_name': 'mediar_ft_from_phase2_on_YeaZ_40_epochs',\n",
            "                 'input_path': 'Datasets/test/images',\n",
            "                 'make_submission': True,\n",
            "                 'model': {'name': 'mediar-former',\n",
            "                           'params': {'classes': 3,\n",
            "                                      'decoder_channels': [1024, 512, 256, 128,\n",
            "                                                           64],\n",
            "                                      'decoder_pab_channels': 256,\n",
            "                                      'encoder_name': 'mit_b5',\n",
            "                                      'in_channels': 3}},\n",
            "                 'model_path': './weights/ft_from_phase2_on_YeaZ_40_epochs.pth',\n",
            "                 'name': 'mediar',\n",
            "                 'output_path': './results/ft_from_phase2_on_YeaZ_40_epochs'}}\n",
            "========================================================================================================================\n",
            "Prediction finished: IBC180_004_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.38s\n",
            "Prediction finished: OD301_01_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.27s\n",
            "Prediction finished: YSM3919_pak2Dcdc42mChSW_24h_04_R3D_image.tif; img size = torch.Size([1, 3, 1024, 1024]); costing: 0.77s\n",
            "Prediction finished: pSP_99_crop_1_im.tif; img size = torch.Size([1, 3, 921, 1580]); costing: 0.99s\n",
            "Prediction finished: pSP_99_crop_2_im.tif; img size = torch.Size([1, 3, 580, 1080]); costing: 0.39s\n",
            "\n",
            " Total Time Cost: 2.81s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_ft_from_phase2_on_YeaZ_40_epochs1220_2037.zip\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --config_path=config/step3_prediction/ft_from_phase2_on_YeaZ_40_epochs.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIJp1ivH_Rrl",
        "outputId": "6d2dfdc6-4afe-4d6e-9d53-60c1412828f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "100% 5/5 [00:01<00:00,  2.89it/s]\n",
            "mean F1 Score: 0.9772399999999999 +/- 0.0024343081152557473\n",
            "mean AP Score: 0.95576 +/- 0.004596530865772574\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=results/ft_from_phase2_on_YeaZ_40_epochs --gt_path=Datasets/test/labels --save_path=evaluation_result/ft_from_phase2_on_YeaZ_40_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxe5rndKA8nR"
      },
      "source": [
        "Note: with test-time augmentation, it slightly reduces metrics to 0.9766 F1 and 0.9545 AP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GII1iyb7_Rw_",
        "outputId": "3e469179-5f70-48f6-89f3-aa7e402f8664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/ (stored 0%)\n",
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/YSM3919_pak2Dcdc42mChSW_24h_04_R3D_image_label.tiff (deflated 12%)\n",
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/pSP_99_crop_1_im_label.tiff (deflated 24%)\n",
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/OD301_01_image_label.tiff (deflated 8%)\n",
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/IBC180_004_image_label.tiff (deflated 7%)\n",
            "  adding: content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs/pSP_99_crop_2_im_label.tiff (deflated 18%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs.zip /content/ml-project-2-doughminators/results/ft_from_phase2_on_YeaZ_40_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCVjR6Zso3U"
      },
      "source": [
        "Now we want to perform ensemble prediction with the P1 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW960eD2sme-",
        "outputId": "25c8fbb3-d967-48c6-cd02-c671b7c59892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'device': 'cuda:0',\n",
            "                 'exp_name': 'mediar_ensemble_tta_fromphase2_ft_fromphase2_on_YeaZ_40_epochs',\n",
            "                 'input_path': 'Datasets/test/images',\n",
            "                 'make_submission': True,\n",
            "                 'model': {'name': 'mediar-former',\n",
            "                           'params': {'classes': 3,\n",
            "                                      'decoder_channels': [1024, 512, 256, 128,\n",
            "                                                           64],\n",
            "                                      'decoder_pab_channels': 256,\n",
            "                                      'encoder_name': 'mit_b5',\n",
            "                                      'in_channels': 3}},\n",
            "                 'model_path1': './weights/ft_from_phase2_on_YeaZ_40_epochs.pth',\n",
            "                 'model_path2': './weights/from_phase2.pth',\n",
            "                 'name': 'ensemble_mediar',\n",
            "                 'output_path': './results/ensemble_tta_fromphase2_ft_fromphase2_on_YeaZ_40_epochs'}}\n",
            "========================================================================================================================\n",
            "Prediction finished: IBC180_004_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.98s\n",
            "Prediction finished: OD301_01_image.tif; img size = torch.Size([1, 3, 512, 512]); costing: 0.70s\n",
            "Prediction finished: YSM3919_pak2Dcdc42mChSW_24h_04_R3D_image.tif; img size = torch.Size([1, 3, 1024, 1024]); costing: 2.44s\n",
            "Prediction finished: pSP_99_crop_1_im.tif; img size = torch.Size([1, 3, 921, 1580]); costing: 3.86s\n",
            "Prediction finished: pSP_99_crop_2_im.tif; img size = torch.Size([1, 3, 580, 1080]); costing: 1.29s\n",
            "\n",
            " Total Time Cost: 9.27s\n",
            "\n",
            ">>>>> Submission file is saved at: ./submissions/mediar_ensemble_tta_fromphase2_ft_fromphase2_on_YeaZ_40_epochs1220_2041.zip\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --config_path=config/step3_prediction/ensemble_tta_fromphase2_ft_from_phase2_on_YeaZ_40_epochs.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WT2cj4rbCAlL",
        "outputId": "4635a521-6b52-45d4-d396-99e5dbab5f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "100% 5/5 [00:01<00:00,  2.89it/s]\n",
            "mean F1 Score: 0.9683999999999999 +/- 0.0036124673008900684\n",
            "mean AP Score: 0.93932 +/- 0.006762453992449785\n"
          ]
        }
      ],
      "source": [
        "!python ./evaluate.py --pred_path=results/ensemble_tta_fromphase2_ft_fromphase2_on_YeaZ_40_epochs --gt_path=Datasets/test/labels --save_path=evaluation_result/ensemble_tta_fromphase2_ft_fromphase2_on_YeaZ_40_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FY2_hNOjCW-D"
      },
      "source": [
        "doesn't work as well (maybe because the second model used in the ensemble is just not general). We could try it with the P2 model which has also seen challenge data, thus more general. For time constraints we are not able to do so.\n",
        "\n",
        "Now let's fine-tune further on 40 more epochs. (we modify the config file to restart from the last checkpoint, accumulating the training on the last 40 epochs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIBeVvLsCMcQ",
        "outputId": "a0fa4c4e-c93c-4c16-ad1d-478a1494892f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n",
            "\n",
            "================================================== Configuration ==================================================\n",
            "{'data_setups': {'labeled': {'amplified': False,\n",
            "                             'batch_size': 8,\n",
            "                             'mapping_file': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'mapping_file_tuning': './train_tools/data_utils/mapping_labeled.json',\n",
            "                             'root': './',\n",
            "                             'valid_portion': 0.2},\n",
            "                 'public': {'enabled': False,\n",
            "                            'params': {'batch_size': 1,\n",
            "                                       'mapping_file': './train_tools/data_utils/mapping_public.json',\n",
            "                                       'root': './'}},\n",
            "                 'unlabeled': {'enabled': False}},\n",
            " 'pred_setups': {'algo_params': {'use_tta': True},\n",
            "                 'exp_name': 'mediar_ft_challenge_from_phase2_on_YeaZ_80_epochs',\n",
            "                 'input_path': './Datasets/test/images',\n",
            "                 'make_submission': True,\n",
            "                 'output_path': './results/'},\n",
            " 'train_setups': {'model': {'name': 'mediar-former',\n",
            "                            'params': {},\n",
            "                            'pretrained': {'enabled': True,\n",
            "                                           'strict': False,\n",
            "                                           'weights': './weights/ft_from_phase2_on_YeaZ_40_epochs.pth'}},\n",
            "                  'optimizer': {'name': 'adamw', 'params': {'lr': 2e-05}},\n",
            "                  'scheduler': {'enabled': True,\n",
            "                                'name': 'cosine',\n",
            "                                'params': {'T_max': 100, 'eta_min': 1e-07}},\n",
            "                  'seed': 19940817,\n",
            "                  'trainer': {'name': 'mediar',\n",
            "                              'params': {'algo_params': {'with_public': False},\n",
            "                                         'amp': True,\n",
            "                                         'device': 'cuda:0',\n",
            "                                         'num_epochs': 40,\n",
            "                                         'valid_frequency': 1}}},\n",
            " 'wandb_setups': {'group': 'Fine-tuning',\n",
            "                  'name': 'mediar_ft_challenge_from_phase2_on_YeaZ_80_epochs',\n",
            "                  'project': 'CellSeg'}}\n",
            "========================================================================================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandre-misrahi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/ml-project-2-doughminators/wandb/run-20231220_114610-fld99bg6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmediar_ft_challenge_from_phase2_on_YeaZ_80_epochs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandre-misrahi/CellSeg/runs/fld99bg6\u001b[0m\n",
            "\n",
            "Loading pretrained model....\n",
            "\n",
            "(DataLoaded) Training data size: 2332, Validation data size: 582\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
            "\n",
            "==================================================\n",
            "Train start on device: NVIDIA A100-SXM4-40GB\n",
            "==================================================\n",
            "[Round 1/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:46<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1086}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:21,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:31<00:48,  1.85it/s]No segmentation results!\n",
            "100% 582/582 [07:48<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1271, 'Valid_F1_Score': 0.9634}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9634\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 2/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:46<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1078}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:19,  1.70it/s]No segmentation results!\n",
            " 85% 492/582 [06:30<00:48,  1.85it/s]No segmentation results!\n",
            "100% 582/582 [07:46<00:00,  1.25it/s]\n",
            "{'Valid_Dice_Loss': 0.1273, 'Valid_F1_Score': 0.963}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.963\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 3/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:47<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1063}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:21,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:31<00:49,  1.81it/s]No segmentation results!\n",
            "100% 582/582 [07:48<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1344, 'Valid_F1_Score': 0.9616}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9616\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 4/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:49<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.107}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:10<03:21,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:30<00:48,  1.84it/s]No segmentation results!\n",
            "100% 582/582 [07:47<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1241, 'Valid_F1_Score': 0.9623}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9623\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 5/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:47<00:00,  3.65s/it]\n",
            "{'Train_Dice_Loss': 0.1074}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:11<03:19,  1.70it/s]No segmentation results!\n",
            " 85% 492/582 [06:27<00:48,  1.86it/s]No segmentation results!\n",
            "100% 582/582 [07:44<00:00,  1.25it/s]\n",
            "{'Valid_Dice_Loss': 0.1226, 'Valid_F1_Score': 0.965}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.965\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 6/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:48<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1072}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:09<03:21,  1.68it/s]No segmentation results!\n",
            " 85% 492/582 [06:30<00:48,  1.85it/s]No segmentation results!\n",
            "100% 582/582 [07:46<00:00,  1.25it/s]\n",
            "{'Valid_Dice_Loss': 0.1236, 'Valid_F1_Score': 0.9635}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9635\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 7/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:50<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1047}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 42% 243/582 [03:12<03:23,  1.67it/s]No segmentation results!\n",
            " 85% 492/582 [06:33<00:49,  1.83it/s]No segmentation results!\n",
            "100% 582/582 [07:50<00:00,  1.24it/s]\n",
            "{'Valid_Dice_Loss': 0.1239, 'Valid_F1_Score': 0.9624}\n",
            "\n",
            "\n",
            ">>>> Update Best Model with score: 0.9624\n",
            "\n",
            "--------------------------------------------------\n",
            "[Round 8/40]\n",
            ">>> Train Epoch\n",
            "100% 292/292 [17:48<00:00,  3.66s/it]\n",
            "{'Train_Dice_Loss': 0.1055}\n",
            "\n",
            ">>> Valid Epoch\n",
            " 32% 188/582 [02:30<02:46,  2.37it/s]"
          ]
        }
      ],
      "source": [
        "!python ./main.py --config_path=config/step2_finetuning/finetuning_yeast.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process is killed after 8 epochs (48 total) for technical reasons. However we can see that the validation F1 score does not increase anymore (in fact, the best validation F1 score was obtained in an epoch < 40)."
      ],
      "metadata": {
        "id": "A1ER0ugneDz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducibility of best results on a test set"
      ],
      "metadata": {
        "id": "C6DXTsrSpE9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the weights:"
      ],
      "metadata": {
        "id": "vw7BjbR_pIbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown [link to weights] --fuzzy -O weights/"
      ],
      "metadata": {
        "id": "YLjk2ps7pHpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write or re-use a prediction configuration file. In this case we use ```ft_from_phase2_on_YeaZ_80_epochs.json```. Make sure to modify the input path of the test images accordingly, as well as the output path, the device (if the test set is less than 10 images, it should be fine to use a CPU), and the experiment name. It is also possible to activate/deactivate test-time augmentation (TTA) but in our test case it worsens the results."
      ],
      "metadata": {
        "id": "n0EU9uOLp1Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --config_path=config/step3_prediction/ft_from_phase2_on_YeaZ_80_epochs.json"
      ],
      "metadata": {
        "id": "NuGhOft4qozV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the predictions:"
      ],
      "metadata": {
        "id": "NKQxUShYvhPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./evaluate.py --pred_path=results/ft_fromphase2_on_YeaZ_80_epochs --gt_path=Datasets/test/labels --save_path=evaluation_result/ft_fromphase2_on_YeaZ_80_epochs"
      ],
      "metadata": {
        "id": "cVCFKbK_vgW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}